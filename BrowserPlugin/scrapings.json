The message: {"type":"SaveWebScrapings","message":{"webPageId":2,"scrapings":" <%24cheerio1 id%3D\"top\"> Information theory From Wikipedia%2C the free encyclopedia <%24cheerio1 class%3D\"mw-jump-link\" href%3D\"%23mw-head\">Jump to navigation <%24cheerio1 class%3D\"mw-jump-link\" href%3D\"%23searchInput\">Jump to search Theory dealing with information Not to be confused with <%24cheerio1 href%3D\"%2Fwiki%2FInformation_science\" title%3D\"Information science\">Information science . <%24cheerio1 class%3D\"mbox-image\"> <%24cheerio1 class%3D\"mbox-text\"> This article may contain <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AWhat_Wikipedia_is_not%23Wikipedia_is_not_an_indiscriminate_collection_of_information\" title%3D\"Wikipedia%3AWhat Wikipedia is not\">indiscriminate %2C <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AManual_of_Style%2FEmbedded_lists%23List_size\" class%3D\"mw-redirect\" title%3D\"Wikipedia%3AManual of Style%2FEmbedded lists\">excessive %2C or <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3ANeutral_point_of_view%23Due_and_undue_weight\" title%3D\"Wikipedia%3ANeutral point of view\">irrelevant examples. Please <%24cheerio1 class%3D\"external text\" href%3D\"https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit\">improve the article by adding more descriptive text and removing <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AExample_cruft\" title%3D\"Wikipedia%3AExample cruft\">less pertinent examples . See Wikipedia's <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AWriting_better_articles\" title%3D\"Wikipedia%3AWriting better articles\">guide to writing better articles for further suggestions. ( May 2020) <%24cheerio1 style%3D\"padding%3A0.2em 0 0.4em\"> <%24cheerio1 href%3D\"%2Fwiki%2FFile%3ABinaryerasurechannel.png\" class%3D\"image\"> <%24cheerio1 style%3D\"padding%3A0 0.1em 0.4em\"> <%24cheerio1 href%3D\"%2Fwiki%2FEntropy_(information_theory)\" title%3D\"Entropy (information theory)\">Entropy <%24cheerio1 href%3D\"%2Fwiki%2FDifferential_entropy\" title%3D\"Differential entropy\">Differential entropy <%24cheerio1 href%3D\"%2Fwiki%2FConditional_entropy\" title%3D\"Conditional entropy\">Conditional entropy <%24cheerio1 href%3D\"%2Fwiki%2FJoint_entropy\" title%3D\"Joint entropy\">Joint entropy <%24cheerio1 href%3D\"%2Fwiki%2FMutual_information\" title%3D\"Mutual information\">Mutual information <%24cheerio1 href%3D\"%2Fwiki%2FConditional_mutual_information\" title%3D\"Conditional mutual information\">Conditional mutual information <%24cheerio1 href%3D\"%2Fwiki%2FRelative_entropy\" class%3D\"mw-redirect\" title%3D\"Relative entropy\">Relative entropy <%24cheerio1 href%3D\"%2Fwiki%2FEntropy_rate\" title%3D\"Entropy rate\">Entropy rate <%24cheerio1 href%3D\"%2Fwiki%2FLimiting_density_of_discrete_points\" title%3D\"Limiting density of discrete points\">Limiting density of discrete points <%24cheerio1 style%3D\"padding%3A0 0.1em 0.4em\"> <%24cheerio1 href%3D\"%2Fwiki%2FAsymptotic_equipartition_property\" title%3D\"Asymptotic equipartition property\">Asymptotic equipartition property <%24cheerio1 href%3D\"%2Fwiki%2FRate%E2%80%93distortion_theory\" title%3D\"Rate distortion theory\">Rate distortion theory <%24cheerio1 style%3D\"padding%3A0 0.1em 0.4em\"> <%24cheerio1 href%3D\"%2Fwiki%2FShannon%27s_source_coding_theorem\" title%3D\"Shannon's source coding theorem\">Shannon's source coding theorem <%24cheerio1 href%3D\"%2Fwiki%2FChannel_capacity\" title%3D\"Channel capacity\">Channel capacity <%24cheerio1 href%3D\"%2Fwiki%2FNoisy-channel_coding_theorem\" title%3D\"Noisy-channel coding theorem\">Noisy-channel coding theorem <%24cheerio1 href%3D\"%2Fwiki%2FShannon%E2%80%93Hartley_theorem\" title%3D\"Shannon Hartley theorem\">Shannon Hartley theorem <%24cheerio1 style%3D\"text-align%3Aright%3Bfont-size%3A115%\"> <%24cheerio1 href%3D\"%2Fwiki%2FTemplate%3AInformation_theory\" title%3D\"Template%3AInformation theory\"> <%24cheerio1bbr title%3D\"View this template\">v <%24cheerio1 href%3D\"%2Fwiki%2FTemplate_talk%3AInformation_theory\" title%3D\"Template talk%3AInformation theory\"> <%24cheerio1bbr title%3D\"Discuss this template\">t <%24cheerio1 class%3D\"external text\" href%3D\"https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DTemplate%3AInformation_theory%26action%3Dedit\"> <%24cheerio1bbr title%3D\"Edit this template\">e <%24cheerio1 class%3D\"mw-selflink selflink\">Information theory Information theory is the scientific study of the <%24cheerio1 href%3D\"%2Fwiki%2FQuantification_(science)\" title%3D\"Quantification (science)\">quantification %2C <%24cheerio1 href%3D\"%2Fwiki%2FComputer_data_storage\" title%3D\"Computer data storage\">storage %2C and <%24cheerio1 href%3D\"%2Fwiki%2FTelecommunication\" title%3D\"Telecommunication\">communication of <%24cheerio1 href%3D\"%2Fwiki%2FInformation\" title%3D\"Information\">information . The field was fundamentally established by the works of <%24cheerio1 href%3D\"%2Fwiki%2FHarry_Nyquist\" title%3D\"Harry Nyquist\">Harry Nyquist and <%24cheerio1 href%3D\"%2Fwiki%2FRalph_Hartley\" title%3D\"Ralph Hartley\">Ralph Hartley %2C in the 1920s%2C and <%24cheerio1 href%3D\"%2Fwiki%2FClaude_Shannon\" title%3D\"Claude Shannon\">Claude Shannon in the 1940s. The field is at the intersection of <%24cheerio1 href%3D\"%2Fwiki%2FProbability_theory\" title%3D\"Probability theory\">probability theory %2C <%24cheerio1 href%3D\"%2Fwiki%2FStatistics\" title%3D\"Statistics\">statistics %2C computer science%2C <%24cheerio1 href%3D\"%2Fwiki%2FStatistical_mechanics\" title%3D\"Statistical mechanics\">statistical mechanics %2C <%24cheerio1 href%3D\"%2Fwiki%2FInformation_engineering_(field)\" title%3D\"Information engineering (field)\">information engineering %2C and <%24cheerio1 href%3D\"%2Fwiki%2FElectrical_engineering\" title%3D\"Electrical engineering\">electrical engineering . A key measure in information theory is <%24cheerio1 href%3D\"%2Fwiki%2FInformation_entropy\" class%3D\"mw-redirect\" title%3D\"Information entropy\">entropy . Entropy quantifies the amount of uncertainty involved in the value of a <%24cheerio1 href%3D\"%2Fwiki%2FRandom_variable\" title%3D\"Random variable\">random variable or the outcome of a <%24cheerio1 href%3D\"%2Fwiki%2FRandom_process\" class%3D\"mw-redirect\" title%3D\"Random process\">random process . For example%2C identifying the outcome of a fair <%24cheerio1 href%3D\"%2Fwiki%2FCoin_flip\" class%3D\"mw-redirect\" title%3D\"Coin flip\">coin flip (with two equally likely outcomes) provides less information (lower entropy) than specifying the outcome from a roll of a <%24cheerio1 href%3D\"%2Fwiki%2FDice\" title%3D\"Dice\">die (with six equally likely outcomes). Some other important measures in information theory are <%24cheerio1 href%3D\"%2Fwiki%2FMutual_information\" title%3D\"Mutual information\">mutual information %2C channel capacity%2C <%24cheerio1 href%3D\"%2Fwiki%2FError_exponent\" title%3D\"Error exponent\">error exponents %2C and <%24cheerio1 href%3D\"%2Fwiki%2FRelative_entropy\" class%3D\"mw-redirect\" title%3D\"Relative entropy\">relative entropy . Important sub-fields of information theory include <%24cheerio1 href%3D\"%2Fwiki%2FSource_coding\" class%3D\"mw-redirect\" title%3D\"Source coding\">source coding %2C <%24cheerio1 href%3D\"%2Fwiki%2FAlgorithmic_complexity_theory\" class%3D\"mw-redirect\" title%3D\"Algorithmic complexity theory\">algorithmic complexity theory %2C <%24cheerio1 href%3D\"%2Fwiki%2FAlgorithmic_information_theory\" title%3D\"Algorithmic information theory\">algorithmic information theory %2C and <%24cheerio1 href%3D\"%2Fwiki%2FInformation-theoretic_security\" title%3D\"Information-theoretic security\">information-theoretic security . Applications of fundamental topics of information theory include <%24cheerio1 href%3D\"%2Fwiki%2FLossless_data_compression\" class%3D\"mw-redirect\" title%3D\"Lossless data compression\">lossless data compression (e.g. <%24cheerio1 href%3D\"%2Fwiki%2FZIP_(file_format)\" title%3D\"ZIP (file format)\">ZIP files )%2C <%24cheerio1 href%3D\"%2Fwiki%2FLossy_data_compression\" class%3D\"mw-redirect\" title%3D\"Lossy data compression\">lossy data compression (e.g. <%24cheerio1 href%3D\"%2Fwiki%2FMP3\" title%3D\"MP3\">MP3s and <%24cheerio1 href%3D\"%2Fwiki%2FJPEG\" title%3D\"JPEG\">JPEGs )%2C and <%24cheerio1 href%3D\"%2Fwiki%2FChannel_capacity\" title%3D\"Channel capacity\">channel coding (e.g. for <%24cheerio1 href%3D\"%2Fwiki%2FDigital_subscriber_line\" title%3D\"Digital subscriber line\">DSL ). Its impact has been crucial to the success of the <%24cheerio1 href%3D\"%2Fwiki%2FVoyager_program\" title%3D\"Voyager program\">Voyager missions to deep space%2C the invention of the <%24cheerio1 href%3D\"%2Fwiki%2FCompact_disc\" title%3D\"Compact disc\">compact disc %2C the feasibility of mobile phones and the development of the Internet. The theory has also found applications in other areas%2C including <%24cheerio1 href%3D\"%2Fwiki%2FStatistical_inference\" title%3D\"Statistical inference\">statistical inference %2C <%24cheerio1 href%3D\"%23cite_note-1\">[1] <%24cheerio1 href%3D\"%2Fwiki%2FCryptography\" title%3D\"Cryptography\">cryptography %2C <%24cheerio1 href%3D\"%2Fwiki%2FNeurobiology\" class%3D\"mw-redirect\" title%3D\"Neurobiology\">neurobiology %2C <%24cheerio1 href%3D\"%23cite_note-Spikes-2\">[2] <%24cheerio1 href%3D\"%2Fwiki%2FPerception\" title%3D\"Perception\">perception %2C <%24cheerio1 href%3D\"%23cite_note-3\">[3] linguistics%2C the evolution <%24cheerio1 href%3D\"%23cite_note-4\">[4] and function <%24cheerio1 href%3D\"%23cite_note-5\">[5] of molecular codes ( <%24cheerio1 href%3D\"%2Fwiki%2FBioinformatics\" title%3D\"Bioinformatics\">bioinformatics )%2C <%24cheerio1 href%3D\"%2Fwiki%2FThermal_physics\" title%3D\"Thermal physics\">thermal physics %2C <%24cheerio1 href%3D\"%23cite_note-6\">[6] <%24cheerio1 href%3D\"%2Fwiki%2FQuantum_computing\" title%3D\"Quantum computing\">quantum computing %2C black holes%2C <%24cheerio1 href%3D\"%2Fwiki%2FInformation_retrieval\" title%3D\"Information retrieval\">information retrieval %2C <%24cheerio1 href%3D\"%2Fwiki%2FIntelligence_(Information_Gathering)\" class%3D\"mw-redirect\" title%3D\"Intelligence (Information Gathering)\">intelligence gathering %2C <%24cheerio1 href%3D\"%2Fwiki%2FPlagiarism_detection\" class%3D\"mw-redirect\" title%3D\"Plagiarism detection\">plagiarism detection %2C <%24cheerio1 href%3D\"%23cite_note-7\">[7] <%24cheerio1 href%3D\"%2Fwiki%2FPattern_recognition\" title%3D\"Pattern recognition\">pattern recognition %2C <%24cheerio1 href%3D\"%2Fwiki%2FAnomaly_detection\" title%3D\"Anomaly detection\">anomaly detection <%24cheerio1 href%3D\"%23cite_note-8\">[8] and even art creation. Contents <%24cheerio1 href%3D\"%23Overview\"> 1 Overview <%24cheerio1 href%3D\"%23Historical_background\"> 2 Historical background <%24cheerio1 href%3D\"%23Quantities_of_information\"> 3 Quantities of information <%24cheerio1 href%3D\"%23Entropy_of_an_information_source\"> 3.1 Entropy of an information source <%24cheerio1 href%3D\"%23Joint_entropy\"> 3.2 Joint entropy <%24cheerio1 href%3D\"%23Conditional_entropy_(equivocation)\"> 3.3 Conditional entropy (equivocation) <%24cheerio1 href%3D\"%23Mutual_information_(transinformation)\"> 3.4 Mutual information (transinformation) <%24cheerio1 href%3D\"%23Kullback Leibler_divergence_(information_gain)\"> 3.5 Kullback Leibler divergence (information gain) <%24cheerio1 href%3D\"%23Other_quantities\"> 3.6 Other quantities <%24cheerio1 href%3D\"%23Coding_theory\"> 4 Coding theory <%24cheerio1 href%3D\"%23Source_theory\"> 4.1 Source theory <%24cheerio1 href%3D\"%23Rate\"> 4.1.1 Rate <%24cheerio1 href%3D\"%23Channel_capacity\"> 4.2 Channel capacity <%24cheerio1 href%3D\"%23Capacity_of_particular_channel_models\"> 4.2.1 Capacity of particular channel models <%24cheerio1 href%3D\"%23Channels_with_memory_and_dircted_infomation\"> 4.2.2 Channels with memory and dircted infomation <%24cheerio1 href%3D\"%23Applications_to_other_fields\"> 5 Applications to other fields <%24cheerio1 href%3D\"%23Intelligence_uses_and_secrecy_applications\"> 5.1 Intelligence uses and secrecy applications <%24cheerio1 href%3D\"%23Pseudorandom_number_generation\"> 5.2 Pseudorandom number generation <%24cheerio1 href%3D\"%23Seismic_exploration\"> 5.3 Seismic exploration <%24cheerio1 href%3D\"%23Semiotics\"> 5.4 Semiotics <%24cheerio1 href%3D\"%23Miscellaneous_applications\"> 5.5 Miscellaneous applications <%24cheerio1 href%3D\"%23See_also\"> 6 See also <%24cheerio1 href%3D\"%23Applications\"> 6.1 Applications <%24cheerio1 href%3D\"%23History\"> 6.2 History <%24cheerio1 href%3D\"%23Theory\"> 6.3 Theory <%24cheerio1 href%3D\"%23Concepts\"> 6.4 Concepts <%24cheerio1 href%3D\"%23References\"> 7 References <%24cheerio1 href%3D\"%23The_classic_work\"> 7.1 The classic work <%24cheerio1 href%3D\"%23Other_journal_articles\"> 7.2 Other journal articles <%24cheerio1 href%3D\"%23Textbooks_on_information_theory\"> 7.3 Textbooks on information theory <%24cheerio1 href%3D\"%23Other_books\"> 7.4 Other books <%24cheerio1 href%3D\"%23MOOC_on_information_theory\"> 7.5 MOOC on information theory <%24cheerio1 href%3D\"%23External_links\"> 8 External links Overview [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D1\" title%3D\"Edit section%3A Overview\">edit ] Information theory studies the transmission%2C processing%2C extraction%2C and utilization of information. Abstractly%2C information can be thought of as the resolution of uncertainty. In the case of communication of information over a noisy channel%2C this abstract concept was formalized in 1948 by Claude Shannon in a paper entitled <%24cheerio1 href%3D\"%2Fwiki%2FA_Mathematical_Theory_of_Communication\" title%3D\"A Mathematical Theory of Communication\">A Mathematical Theory of Communication %2C in which information is thought of as a set of possible messages%2C and the goal is to send these messages over a noisy channel%2C and to have the receiver reconstruct the message with low probability of error%2C in spite of the channel noise. Shannon's main result%2C the <%24cheerio1 href%3D\"%2Fwiki%2FNoisy-channel_coding_theorem\" title%3D\"Noisy-channel coding theorem\">noisy-channel coding theorem showed that%2C in the limit of many channel uses%2C the rate of information that is asymptotically achievable is equal to the channel capacity%2C a quantity dependent merely on the statistics of the channel over which the messages are sent. <%24cheerio1 href%3D\"%23cite_note-Spikes-2\">[2] Information theory is closely associated with a collection of pure and applied disciplines that have been investigated and reduced to engineering practice under a variety of <%24cheerio1 href%3D\"%2Fwiki%2FRubric_(academic)\" title%3D\"Rubric (academic)\">rubrics throughout the world over the past half-century or more%3A <%24cheerio1 href%3D\"%2Fwiki%2FAdaptive_system\" title%3D\"Adaptive system\">adaptive systems %2C <%24cheerio1 href%3D\"%2Fwiki%2FAnticipatory_system\" class%3D\"mw-redirect\" title%3D\"Anticipatory system\">anticipatory systems %2C <%24cheerio1 href%3D\"%2Fwiki%2FArtificial_intelligence\" title%3D\"Artificial intelligence\">artificial intelligence %2C <%24cheerio1 href%3D\"%2Fwiki%2FComplex_system\" title%3D\"Complex system\">complex systems %2C <%24cheerio1 href%3D\"%2Fwiki%2FComplexity_science\" class%3D\"mw-redirect\" title%3D\"Complexity science\">complexity science %2C <%24cheerio1 href%3D\"%2Fwiki%2FCybernetics\" title%3D\"Cybernetics\">cybernetics %2C <%24cheerio1 href%3D\"%2Fwiki%2FInformatics_(academic_field)\" class%3D\"mw-redirect\" title%3D\"Informatics (academic field)\">informatics %2C <%24cheerio1 href%3D\"%2Fwiki%2FMachine_learning\" title%3D\"Machine learning\">machine learning %2C along with <%24cheerio1 href%3D\"%2Fwiki%2FSystems_science\" title%3D\"Systems science\">systems sciences of many descriptions. Information theory is a broad and deep mathematical theory%2C with equally broad and deep applications%2C amongst which is the vital field of <%24cheerio1 href%3D\"%2Fwiki%2FCoding_theory\" title%3D\"Coding theory\">coding theory . Coding theory is concerned with finding explicit methods%2C called codes%2C for increasing the efficiency and reducing the error rate of data communication over noisy channels to near the channel capacity. These codes can be roughly subdivided into data compression (source coding) and <%24cheerio1 href%3D\"%2Fwiki%2FError-correction\" class%3D\"mw-redirect\" title%3D\"Error-correction\">error-correction (channel coding) techniques. In the latter case%2C it took many years to find the methods Shannon's work proved were possible. A third class of information theory codes are cryptographic algorithms (both <%24cheerio1 href%3D\"%2Fwiki%2FCode_(cryptography)\" title%3D\"Code (cryptography)\">codes and <%24cheerio1 href%3D\"%2Fwiki%2FCipher\" title%3D\"Cipher\">ciphers ). Concepts%2C methods and results from coding theory and information theory are widely used in cryptography and <%24cheerio1 href%3D\"%2Fwiki%2FCryptanalysis\" title%3D\"Cryptanalysis\">cryptanalysis . See the article <%24cheerio1 href%3D\"%2Fwiki%2FBan_(unit)\" class%3D\"mw-redirect\" title%3D\"Ban (unit)\">ban (unit) for a historical application. Historical background [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D2\" title%3D\"Edit section%3A Historical background\">edit ] Main article%3A <%24cheerio1 href%3D\"%2Fwiki%2FHistory_of_information_theory\" title%3D\"History of information theory\">History of information theory The landmark event that established the discipline of information theory and brought it to immediate worldwide attention was the publication of Claude E. Shannon's classic paper \"A Mathematical Theory of Communication\" in the <%24cheerio1 href%3D\"%2Fwiki%2FBell_System_Technical_Journal\" class%3D\"mw-redirect\" title%3D\"Bell System Technical Journal\">Bell System Technical Journal in July and October 1948. Prior to this paper%2C limited information-theoretic ideas had been developed at <%24cheerio1 href%3D\"%2Fwiki%2FBell_Labs\" title%3D\"Bell Labs\">Bell Labs %2C all implicitly assuming events of equal probability. <%24cheerio1 href%3D\"%2Fwiki%2FHarry_Nyquist\" title%3D\"Harry Nyquist\">Harry Nyquist 's 1924 paper%2C Certain Factors Affecting Telegraph Speed%2C contains a theoretical section quantifying \"intelligence\" and the \"line speed\" at which it can be transmitted by a communication system%2C giving the relation W %3D K log m (recalling <%24cheerio1 href%3D\"%2Fwiki%2FBoltzmann%27s_constant\" class%3D\"mw-redirect\" title%3D\"Boltzmann's constant\">Boltzmann's constant )%2C where W is the speed of transmission of intelligence%2C m is the number of different voltage levels to choose from at each time step%2C and K is a constant. <%24cheerio1 href%3D\"%2Fwiki%2FRalph_Hartley\" title%3D\"Ralph Hartley\">Ralph Hartley 's 1928 paper%2C Transmission of Information%2C uses the word information as a measurable quantity%2C reflecting the receiver's ability to distinguish one <%24cheerio1 href%3D\"%2Fwiki%2FSequence_of_symbols\" class%3D\"mw-redirect\" title%3D\"Sequence of symbols\">sequence of symbols from any other%2C thus quantifying information as H %3D log Sn %3D n log S%2C where S was the number of possible symbols%2C and n the number of symbols in a transmission. The unit of information was therefore the <%24cheerio1 href%3D\"%2Fwiki%2FDecimal_digit\" class%3D\"mw-redirect\" title%3D\"Decimal digit\">decimal digit %2C which has since sometimes been called the <%24cheerio1 href%3D\"%2Fwiki%2FHartley_(unit)\" title%3D\"Hartley (unit)\">hartley in his honor as a unit or scale or measure of information. <%24cheerio1 href%3D\"%2Fwiki%2FAlan_Turing\" title%3D\"Alan Turing\">Alan Turing in 1940 used similar ideas as part of the statistical analysis of the breaking of the German second world war <%24cheerio1 href%3D\"%2Fwiki%2FCryptanalysis_of_the_Enigma\" title%3D\"Cryptanalysis of the Enigma\">Enigma ciphers. Much of the mathematics behind information theory with events of different probabilities were developed for the field of <%24cheerio1 href%3D\"%2Fwiki%2FThermodynamics\" title%3D\"Thermodynamics\">thermodynamics by <%24cheerio1 href%3D\"%2Fwiki%2FLudwig_Boltzmann\" title%3D\"Ludwig Boltzmann\">Ludwig Boltzmann and <%24cheerio1 href%3D\"%2Fwiki%2FJ._Willard_Gibbs\" class%3D\"mw-redirect\" title%3D\"J. Willard Gibbs\">J. Willard Gibbs . Connections between information-theoretic entropy and thermodynamic entropy%2C including the important contributions by <%24cheerio1 href%3D\"%2Fwiki%2FRolf_Landauer\" title%3D\"Rolf Landauer\">Rolf Landauer in the 1960s%2C are explored in <%24cheerio1 href%3D\"%2Fwiki%2FEntropy_in_thermodynamics_and_information_theory\" title%3D\"Entropy in thermodynamics and information theory\">Entropy in thermodynamics and information theory . In Shannon's revolutionary and groundbreaking paper%2C the work for which had been substantially completed at Bell Labs by the end of 1944%2C Shannon for the first time introduced the qualitative and quantitative model of communication as a statistical process underlying information theory%2C opening with the assertion that \"The fundamental problem of communication is that of reproducing at one point%2C either exactly or approximately%2C a message selected at another point.\" With it came the ideas of the information entropy and <%24cheerio1 href%3D\"%2Fwiki%2FRedundancy_(information_theory)\" title%3D\"Redundancy (information theory)\">redundancy of a source%2C and its relevance through the <%24cheerio1 href%3D\"%2Fwiki%2FSource_coding_theorem\" class%3D\"mw-redirect\" title%3D\"Source coding theorem\">source coding theorem %3B the mutual information%2C and the channel capacity of a noisy channel%2C including the promise of perfect loss-free communication given by the noisy-channel coding theorem%3B the practical result of the <%24cheerio1 href%3D\"%2Fwiki%2FShannon%E2%80%93Hartley_law\" class%3D\"mw-redirect\" title%3D\"Shannon Hartley law\">Shannon Hartley law for the channel capacity of a <%24cheerio1 href%3D\"%2Fwiki%2FGaussian_channel\" class%3D\"mw-redirect\" title%3D\"Gaussian channel\">Gaussian channel %3B as well as the <%24cheerio1 href%3D\"%2Fwiki%2FBit\" title%3D\"Bit\">bit a new way of seeing the most fundamental unit of information. Quantities of information [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D3\" title%3D\"Edit section%3A Quantities of information\">edit ] Main article%3A <%24cheerio1 href%3D\"%2Fwiki%2FQuantities_of_information\" title%3D\"Quantities of information\">Quantities of information Information theory is based on <%24cheerio1 href%3D\"%2Fwiki%2FProbability_theory\" title%3D\"Probability theory\">probability theory and statistics. Information theory often concerns itself with measures of information of the distributions associated with random variables. Important quantities of information are entropy%2C a measure of information in a single random variable%2C and mutual information%2C a measure of information in common between two random variables. The former quantity is a property of the probability distribution of a random variable and gives a limit on the rate at which data generated by independent samples with the given distribution can be reliably compressed. The latter is a property of the joint distribution of two random variables%2C and is the maximum rate of reliable communication across a noisy <%24cheerio1 href%3D\"%2Fwiki%2FCommunication_channel\" title%3D\"Communication channel\">channel in the limit of long block lengths%2C when the channel statistics are determined by the joint distribution. The choice of logarithmic base in the following formulae determines the <%24cheerio1 href%3D\"%2Fwiki%2FUnits_of_measurement\" class%3D\"mw-redirect\" title%3D\"Units of measurement\">unit of information entropy that is used. A common unit of information is the bit%2C based on the <%24cheerio1 href%3D\"%2Fwiki%2FBinary_logarithm\" title%3D\"Binary logarithm\">binary logarithm . Other units include the <%24cheerio1 href%3D\"%2Fwiki%2FNat_(unit)\" title%3D\"Nat (unit)\">nat %2C which is based on the <%24cheerio1 href%3D\"%2Fwiki%2FNatural_logarithm\" title%3D\"Natural logarithm\">natural logarithm %2C and the <%24cheerio1 href%3D\"%2Fwiki%2FDeciban\" class%3D\"mw-redirect\" title%3D\"Deciban\">decimal digit %2C which is based on the <%24cheerio1 href%3D\"%2Fwiki%2FCommon_logarithm\" title%3D\"Common logarithm\">common logarithm . In what follows%2C an expression of the form p log p is considered by convention to be equal to zero whenever p %3D 0. This is justified because lim p 0 %2B p log p %3D 0 <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle \\lim _{p\\rightarrow 0%2B}p\\log p%3D0} for any logarithmic base. Entropy of an information source [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D4\" title%3D\"Edit section%3A Entropy of an information source\">edit ] Based on the <%24cheerio1 href%3D\"%2Fwiki%2FProbability_mass_function\" title%3D\"Probability mass function\">probability mass function of each source symbol to be communicated%2C the Shannon <%24cheerio1 href%3D\"%2Fwiki%2FEntropy_(information_theory)\" title%3D\"Entropy (information theory)\">entropy H%2C in units of bits (per symbol)%2C is given by H %3D i p i log 2 ( p i ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle H%3D-\\sum _{i}p_{i}\\log _{2}(p_{i})} where pi is the probability of occurrence of the i-th possible value of the source symbol. This equation gives the entropy in the units of \"bits\" (per symbol) because it uses a logarithm of base 2%2C and this base-2 measure of entropy has sometimes been called the <%24cheerio1 href%3D\"%2Fwiki%2FShannon_(unit)\" title%3D\"Shannon (unit)\">shannon in his honor. Entropy is also commonly computed using the natural logarithm (base <%24cheerio1 href%3D\"%2Fwiki%2FE_(mathematical_constant)\" title%3D\"E (mathematical constant)\"> e %2C where e is Euler's number)%2C which produces a measurement of entropy in nats per symbol and sometimes simplifies the analysis by avoiding the need to include extra constants in the formulas. Other bases are also possible%2C but less commonly used. For example%2C a logarithm of base 28 %3D 256 will produce a measurement in <%24cheerio1 href%3D\"%2Fwiki%2FByte\" title%3D\"Byte\">bytes per symbol%2C and a logarithm of base 10 will produce a measurement in decimal digits (or <%24cheerio1 href%3D\"%2Fwiki%2FHartley_(unit)\" title%3D\"Hartley (unit)\">hartleys ) per symbol. Intuitively%2C the entropy HX of a discrete random variable X is a measure of the amount of uncertainty associated with the value of X when only its distribution is known. The entropy of a source that emits a sequence of N symbols that are <%24cheerio1 href%3D\"%2Fwiki%2FIndependent_and_identically_distributed\" class%3D\"mw-redirect\" title%3D\"Independent and identically distributed\">independent and identically distributed (iid) is N H bits (per message of N symbols). If the source data symbols are identically distributed but not independent%2C the entropy of a message of length N will be less than N H. <%24cheerio1 href%3D\"%2Fwiki%2FFile%3ABinary_entropy_plot.svg\" class%3D\"image\"> <%24cheerio1 href%3D\"%2Fwiki%2FFile%3ABinary_entropy_plot.svg\" class%3D\"internal\" title%3D\"Enlarge\"> The entropy of a <%24cheerio1 href%3D\"%2Fwiki%2FBernoulli_trial\" title%3D\"Bernoulli trial\">Bernoulli trial as a function of success probability%2C often called the <%24cheerio1 href%3D\"%2Fwiki%2FBinary_entropy_function\" title%3D\"Binary entropy function\">binary entropy function %2C Hb(p). The entropy is maximized at 1 bit per trial when the two possible outcomes are equally probable%2C as in an unbiased coin toss. If one transmits 1000 bits (0s and 1s)%2C and the value of each of these bits is known to the receiver (has a specific value with certainty) ahead of transmission%2C it is clear that no information is transmitted. If%2C however%2C each bit is independently equally likely to be 0 or 1%2C 1000 shannons of information (more often called bits) have been transmitted. Between these two extremes%2C information can be quantified as follows. If is the set of all messages {x1%2C ...%2C xn} that X could be%2C and p(x) is the probability of some x X <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle x\\in \\mathbb {X} } %2C then the entropy%2C H%2C of X is defined%3A <%24cheerio1 href%3D\"%23cite_note-Reza-9\">[9] H ( X ) %3D E X [ I ( x ) ] %3D x X p ( x ) log p ( x ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle H(X)%3D\\mathbb {E} _{X}[I(x)]%3D-\\sum _{x\\in \\mathbb {X} }p(x)\\log p(x).} (Here%2C I(x) is the <%24cheerio1 href%3D\"%2Fwiki%2FSelf-information\" class%3D\"mw-redirect\" title%3D\"Self-information\">self-information %2C which is the entropy contribution of an individual message%2C and X is the <%24cheerio1 href%3D\"%2Fwiki%2FExpected_value\" title%3D\"Expected value\">expected value .) A property of entropy is that it is maximized when all the messages in the message space are equiprobable p(x) %3D 1%2Fn%3B i.e.%2C most unpredictable%2C in which case H(X) %3D log n. The special case of information entropy for a random variable with two outcomes is the binary entropy function%2C usually taken to the logarithmic base 2%2C thus having the shannon (Sh) as unit%3A H b ( p ) %3D p log 2 p ( 1 p ) log 2 ( 1 p ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle H_{\\mathrm {b} }(p)%3D-p\\log _{2}p-(1-p)\\log _{2}(1-p).} Joint entropy [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D5\" title%3D\"Edit section%3A Joint entropy\">edit ] The <%24cheerio1 href%3D\"%2Fwiki%2FJoint_entropy\" title%3D\"Joint entropy\">joint entropy of two discrete random variables X and Y is merely the entropy of their pairing%3A (X%2C Y). This implies that if X and Y are <%24cheerio1 href%3D\"%2Fwiki%2FStatistical_independence\" class%3D\"mw-redirect\" title%3D\"Statistical independence\">independent %2C then their joint entropy is the sum of their individual entropies. For example%2C if (X%2C Y) represents the position of a chess piece X the row and Y the column%2C then the joint entropy of the row of the piece and the column of the piece will be the entropy of the position of the piece. H ( X %2C Y ) %3D E X %2C Y [ log p ( x %2C y ) ] %3D x %2C y p ( x %2C y ) log p ( x %2C y ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle H(X%2CY)%3D\\mathbb {E} _{X%2CY}[-\\log p(x%2Cy)]%3D-\\sum _{x%2Cy}p(x%2Cy)\\log p(x%2Cy)\\%2C} Despite similar notation%2C joint entropy should not be confused with <%24cheerio1 href%3D\"%2Fwiki%2FCross_entropy\" title%3D\"Cross entropy\">cross entropy . Conditional entropy (equivocation) [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D6\" title%3D\"Edit section%3A Conditional entropy (equivocation)\">edit ] The <%24cheerio1 href%3D\"%2Fwiki%2FConditional_entropy\" title%3D\"Conditional entropy\">conditional entropy or conditional uncertainty of X given random variable Y (also called the equivocation of X about Y) is the average conditional entropy over Y%3A <%24cheerio1 href%3D\"%23cite_note-Ash-10\">[10] H ( X | Y ) %3D E Y [ H ( X | y ) ] %3D y Y p ( y ) x X p ( x | y ) log p ( x | y ) %3D x %2C y p ( x %2C y ) log p ( x | y ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle H(X|Y)%3D\\mathbb {E} _{Y}[H(X|y)]%3D-\\sum _{y\\in Y}p(y)\\sum _{x\\in X}p(x|y)\\log p(x|y)%3D-\\sum _{x%2Cy}p(x%2Cy)\\log p(x|y).} Because entropy can be conditioned on a random variable or on that random variable being a certain value%2C care should be taken not to confuse these two definitions of conditional entropy%2C the former of which is in more common use. A basic property of this form of conditional entropy is that%3A H ( X | Y ) %3D H ( X %2C Y ) H ( Y ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle H(X|Y)%3DH(X%2CY)-H(Y).\\%2C} Mutual information (transinformation) [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D7\" title%3D\"Edit section%3A Mutual information (transinformation)\">edit ] <%24cheerio1 href%3D\"%2Fwiki%2FMutual_information\" title%3D\"Mutual information\">Mutual information measures the amount of information that can be obtained about one random variable by observing another. It is important in communication where it can be used to maximize the amount of information shared between sent and received signals. The mutual information of X relative to Y is given by%3A I ( X %3B Y ) %3D E X %2C Y [ S I ( x %2C y ) ] %3D x %2C y p ( x %2C y ) log p ( x %2C y ) p ( x ) p ( y ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle I(X%3BY)%3D\\mathbb {E} _{X%2CY}[SI(x%2Cy)]%3D\\sum _{x%2Cy}p(x%2Cy)\\log {\\frac {p(x%2Cy)}{p(x)\\%2Cp(y)}}} where SI (Specific mutual Information) is the <%24cheerio1 href%3D\"%2Fwiki%2FPointwise_mutual_information\" title%3D\"Pointwise mutual information\">pointwise mutual information . A basic property of the mutual information is that I ( X %3B Y ) %3D H ( X ) H ( X | Y ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle I(X%3BY)%3DH(X)-H(X|Y).\\%2C} That is%2C knowing Y%2C we can save an average of I(X%3B Y) bits in encoding X compared to not knowing Y. Mutual information is <%24cheerio1 href%3D\"%2Fwiki%2FSymmetric_function\" title%3D\"Symmetric function\">symmetric %3A I ( X %3B Y ) %3D I ( Y %3B X ) %3D H ( X ) %2B H ( Y ) H ( X %2C Y ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle I(X%3BY)%3DI(Y%3BX)%3DH(X)%2BH(Y)-H(X%2CY).\\%2C} Mutual information can be expressed as the average Kullback Leibler divergence (information gain) between the <%24cheerio1 href%3D\"%2Fwiki%2FPosterior_probability\" title%3D\"Posterior probability\">posterior probability distribution of X given the value of Y and the <%24cheerio1 href%3D\"%2Fwiki%2FPrior_probability\" title%3D\"Prior probability\">prior distribution on X%3A I ( X %3B Y ) %3D E p ( y ) [ D K L ( p ( X | Y %3D y ) p ( X ) ) ] . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle I(X%3BY)%3D\\mathbb {E} _{p(y)}[D_{\\mathrm {KL} }(p(X|Y%3Dy)\\|p(X))].} In other words%2C this is a measure of how much%2C on the average%2C the probability distribution on X will change if we are given the value of Y. This is often recalculated as the divergence from the product of the marginal distributions to the actual joint distribution%3A I ( X %3B Y ) %3D D K L ( p ( X %2C Y ) p ( X ) p ( Y ) ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle I(X%3BY)%3DD_{\\mathrm {KL} }(p(X%2CY)\\|p(X)p(Y)).} Mutual information is closely related to the <%24cheerio1 href%3D\"%2Fwiki%2FLikelihood-ratio_test\" title%3D\"Likelihood-ratio test\">log-likelihood ratio test in the context of contingency tables and the <%24cheerio1 href%3D\"%2Fwiki%2FMultinomial_distribution\" title%3D\"Multinomial distribution\">multinomial distribution and to <%24cheerio1 href%3D\"%2Fwiki%2FPearson%27s_chi-squared_test\" title%3D\"Pearson's chi-squared test\">Pearson's χ2 test %3A mutual information can be considered a statistic for assessing independence between a pair of variables%2C and has a well-specified asymptotic distribution. Kullback Leibler divergence (information gain) [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D8\" title%3D\"Edit section%3A Kullback Leibler divergence (information gain)\">edit ] The <%24cheerio1 href%3D\"%2Fwiki%2FKullback%E2%80%93Leibler_divergence\" title%3D\"Kullback Leibler divergence\">Kullback Leibler divergence (or information divergence%2C information gain%2C or relative entropy) is a way of comparing two distributions%3A a \"true\" <%24cheerio1 href%3D\"%2Fwiki%2FProbability_distribution\" title%3D\"Probability distribution\">probability distribution p ( X ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle p(X)} %2C and an arbitrary probability distribution q ( X ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle q(X)} . If we compress data in a manner that assumes q ( X ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle q(X)} is the distribution underlying some data%2C when%2C in reality%2C p ( X ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle p(X)} is the correct distribution%2C the Kullback Leibler divergence is the number of average additional bits per datum necessary for compression. It is thus defined D K L ( p ( X ) q ( X ) ) %3D x X p ( x ) log q ( x ) x X p ( x ) log p ( x ) %3D x X p ( x ) log p ( x ) q ( x ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle D_{\\mathrm {KL} }(p(X)\\|q(X))%3D\\sum _{x\\in X}-p(x)\\log {q(x)}\\%2C-\\%2C\\sum _{x\\in X}-p(x)\\log {p(x)}%3D\\sum _{x\\in X}p(x)\\log {\\frac {p(x)}{q(x)}}.} Although it is sometimes used as a 'distance metric'%2C KL divergence is not a true <%24cheerio1 href%3D\"%2Fwiki%2FMetric_(mathematics)\" title%3D\"Metric (mathematics)\">metric since it is not symmetric and does not satisfy the <%24cheerio1 href%3D\"%2Fwiki%2FTriangle_inequality\" title%3D\"Triangle inequality\">triangle inequality (making it a semi-quasimetric). Another interpretation of the KL divergence is the \"unnecessary surprise\" introduced by a prior from the truth%3A suppose a number X is about to be drawn randomly from a discrete set with probability distribution p ( x ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle p(x)} . If Alice knows the true distribution p ( x ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle p(x)} %2C while Bob believes (has a <%24cheerio1 href%3D\"%2Fwiki%2FPrior_probability\" title%3D\"Prior probability\">prior ) that the distribution is q ( x ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle q(x)} %2C then Bob will be more <%24cheerio1 href%3D\"%2Fwiki%2FInformation_content\" title%3D\"Information content\">surprised than Alice%2C on average%2C upon seeing the value of X. The KL divergence is the (objective) expected value of Bob's (subjective) surprisal minus Alice's surprisal%2C measured in bits if the log is in base 2. In this way%2C the extent to which Bob's prior is \"wrong\" can be quantified in terms of how \"unnecessarily surprised\" it is expected to make him. Other quantities [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D9\" title%3D\"Edit section%3A Other quantities\">edit ] Other important information theoretic quantities include <%24cheerio1 href%3D\"%2Fwiki%2FR%C3%A9nyi_entropy\" title%3D\"Rényi entropy\">Rényi entropy (a generalization of entropy)%2C <%24cheerio1 href%3D\"%2Fwiki%2FDifferential_entropy\" title%3D\"Differential entropy\">differential entropy (a generalization of quantities of information to continuous distributions)%2C and the <%24cheerio1 href%3D\"%2Fwiki%2FConditional_mutual_information\" title%3D\"Conditional mutual information\">conditional mutual information . Coding theory [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D10\" title%3D\"Edit section%3A Coding theory\">edit ] Main article%3A <%24cheerio1 href%3D\"%2Fwiki%2FCoding_theory\" title%3D\"Coding theory\">Coding theory <%24cheerio1 href%3D\"%2Fwiki%2FFile%3ACDSCRATCHES.jpg\" class%3D\"image\"> <%24cheerio1 href%3D\"%2Fwiki%2FFile%3ACDSCRATCHES.jpg\" class%3D\"internal\" title%3D\"Enlarge\"> A picture showing scratches on the readable surface of a CD-R. Music and data CDs are coded using error correcting codes and thus can still be read even if they have minor scratches using <%24cheerio1 href%3D\"%2Fwiki%2FError_detection_and_correction\" title%3D\"Error detection and correction\">error detection and correction . Coding theory is one of the most important and direct applications of information theory. It can be subdivided into <%24cheerio1 href%3D\"%2Fwiki%2FData_compression\" title%3D\"Data compression\">source coding theory and channel coding theory. Using a statistical description for data%2C information theory quantifies the number of bits needed to describe the data%2C which is the information entropy of the source. Data compression (source coding)%3A There are two formulations for the compression problem%3A <%24cheerio1 href%3D\"%2Fwiki%2FLossless_data_compression\" class%3D\"mw-redirect\" title%3D\"Lossless data compression\">lossless data compression %3A the data must be reconstructed exactly%3B <%24cheerio1 href%3D\"%2Fwiki%2FLossy_data_compression\" class%3D\"mw-redirect\" title%3D\"Lossy data compression\">lossy data compression %3A allocates bits needed to reconstruct the data%2C within a specified fidelity level measured by a distortion function. This subset of information theory is called <%24cheerio1 href%3D\"%2Fwiki%2FRate%E2%80%93distortion_theory\" title%3D\"Rate distortion theory\">rate distortion theory . Error-correcting codes (channel coding)%3A While data compression removes as much redundancy as possible%2C an error-correcting code adds just the right kind of redundancy (i.e.%2C error correction) needed to transmit the data efficiently and faithfully across a noisy channel. This division of coding theory into compression and transmission is justified by the information transmission theorems%2C or source channel separation theorems that justify the use of bits as the universal currency for information in many contexts. However%2C these theorems only hold in the situation where one transmitting user wishes to communicate to one receiving user. In scenarios with more than one transmitter (the multiple-access channel)%2C more than one receiver (the <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DBroadcast_channel%26action%3Dedit%26redlink%3D1\" class%3D\"new\" title%3D\"Broadcast channel (page does not exist)\">broadcast channel ) or intermediary \"helpers\" (the <%24cheerio1 href%3D\"%2Fwiki%2FRelay_channel\" title%3D\"Relay channel\">relay channel )%2C or more general <%24cheerio1 href%3D\"%2Fwiki%2FComputer_network\" title%3D\"Computer network\">networks %2C compression followed by transmission may no longer be optimal. <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DNetwork_information_theory%26action%3Dedit%26redlink%3D1\" class%3D\"new\" title%3D\"Network information theory (page does not exist)\">Network information theory refers to these multi-agent communication models. Source theory [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D11\" title%3D\"Edit section%3A Source theory\">edit ] Any process that generates successive messages can be considered a <%24cheerio1 href%3D\"%2Fwiki%2FCommunication_source\" title%3D\"Communication source\">source of information. A memoryless source is one in which each message is an <%24cheerio1 href%3D\"%2Fwiki%2FIndependent_identically_distributed_random_variables\" class%3D\"mw-redirect\" title%3D\"Independent identically distributed random variables\">independent identically distributed random variable %2C whereas the properties of <%24cheerio1 href%3D\"%2Fwiki%2FErgodic_theory\" title%3D\"Ergodic theory\">ergodicity and <%24cheerio1 href%3D\"%2Fwiki%2FStationary_process\" title%3D\"Stationary process\">stationarity impose less restrictive constraints. All such sources are <%24cheerio1 href%3D\"%2Fwiki%2FStochastic_process\" title%3D\"Stochastic process\">stochastic . These terms are well studied in their own right outside information theory. Rate [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D12\" title%3D\"Edit section%3A Rate\">edit ] Information <%24cheerio1 href%3D\"%2Fwiki%2FEntropy_rate\" title%3D\"Entropy rate\">rate is the average entropy per symbol. For memoryless sources%2C this is merely the entropy of each symbol%2C while%2C in the case of a stationary stochastic process%2C it is r %3D lim n H ( X n | X n 1 %2C X n 2 %2C X n 3 %2C … ) %3B <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle r%3D\\lim _{n\\to \\infty }H(X_{n}|X_{n-1}%2CX_{n-2}%2CX_{n-3}%2C\\ldots )%3B} that is%2C the conditional entropy of a symbol given all the previous symbols generated. For the more general case of a process that is not necessarily stationary%2C the average rate is r %3D lim n 1 n H ( X 1 %2C X 2 %2C … X n ) %3B <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle r%3D\\lim _{n\\to \\infty }{\\frac {1}{n}}H(X_{1}%2CX_{2}%2C\\dots X_{n})%3B} that is%2C the limit of the joint entropy per symbol. For stationary sources%2C these two expressions give the same result. <%24cheerio1 href%3D\"%23cite_note-11\">[11] Information rate is defined as r %3D lim n 1 n I ( X 1 %2C X 2 %2C … X n %3B Y 1 %2C Y 2 %2C … Y n ) %3B <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle r%3D\\lim _{n\\to \\infty }{\\frac {1}{n}}I(X_{1}%2CX_{2}%2C\\dots X_{n}%3BY_{1}%2CY_{2}%2C\\dots Y_{n})%3B} It is common in information theory to speak of the \"rate\" or \"entropy\" of a language. This is appropriate%2C for example%2C when the source of information is English prose. The rate of a source of information is related to its redundancy and how well it can be compressed%2C the subject of source coding. Channel capacity [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D13\" title%3D\"Edit section%3A Channel capacity\">edit ] Main article%3A <%24cheerio1 href%3D\"%2Fwiki%2FChannel_capacity\" title%3D\"Channel capacity\">Channel capacity Communications over a channel such as an <%24cheerio1 href%3D\"%2Fwiki%2FEthernet\" title%3D\"Ethernet\">ethernet cable is the primary motivation of information theory. However%2C such channels often fail to produce exact reconstruction of a signal%3B noise%2C periods of silence%2C and other forms of signal corruption often degrade quality. Consider the communications process over a discrete channel. A simple model of the process is shown below%3A Message W Encoder f n E n c o d e d s e q u e n c e X n Channel p ( y | x ) R e c e i v e d s e q u e n c e Y n Decoder g n E s t i m a t e d m e s s a g e W ^ <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle {\\xrightarrow[{\\text{Message}}]{W}}{\\begin{array}{|c| }\\hline {\\text{Encoder}}\\\\f_{n}\\\\\\hline \\end{array}}{\\xrightarrow[{\\mathrm {Encoded \\atop sequence} }]{X^{n}}}{\\begin{array}{|c| }\\hline {\\text{Channel}}\\\\p(y|x)\\\\\\hline \\end{array}}{\\xrightarrow[{\\mathrm {Received \\atop sequence} }]{Y^{n}}}{\\begin{array}{|c| }\\hline {\\text{Decoder}}\\\\g_{n}\\\\\\hline \\end{array}}{\\xrightarrow[{\\mathrm {Estimated \\atop message} }]{\\hat {W}}}} Here X represents the space of messages transmitted%2C and Y the space of messages received during a unit time over our channel. Let p(y|x) be the <%24cheerio1 href%3D\"%2Fwiki%2FConditional_probability\" title%3D\"Conditional probability\">conditional probability distribution function of Y given X. We will consider p(y|x) to be an inherent fixed property of our communications channel (representing the nature of the <%24cheerio1 href%3D\"%2Fwiki%2FSignal_noise\" class%3D\"mw-redirect\" title%3D\"Signal noise\">noise of our channel). Then the joint distribution of X and Y is completely determined by our channel and by our choice of f(x)%2C the marginal distribution of messages we choose to send over the channel. Under these constraints%2C we would like to maximize the rate of information%2C or the <%24cheerio1 href%3D\"%2Fwiki%2FSignal_(electrical_engineering)\" class%3D\"mw-redirect\" title%3D\"Signal (electrical engineering)\">signal %2C we can communicate over the channel. The appropriate measure for this is the mutual information%2C and this maximum mutual information is called the channel capacity and is given by%3A C %3D max f I ( X %3B Y ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle C%3D\\max _{f}I(X%3BY).\\!} This capacity has the following property related to communicating at information rate R (where R is usually bits per symbol). For any information rate R < C and coding error ε > 0%2C for large enough N%2C there exists a code of length N and rate R and a decoding algorithm%2C such that the maximal probability of block error is ε%3B that is%2C it is always possible to transmit with arbitrarily small block error. In addition%2C for any rate R > C%2C it is impossible to transmit with arbitrarily small block error. <%24cheerio1 href%3D\"%2Fwiki%2FChannel_code\" class%3D\"mw-redirect\" title%3D\"Channel code\">Channel coding is concerned with finding such nearly optimal codes that can be used to transmit data over a noisy channel with a small coding error at a rate near the channel capacity. Capacity of particular channel models [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D14\" title%3D\"Edit section%3A Capacity of particular channel models\">edit ] A continuous-time analog communications channel subject to <%24cheerio1 href%3D\"%2Fwiki%2FGaussian_noise\" title%3D\"Gaussian noise\">Gaussian noise see <%24cheerio1 href%3D\"%2Fwiki%2FShannon%E2%80%93Hartley_theorem\" title%3D\"Shannon Hartley theorem\">Shannon Hartley theorem . A <%24cheerio1 href%3D\"%2Fwiki%2FBinary_symmetric_channel\" title%3D\"Binary symmetric channel\">binary symmetric channel (BSC) with crossover probability p is a binary input%2C binary output channel that flips the input bit with probability p. The BSC has a capacity of 1 Hb(p) bits per channel use%2C where Hb is the binary entropy function to the base-2 logarithm%3A <%24cheerio1 href%3D\"%2Fwiki%2FFile%3ABinary_symmetric_channel.svg\" class%3D\"image\"> A <%24cheerio1 href%3D\"%2Fwiki%2FBinary_erasure_channel\" title%3D\"Binary erasure channel\">binary erasure channel (BEC) with erasure probability p is a binary input%2C ternary output channel. The possible channel outputs are 0%2C 1%2C and a third symbol 'e' called an erasure. The erasure represents complete loss of information about an input bit. The capacity of the BEC is 1 p bits per channel use. <%24cheerio1 href%3D\"%2Fwiki%2FFile%3ABinary_erasure_channel.svg\" class%3D\"image\"> Channels with memory and dircted infomation [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D15\" title%3D\"Edit section%3A Channels with memory and dircted infomation\">edit ] In practice many channels have memory. Namely%2C at time i <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle i} the channel is given by the condiation probability P ( y i | x i %2C x i 1 %2C x 1 2 %2C . . . %2C x 1 %2C y i 1 %2C y 1 2 %2C . . . %2C y 1 ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle P(y_{i}|x_{i}%2Cx_{i-1}%2Cx_{1-2}%2C...%2Cx_{1}%2Cy_{i-1}%2Cy_{1-2}%2C...%2Cy_{1}).} . It is often more coomfortble to use the notation x i %3D ( x i %2C x i 1 %2C x 1 2 %2C . . . %2C x 1 ) <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle x^{i}%3D(x_{i}%2Cx_{i-1}%2Cx_{1-2}%2C...%2Cx_{1})} and the channel become P ( y i | x i %2C y i 1 ) . <%24cheerio1nnotation encoding%3D\"application%2Fx-tex\">{\\displaystyle P(y_{i}|x^{i}%2Cy^{i-1}).} . In such a case the capacity is given by the <%24cheerio1 href%3D\"%2Fwiki%2FMutual_information\" title%3D\"Mutual information\">Mutual information rate when there is no feedback availble and the <%24cheerio1 href%3D\"%2Fwiki%2FDirected_information\" title%3D\"Directed information\">Directed information rate in the case that either there is feedback or not <%24cheerio1 href%3D\"%23cite_note-12\">[12] <%24cheerio1 href%3D\"%23cite_note-13\">[13] (if there is no feedback the dircted informationj equals the mutual information). Applications to other fields [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D16\" title%3D\"Edit section%3A Applications to other fields\">edit ] Intelligence uses and secrecy applications [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D17\" title%3D\"Edit section%3A Intelligence uses and secrecy applications\">edit ] Information theoretic concepts apply to cryptography and cryptanalysis. Turing's information unit%2C the <%24cheerio1 href%3D\"%2Fwiki%2FBan_(unit)\" class%3D\"mw-redirect\" title%3D\"Ban (unit)\">ban %2C was used in the <%24cheerio1 href%3D\"%2Fwiki%2FUltra\" title%3D\"Ultra\">Ultra project%2C breaking the German <%24cheerio1 href%3D\"%2Fwiki%2FEnigma_machine\" title%3D\"Enigma machine\">Enigma machine code and hastening the <%24cheerio1 href%3D\"%2Fwiki%2FVictory_in_Europe_Day\" title%3D\"Victory in Europe Day\">end of World War II in Europe . Shannon himself defined an important concept now called the <%24cheerio1 href%3D\"%2Fwiki%2FUnicity_distance\" title%3D\"Unicity distance\">unicity distance . Based on the redundancy of the <%24cheerio1 href%3D\"%2Fwiki%2FPlaintext\" title%3D\"Plaintext\">plaintext %2C it attempts to give a minimum amount of <%24cheerio1 href%3D\"%2Fwiki%2FCiphertext\" title%3D\"Ciphertext\">ciphertext necessary to ensure unique decipherability. Information theory leads us to believe it is much more difficult to keep secrets than it might first appear. A <%24cheerio1 href%3D\"%2Fwiki%2FBrute_force_attack\" class%3D\"mw-redirect\" title%3D\"Brute force attack\">brute force attack can break systems based on <%24cheerio1 href%3D\"%2Fwiki%2FPublic-key_cryptography\" title%3D\"Public-key cryptography\">asymmetric key algorithms or on most commonly used methods of <%24cheerio1 href%3D\"%2Fwiki%2FSymmetric-key_algorithm\" title%3D\"Symmetric-key algorithm\">symmetric key algorithms (sometimes called secret key algorithms)%2C such as <%24cheerio1 href%3D\"%2Fwiki%2FBlock_cipher\" title%3D\"Block cipher\">block ciphers . The security of all such methods currently comes from the assumption that no known attack can break them in a practical amount of time. <%24cheerio1 href%3D\"%2Fwiki%2FInformation_theoretic_security\" class%3D\"mw-redirect\" title%3D\"Information theoretic security\">Information theoretic security refers to methods such as the <%24cheerio1 href%3D\"%2Fwiki%2FOne-time_pad\" title%3D\"One-time pad\">one-time pad that are not vulnerable to such brute force attacks. In such cases%2C the positive conditional mutual information between the plaintext and ciphertext (conditioned on the <%24cheerio1 href%3D\"%2Fwiki%2FKey_(cryptography)\" title%3D\"Key (cryptography)\">key ) can ensure proper transmission%2C while the unconditional mutual information between the plaintext and ciphertext remains zero%2C resulting in absolutely secure communications. In other words%2C an eavesdropper would not be able to improve his or her guess of the plaintext by gaining knowledge of the ciphertext but not of the key. However%2C as in any other cryptographic system%2C care must be used to correctly apply even information-theoretically secure methods%3B the <%24cheerio1 href%3D\"%2Fwiki%2FVenona_project\" title%3D\"Venona project\">Venona project was able to crack the one-time pads of the Soviet Union due to their improper reuse of key material. Pseudorandom number generation [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D18\" title%3D\"Edit section%3A Pseudorandom number generation\">edit ] <%24cheerio1 href%3D\"%2Fwiki%2FPseudorandom_number_generator\" title%3D\"Pseudorandom number generator\">Pseudorandom number generators are widely available in computer language libraries and application programs. They are%2C almost universally%2C unsuited to cryptographic use as they do not evade the deterministic nature of modern computer equipment and software. A class of improved random number generators is termed <%24cheerio1 href%3D\"%2Fwiki%2FCryptographically_secure_pseudorandom_number_generator\" title%3D\"Cryptographically secure pseudorandom number generator\">cryptographically secure pseudorandom number generators %2C but even they require <%24cheerio1 href%3D\"%2Fwiki%2FRandom_seed\" title%3D\"Random seed\">random seeds external to the software to work as intended. These can be obtained via <%24cheerio1 href%3D\"%2Fwiki%2FExtractor_(mathematics)\" title%3D\"Extractor (mathematics)\">extractors %2C if done carefully. The measure of sufficient randomness in extractors is <%24cheerio1 href%3D\"%2Fwiki%2FMin-entropy\" title%3D\"Min-entropy\">min-entropy %2C a value related to Shannon entropy through <%24cheerio1 href%3D\"%2Fwiki%2FR%C3%A9nyi_entropy\" title%3D\"Rényi entropy\">Rényi entropy %3B Rényi entropy is also used in evaluating randomness in cryptographic systems. Although related%2C the distinctions among these measures mean that a random variable with high Shannon entropy is not necessarily satisfactory for use in an extractor and so for cryptography uses. Seismic exploration [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D19\" title%3D\"Edit section%3A Seismic exploration\">edit ] One early commercial application of information theory was in the field of seismic oil exploration. Work in this field made it possible to strip off and separate the unwanted noise from the desired seismic signal. Information theory and <%24cheerio1 href%3D\"%2Fwiki%2FDigital_signal_processing\" title%3D\"Digital signal processing\">digital signal processing offer a major improvement of resolution and image clarity over previous analog methods. <%24cheerio1 href%3D\"%23cite_note-14\">[14] Semiotics [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D20\" title%3D\"Edit section%3A Semiotics\">edit ] <%24cheerio1 href%3D\"%2Fwiki%2FSemiotics\" title%3D\"Semiotics\">Semioticians <%24cheerio1 href%3D\"https%3A%2F%2Fnl.wikipedia.org%2Fwiki%2FDoede_Nauta\" class%3D\"extiw\" title%3D\"nl%3ADoede Nauta\">Doede Nauta and <%24cheerio1 href%3D\"%2Fwiki%2FWinfried_N%C3%B6th\" title%3D\"Winfried Nöth\">Winfried Nöth both considered <%24cheerio1 href%3D\"%2Fwiki%2FCharles_Sanders_Peirce\" title%3D\"Charles Sanders Peirce\">Charles Sanders Peirce as having created a theory of information in his works on semiotics. <%24cheerio1 href%3D\"%23cite_note-Nauta_1972-15\">[15] %3A 171 <%24cheerio1 href%3D\"%23cite_note-Nöth_2012-16\">[16] %3A 137 Nauta defined semiotic information theory as the study of \"the internal processes of coding%2C filtering%2C and information processing.\" <%24cheerio1 href%3D\"%23cite_note-Nauta_1972-15\">[15] %3A 91 Concepts from information theory such as redundancy and code control have been used by semioticians such as <%24cheerio1 href%3D\"%2Fwiki%2FUmberto_Eco\" title%3D\"Umberto Eco\">Umberto Eco and <%24cheerio1 href%3D\"https%3A%2F%2Fit.wikipedia.org%2Fwiki%2FFerruccio_Rossi-Landi\" class%3D\"extiw\" title%3D\"it%3AFerruccio Rossi-Landi\">Ferruccio Rossi-Landi to explain ideology as a form of message transmission whereby a dominant social class emits its message by using signs that exhibit a high degree of redundancy such that only one message is decoded among a selection of competing ones. <%24cheerio1 href%3D\"%23cite_note-17\">[17] Miscellaneous applications [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D21\" title%3D\"Edit section%3A Miscellaneous applications\">edit ] Information theory also has applications in <%24cheerio1 href%3D\"%2Fwiki%2FGambling_and_information_theory\" title%3D\"Gambling and information theory\">Gambling and information theory %2C <%24cheerio1 href%3D\"%2Fwiki%2FBlack_hole_information_paradox\" title%3D\"Black hole information paradox\">black holes %2C and <%24cheerio1 href%3D\"%2Fwiki%2FBioinformatics\" title%3D\"Bioinformatics\">bioinformatics . See also [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D22\" title%3D\"Edit section%3A See also\">edit ] <%24cheerio1 href%3D\"%2Fwiki%2FFile%3ANuvola_apps_edu_mathematics_blue-p.svg\" class%3D\"image\"> <%24cheerio1 href%3D\"%2Fwiki%2FPortal%3AMathematics\" title%3D\"Portal%3AMathematics\">Mathematics portal <%24cheerio1 href%3D\"%2Fwiki%2FAlgorithmic_probability\" title%3D\"Algorithmic probability\">Algorithmic probability <%24cheerio1 href%3D\"%2Fwiki%2FBayesian_inference\" title%3D\"Bayesian inference\">Bayesian inference <%24cheerio1 href%3D\"%2Fwiki%2FCommunication_theory\" title%3D\"Communication theory\">Communication theory <%24cheerio1 href%3D\"%2Fwiki%2FConstructor_theory\" title%3D\"Constructor theory\">Constructor theory - a generalization of information theory that includes quantum information <%24cheerio1 href%3D\"%2Fwiki%2FInductive_probability\" title%3D\"Inductive probability\">Inductive probability <%24cheerio1 href%3D\"%2Fwiki%2FInfo-metrics\" title%3D\"Info-metrics\">Info-metrics <%24cheerio1 href%3D\"%2Fwiki%2FMinimum_message_length\" title%3D\"Minimum message length\">Minimum message length <%24cheerio1 href%3D\"%2Fwiki%2FMinimum_description_length\" title%3D\"Minimum description length\">Minimum description length <%24cheerio1 href%3D\"%2Fwiki%2FList_of_important_publications_in_theoretical_computer_science%23Information_theory\" title%3D\"List of important publications in theoretical computer science\">List of important publications <%24cheerio1 href%3D\"%2Fwiki%2FPhilosophy_of_information\" title%3D\"Philosophy of information\">Philosophy of information Applications [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D23\" title%3D\"Edit section%3A Applications\">edit ] <%24cheerio1 href%3D\"%2Fwiki%2FActive_networking\" title%3D\"Active networking\">Active networking <%24cheerio1 href%3D\"%2Fwiki%2FCryptanalysis\" title%3D\"Cryptanalysis\">Cryptanalysis <%24cheerio1 href%3D\"%2Fwiki%2FCryptography\" title%3D\"Cryptography\">Cryptography <%24cheerio1 href%3D\"%2Fwiki%2FCybernetics\" title%3D\"Cybernetics\">Cybernetics <%24cheerio1 href%3D\"%2Fwiki%2FEntropy_in_thermodynamics_and_information_theory\" title%3D\"Entropy in thermodynamics and information theory\">Entropy in thermodynamics and information theory <%24cheerio1 href%3D\"%2Fwiki%2FGambling\" title%3D\"Gambling\">Gambling <%24cheerio1 href%3D\"%2Fwiki%2FIntelligence_(information_gathering)\" class%3D\"mw-redirect\" title%3D\"Intelligence (information gathering)\">Intelligence (information gathering) <%24cheerio1 href%3D\"%2Fwiki%2FReflection_seismology\" title%3D\"Reflection seismology\">Seismic exploration History [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D24\" title%3D\"Edit section%3A History\">edit ] <%24cheerio1 href%3D\"%2Fwiki%2FRalph_Hartley\" title%3D\"Ralph Hartley\">Hartley%2C R.V.L. <%24cheerio1 href%3D\"%2Fwiki%2FHistory_of_information_theory\" title%3D\"History of information theory\">History of information theory <%24cheerio1 href%3D\"%2Fwiki%2FClaude_Elwood_Shannon\" class%3D\"mw-redirect\" title%3D\"Claude Elwood Shannon\">Shannon%2C C.E. <%24cheerio1 href%3D\"%2Fwiki%2FTimeline_of_information_theory\" title%3D\"Timeline of information theory\">Timeline of information theory <%24cheerio1 href%3D\"%2Fwiki%2FHubert_Yockey\" title%3D\"Hubert Yockey\">Yockey%2C H.P. Theory [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D25\" title%3D\"Edit section%3A Theory\">edit ] <%24cheerio1 href%3D\"%2Fwiki%2FCoding_theory\" title%3D\"Coding theory\">Coding theory <%24cheerio1 href%3D\"%2Fwiki%2FDetection_theory\" title%3D\"Detection theory\">Detection theory <%24cheerio1 href%3D\"%2Fwiki%2FEstimation_theory\" title%3D\"Estimation theory\">Estimation theory <%24cheerio1 href%3D\"%2Fwiki%2FFisher_information\" title%3D\"Fisher information\">Fisher information <%24cheerio1 href%3D\"%2Fwiki%2FInformation_algebra\" title%3D\"Information algebra\">Information algebra <%24cheerio1 href%3D\"%2Fwiki%2FInformation_asymmetry\" title%3D\"Information asymmetry\">Information asymmetry <%24cheerio1 href%3D\"%2Fwiki%2FInformation_field_theory\" title%3D\"Information field theory\">Information field theory <%24cheerio1 href%3D\"%2Fwiki%2FInformation_geometry\" title%3D\"Information geometry\">Information geometry <%24cheerio1 href%3D\"%2Fwiki%2FInformation_theory_and_measure_theory\" title%3D\"Information theory and measure theory\">Information theory and measure theory <%24cheerio1 href%3D\"%2Fwiki%2FKolmogorov_complexity\" title%3D\"Kolmogorov complexity\">Kolmogorov complexity <%24cheerio1 href%3D\"%2Fwiki%2FList_of_unsolved_problems_in_information_theory\" title%3D\"List of unsolved problems in information theory\">List of unsolved problems in information theory <%24cheerio1 href%3D\"%2Fwiki%2FLogic_of_information\" title%3D\"Logic of information\">Logic of information <%24cheerio1 href%3D\"%2Fwiki%2FNetwork_coding\" class%3D\"mw-redirect\" title%3D\"Network coding\">Network coding <%24cheerio1 href%3D\"%2Fwiki%2FPhilosophy_of_information\" title%3D\"Philosophy of information\">Philosophy of information <%24cheerio1 href%3D\"%2Fwiki%2FQuantum_information_science\" title%3D\"Quantum information science\">Quantum information science <%24cheerio1 href%3D\"%2Fwiki%2FSource_coding\" class%3D\"mw-redirect\" title%3D\"Source coding\">Source coding Concepts [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D26\" title%3D\"Edit section%3A Concepts\">edit ] <%24cheerio1 href%3D\"%2Fwiki%2FBan_(unit)\" class%3D\"mw-redirect\" title%3D\"Ban (unit)\">Ban (unit) <%24cheerio1 href%3D\"%2Fwiki%2FChannel_capacity\" title%3D\"Channel capacity\">Channel capacity <%24cheerio1 href%3D\"%2Fwiki%2FCommunication_channel\" title%3D\"Communication channel\">Communication channel <%24cheerio1 href%3D\"%2Fwiki%2FCommunication_source\" title%3D\"Communication source\">Communication source <%24cheerio1 href%3D\"%2Fwiki%2FConditional_entropy\" title%3D\"Conditional entropy\">Conditional entropy <%24cheerio1 href%3D\"%2Fwiki%2FCovert_channel\" title%3D\"Covert channel\">Covert channel <%24cheerio1 href%3D\"%2Fwiki%2FData_compression\" title%3D\"Data compression\">Data compression Decoder <%24cheerio1 href%3D\"%2Fwiki%2FDifferential_entropy\" title%3D\"Differential entropy\">Differential entropy <%24cheerio1 href%3D\"%2Fwiki%2FFungible_information\" title%3D\"Fungible information\">Fungible information <%24cheerio1 href%3D\"%2Fwiki%2FInformation_fluctuation_complexity\" title%3D\"Information fluctuation complexity\">Information fluctuation complexity <%24cheerio1 href%3D\"%2Fwiki%2FInformation_entropy\" class%3D\"mw-redirect\" title%3D\"Information entropy\">Information entropy <%24cheerio1 href%3D\"%2Fwiki%2FJoint_entropy\" title%3D\"Joint entropy\">Joint entropy <%24cheerio1 href%3D\"%2Fwiki%2FKullback%E2%80%93Leibler_divergence\" title%3D\"Kullback Leibler divergence\">Kullback Leibler divergence <%24cheerio1 href%3D\"%2Fwiki%2FMutual_information\" title%3D\"Mutual information\">Mutual information <%24cheerio1 href%3D\"%2Fwiki%2FPointwise_mutual_information\" title%3D\"Pointwise mutual information\">Pointwise mutual information (PMI) <%24cheerio1 href%3D\"%2Fwiki%2FReceiver_(information_theory)\" title%3D\"Receiver (information theory)\">Receiver (information theory) <%24cheerio1 href%3D\"%2Fwiki%2FRedundancy_(information_theory)\" title%3D\"Redundancy (information theory)\">Redundancy <%24cheerio1 href%3D\"%2Fwiki%2FR%C3%A9nyi_entropy\" title%3D\"Rényi entropy\">Rényi entropy <%24cheerio1 href%3D\"%2Fwiki%2FSelf-information\" class%3D\"mw-redirect\" title%3D\"Self-information\">Self-information <%24cheerio1 href%3D\"%2Fwiki%2FUnicity_distance\" title%3D\"Unicity distance\">Unicity distance <%24cheerio1 href%3D\"%2Fwiki%2FVariety_(cybernetics)\" title%3D\"Variety (cybernetics)\">Variety <%24cheerio1 href%3D\"%2Fwiki%2FHamming_distance\" title%3D\"Hamming distance\">Hamming distance References [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D27\" title%3D\"Edit section%3A References\">edit ] <%24cheerio1 href%3D\"%23cite_ref-1\">^ Burnham%2C K. P. and Anderson D. R. (2002) Model Selection and Multimodel Inference%3A A Practical Information-Theoretic Approach%2C Second Edition (Springer Science%2C New York) <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F978-0-387-95364-9\" title%3D\"Special%3ABookSources%2F978-0-387-95364-9\">978-0-387-95364-9 . ^ <%24cheerio1 href%3D\"%23cite_ref-Spikes_2-0\">a <%24cheerio1 href%3D\"%23cite_ref-Spikes_2-1\">b F. Rieke%3B D. Warland%3B R Ruyter van Steveninck%3B W Bialek (1997). Spikes%3A Exploring the Neural Code. The MIT press. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F978-0262681087\" title%3D\"Special%3ABookSources%2F978-0262681087\">978-0262681087 . <%24cheerio1 href%3D\"%23cite_ref-3\">^ Delgado-Bonal%2C Alfonso%3B Martín-Torres%2C Javier (2016-11-03). <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5093619\">\"Human vision is determined based on information theory\" . Scientific Reports. 6 (1)%3A 36038. <%24cheerio1 href%3D\"%2Fwiki%2FBibcode_(identifier)\" class%3D\"mw-redirect\" title%3D\"Bibcode (identifier)\">Bibcode %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fui.adsabs.harvard.edu%2Fabs%2F2016NatSR...636038D\">2016NatSR...636038D . <%24cheerio1 href%3D\"%2Fwiki%2FDoi_(identifier)\" class%3D\"mw-redirect\" title%3D\"Doi (identifier)\">doi %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fdoi.org%2F10.1038%2Fsrep36038\">10.1038%2Fsrep36038 . <%24cheerio1 href%3D\"%2Fwiki%2FISSN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISSN (identifier)\">ISSN <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Fwww.worldcat.org%2Fissn%2F2045-2322\">2045-2322 . <%24cheerio1 href%3D\"%2Fwiki%2FPMC_(identifier)\" class%3D\"mw-redirect\" title%3D\"PMC (identifier)\">PMC <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5093619\">5093619 . <%24cheerio1 href%3D\"%2Fwiki%2FPMID_(identifier)\" class%3D\"mw-redirect\" title%3D\"PMID (identifier)\">PMID <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Fpubmed.ncbi.nlm.nih.gov%2F27808236\">27808236 . <%24cheerio1 href%3D\"%23cite_ref-4\">^ cf%3B Huelsenbeck%2C J. P.%3B Ronquist%2C F.%3B Nielsen%2C R.%3B Bollback%2C J. P. (2001). \"Bayesian inference of phylogeny and its impact on evolutionary biology\". Science. 294 (5550)%3A 2310 2314. <%24cheerio1 href%3D\"%2Fwiki%2FBibcode_(identifier)\" class%3D\"mw-redirect\" title%3D\"Bibcode (identifier)\">Bibcode %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fui.adsabs.harvard.edu%2Fabs%2F2001Sci...294.2310H\">2001Sci...294.2310H . <%24cheerio1 href%3D\"%2Fwiki%2FDoi_(identifier)\" class%3D\"mw-redirect\" title%3D\"Doi (identifier)\">doi %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fdoi.org%2F10.1126%2Fscience.1065889\">10.1126%2Fscience.1065889 . <%24cheerio1 href%3D\"%2Fwiki%2FPMID_(identifier)\" class%3D\"mw-redirect\" title%3D\"PMID (identifier)\">PMID <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Fpubmed.ncbi.nlm.nih.gov%2F11743192\">11743192 . <%24cheerio1 href%3D\"%2Fwiki%2FS2CID_(identifier)\" class%3D\"mw-redirect\" title%3D\"S2CID (identifier)\">S2CID <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A2138288\">2138288 . <%24cheerio1 href%3D\"%23cite_ref-5\">^ Allikmets%2C Rando%3B Wasserman%2C Wyeth W.%3B Hutchinson%2C Amy%3B Smallwood%2C Philip%3B Nathans%2C Jeremy%3B Rogan%2C Peter K. (1998). <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Falum.mit.edu%2Fwww%2Ftoms%2F\">\"Thomas D. Schneider]%2C Michael Dean (1998) Organization of the ABCR gene%3A analysis of promoter and splice junction sequences\" . Gene. 215 (1)%3A 111 122. <%24cheerio1 href%3D\"%2Fwiki%2FDoi_(identifier)\" class%3D\"mw-redirect\" title%3D\"Doi (identifier)\">doi %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fdoi.org%2F10.1016%2Fs0378-1119%2898%2900269-8\">10.1016%2Fs0378-1119(98)00269-8 . <%24cheerio1 href%3D\"%2Fwiki%2FPMID_(identifier)\" class%3D\"mw-redirect\" title%3D\"PMID (identifier)\">PMID <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Fpubmed.ncbi.nlm.nih.gov%2F9666097\">9666097 . <%24cheerio1 href%3D\"%23cite_ref-6\">^ Jaynes%2C E. T. (1957). <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fbayes.wustl.edu%2F\">\"Information Theory and Statistical Mechanics\" . Phys. Rev. 106 (4)%3A 620. <%24cheerio1 href%3D\"%2Fwiki%2FBibcode_(identifier)\" class%3D\"mw-redirect\" title%3D\"Bibcode (identifier)\">Bibcode %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fui.adsabs.harvard.edu%2Fabs%2F1957PhRv..106..620J\">1957PhRv..106..620J . <%24cheerio1 href%3D\"%2Fwiki%2FDoi_(identifier)\" class%3D\"mw-redirect\" title%3D\"Doi (identifier)\">doi %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fdoi.org%2F10.1103%2Fphysrev.106.620\">10.1103%2Fphysrev.106.620 . <%24cheerio1 href%3D\"%23cite_ref-7\">^ Bennett%2C Charles H.%3B Li%2C Ming%3B Ma%2C Bin (2003). <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fweb.archive.org%2Fweb%2F20071007041539%2Fhttp%3A%2F%2Fwww.sciamdigital.com%2Findex.cfm%3Ffa%3DProducts.ViewIssuePreview%26ARTICLEID_CHAR%3D08B64096-0772-4904-9D48227D5C9FAC75\">\"Chain Letters and Evolutionary Histories\" . Scientific American. 288 (6)%3A 76 81. <%24cheerio1 href%3D\"%2Fwiki%2FBibcode_(identifier)\" class%3D\"mw-redirect\" title%3D\"Bibcode (identifier)\">Bibcode %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fui.adsabs.harvard.edu%2Fabs%2F2003SciAm.288f..76B\">2003SciAm.288f..76B . <%24cheerio1 href%3D\"%2Fwiki%2FDoi_(identifier)\" class%3D\"mw-redirect\" title%3D\"Doi (identifier)\">doi %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fdoi.org%2F10.1038%2Fscientificamerican0603-76\">10.1038%2Fscientificamerican0603-76 . <%24cheerio1 href%3D\"%2Fwiki%2FPMID_(identifier)\" class%3D\"mw-redirect\" title%3D\"PMID (identifier)\">PMID <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Fpubmed.ncbi.nlm.nih.gov%2F12764940\">12764940 . Archived from <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fsciamdigital.com%2Findex.cfm%3Ffa%3DProducts.ViewIssuePreview%26ARTICLEID_CHAR%3D08B64096-0772-4904-9D48227D5C9FAC75\">the original on 2007-10-07 . Retrieved 2008-03-11. <%24cheerio1 href%3D\"%23cite_ref-8\">^ David R. Anderson (November 1%2C 2003). <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fweb.archive.org%2Fweb%2F20110723045720%2Fhttp%3A%2F%2Faicanderson2.home.comcast.net%2F~aicanderson2%2Fhome.pdf\">\"Some background on why people in the empirical sciences may want to better understand the information-theoretic methods\" (PDF). Archived from <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Faicanderson2.home.comcast.net%2F~aicanderson2%2Fhome.pdf\">the original (PDF) on July 23%2C 2011 . Retrieved 2010-06-23. <%24cheerio1 href%3D\"%23cite_ref-Reza_9-0\">^ Fazlollah M. Reza (1994) [1961]. <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DRtzpRAiX6OgC%26q%3Dintitle%3A%22An%2BIntroduction%2Bto%2BInformation%2BTheory%22%2B%2B%22entropy%2Bof%2Ba%2Bsimple%2Bsource%22%26pg%3DPA8\">An Introduction to Information Theory . Dover Publications%2C Inc.%2C New York. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-486-68210-2\" title%3D\"Special%3ABookSources%2F0-486-68210-2\">0-486-68210-2 . <%24cheerio1 href%3D\"%23cite_ref-Ash_10-0\">^ Robert B. Ash (1990) [1965]. <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DngZhvUfF0UIC%26q%3Dintitle%3Ainformation%2Bintitle%3Atheory%2Binauthor%3Aash%2Bconditional%2Buncertainty%26pg%3DPA16\">Information Theory . Dover Publications%2C Inc. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-486-66521-6\" title%3D\"Special%3ABookSources%2F0-486-66521-6\">0-486-66521-6 . <%24cheerio1 href%3D\"%23cite_ref-11\">^ Jerry D. Gibson (1998). <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DaqQ2Ry6spu0C%26q%3Dentropy-rate%2Bconditional%26pg%3DPA56\">Digital Compression for Multimedia%3A Principles and Standards . Morgan Kaufmann. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F1-55860-369-7\" title%3D\"Special%3ABookSources%2F1-55860-369-7\">1-55860-369-7 . <%24cheerio1 href%3D\"%23cite_ref-12\">^ Massey%2C James L. (1990). <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.36.5688\">\"Causality%2C Feedback And Directed Information\" . Cite journal requires |journal%3D ( <%24cheerio1 href%3D\"%2Fwiki%2FHelp%3ACS1_errors%23missing_periodical\" title%3D\"Help%3ACS1 errors\">help ) <%24cheerio1 href%3D\"%23cite_ref-13\">^ Permuter%2C Haim Henry%3B Weissman%2C Tsachy%3B Goldsmith%2C Andrea J. (February 2009). \"Finite State Channels With Time-Invariant Deterministic Feedback\". IEEE Transactions on Information Theory. 55 (2)%3A 644 662. <%24cheerio1 href%3D\"%2Fwiki%2FArXiv_(identifier)\" class%3D\"mw-redirect\" title%3D\"ArXiv (identifier)\">arXiv %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Farxiv.org%2Fabs%2Fcs%2F0608070\">cs%2F0608070 . <%24cheerio1 href%3D\"%2Fwiki%2FDoi_(identifier)\" class%3D\"mw-redirect\" title%3D\"Doi (identifier)\">doi %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fdoi.org%2F10.1109%2FTIT.2008.2009849\">10.1109%2FTIT.2008.2009849 . <%24cheerio1 href%3D\"%23cite_ref-14\">^ Haggerty%2C Patrick E. (1981). \"The corporation and innovation\". Strategic Management Journal. 2 (2)%3A 97 118. <%24cheerio1 href%3D\"%2Fwiki%2FDoi_(identifier)\" class%3D\"mw-redirect\" title%3D\"Doi (identifier)\">doi %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fdoi.org%2F10.1002%2Fsmj.4250020202\">10.1002%2Fsmj.4250020202 . ^ <%24cheerio1 href%3D\"%23cite_ref-Nauta_1972_15-0\">a <%24cheerio1 href%3D\"%23cite_ref-Nauta_1972_15-1\">b Nauta%2C Doede (1972). The Meaning of Information. The Hague%3A Mouton. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F9789027919960\" title%3D\"Special%3ABookSources%2F9789027919960\">9789027919960 . <%24cheerio1 href%3D\"%23cite_ref-Nöth_2012_16-0\">^ Nöth%2C Winfried (January 2012). <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fedisciplinas.usp.br%2Fmod%2Fresource%2Fview.php%3Fid%3D2311849\">\"Charles S. Peirce's theory of information%3A a theory of the growth of symbols and of knowledge\" . Cybernetics and Human Knowing. 19 (1 2)%3A 137 161. <%24cheerio1 href%3D\"%23cite_ref-17\">^ Nöth%2C Winfried (1981). \" <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fkobra.uni-kassel.de%2Fbitstream%2Fhandle%2F123456789%2F2014122246977%2Fsemi_2004_002.pdf%3Fsequence%3D1%26isAllowed%3Dy\">Semiotics of ideology \". Semiotica%2C Issue 148. The classic work [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D28\" title%3D\"Edit section%3A The classic work\">edit ] <%24cheerio1 href%3D\"%2Fwiki%2FClaude_Elwood_Shannon\" class%3D\"mw-redirect\" title%3D\"Claude Elwood Shannon\">Shannon%2C C.E. (1948)%2C \" <%24cheerio1 href%3D\"%2Fwiki%2FA_Mathematical_Theory_of_Communication\" title%3D\"A Mathematical Theory of Communication\">A Mathematical Theory of Communication \"%2C Bell System Technical Journal%2C 27%2C pp. 379 423 %26 623 656%2C July %26 October%2C 1948. <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fmath.harvard.edu%2F~ctm%2Fhome%2Ftext%2Fothers%2Fshannon%2Fentropy%2Fentropy.pdf\">PDF. <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fcm.bell-labs.com%2Fcm%2Fms%2Fwhat%2Fshannonday%2Fpaper.html\">Notes and other formats. R.V.L. Hartley%2C <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fwww.dotrose.com%2Fetext%2F90_Miscellaneous%2Ftransmission_of_information_1928b.pdf\">\"Transmission of Information\" %2C Bell System Technical Journal%2C July 1928 <%24cheerio1 href%3D\"%2Fwiki%2FAndrey_Kolmogorov\" title%3D\"Andrey Kolmogorov\">Andrey Kolmogorov (1968)%2C \" <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2Fpdf%2F10.1080%2F00207166808803030\">Three approaches to the quantitative definition of information \" in International Journal of Computer Mathematics. Other journal articles [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D29\" title%3D\"Edit section%3A Other journal articles\">edit ] J. L. Kelly%2C Jr.%2C <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fwww.princeton.edu%2F~wbialek%2Frome%2Frefs%2Fkelly_56.pdf\">Princeton %2C \"A New Interpretation of Information Rate\" Bell System Technical Journal%2C Vol. 35%2C July 1956%2C pp. 917 26. R. Landauer%2C <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fieeexplore.ieee.org%2Fsearch%2Fwrapper.jsp%3Farnumber%3D615478\">IEEE.org %2C \"Information is Physical\" Proc. Workshop on Physics and Computation PhysComp'92 (IEEE Comp. Sci.Press%2C Los Alamitos%2C 1993) pp. 1 4. Landauer%2C R. (1961). <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fwww.research.ibm.com%2Fjournal%2Frd%2F441%2Flandauerii.pdf\">\"Irreversibility and Heat Generation in the Computing Process\" (PDF). IBM J. Res. Dev. 5 (3)%3A 183 191. <%24cheerio1 href%3D\"%2Fwiki%2FDoi_(identifier)\" class%3D\"mw-redirect\" title%3D\"Doi (identifier)\">doi %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fdoi.org%2F10.1147%2Frd.53.0183\">10.1147%2Frd.53.0183 . Timme%2C Nicholas%3B Alford%2C Wesley%3B Flecker%2C Benjamin%3B Beggs%2C John M. (2012). \"Multivariate information measures%3A an experimentalist's perspective\". <%24cheerio1 href%3D\"%2Fwiki%2FArXiv_(identifier)\" class%3D\"mw-redirect\" title%3D\"ArXiv (identifier)\">arXiv %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Farxiv.org%2Fabs%2F1111.6857\">1111.6857 [ <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Farxiv.org%2Farchive%2Fcs.IT\">cs.IT ]. Textbooks on information theory [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D30\" title%3D\"Edit section%3A Textbooks on information theory\">edit ] Arndt%2C C. Information Measures%2C Information and its Description in Science and Engineering (Springer Series%3A Signals and Communication Technology)%2C 2004%2C <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F978-3-540-40855-0\" title%3D\"Special%3ABookSources%2F978-3-540-40855-0\">978-3-540-40855-0 Ash%2C RB. Information Theory. New York%3A Interscience%2C 1965. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-470-03445-9\" title%3D\"Special%3ABookSources%2F0-470-03445-9\">0-470-03445-9 . New York%3A Dover 1990. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-486-66521-6\" title%3D\"Special%3ABookSources%2F0-486-66521-6\">0-486-66521-6 <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DGallager%2C_R%26action%3Dedit%26redlink%3D1\" class%3D\"new\" title%3D\"Gallager%2C R (page does not exist)\">Gallager%2C R . Information Theory and Reliable Communication. New York%3A John Wiley and Sons%2C 1968. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-471-29048-3\" title%3D\"Special%3ABookSources%2F0-471-29048-3\">0-471-29048-3 Goldman%2C S. Information Theory. New York%3A Prentice Hall%2C 1953. New York%3A Dover 1968 <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-486-62209-6\" title%3D\"Special%3ABookSources%2F0-486-62209-6\">0-486-62209-6 %2C 2005 <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-486-44271-3\" title%3D\"Special%3ABookSources%2F0-486-44271-3\">0-486-44271-3 <%24cheerio1 href%3D\"%2Fwiki%2FThomas_M._Cover\" title%3D\"Thomas M. Cover\">Cover%2C Thomas %3B Thomas%2C Joy A. (2006). Elements of information theory (2nd ed.). New York%3A <%24cheerio1 href%3D\"%2Fwiki%2FWiley-Interscience\" class%3D\"mw-redirect\" title%3D\"Wiley-Interscience\">Wiley-Interscience . <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-471-24195-4\" title%3D\"Special%3ABookSources%2F0-471-24195-4\">0-471-24195-4 . <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DCsiszar%2C_I%26action%3Dedit%26redlink%3D1\" class%3D\"new\" title%3D\"Csiszar%2C I (page does not exist)\">Csiszar%2C I %2C Korner%2C J. Information Theory%3A Coding Theorems for Discrete Memoryless Systems Akademiai Kiado%3A 2nd edition%2C 1997. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F963-05-7440-3\" title%3D\"Special%3ABookSources%2F963-05-7440-3\">963-05-7440-3 <%24cheerio1 href%3D\"%2Fwiki%2FDavid_J._C._MacKay\" title%3D\"David J. C. MacKay\">MacKay%2C David J. C. . <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fwww.inference.phy.cam.ac.uk%2Fmackay%2Fitila%2Fbook.html\">Information Theory%2C Inference%2C and Learning Algorithms Cambridge%3A Cambridge University Press%2C 2003. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-521-64298-1\" title%3D\"Special%3ABookSources%2F0-521-64298-1\">0-521-64298-1 Mansuripur%2C M. Introduction to Information Theory. New York%3A Prentice Hall%2C 1987. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-13-484668-0\" title%3D\"Special%3ABookSources%2F0-13-484668-0\">0-13-484668-0 <%24cheerio1 href%3D\"%2Fwiki%2FRobert_McEliece\" title%3D\"Robert McEliece\">McEliece%2C R . The Theory of Information and Coding\". Cambridge%2C 2002. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F978-0521831857\" title%3D\"Special%3ABookSources%2F978-0521831857\">978-0521831857 Pierce%2C JR. \"An introduction to information theory%3A symbols%2C signals and noise\". Dover (2nd Edition). 1961 (reprinted by Dover 1980). <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DReza%2C_F%26action%3Dedit%26redlink%3D1\" class%3D\"new\" title%3D\"Reza%2C F (page does not exist)\">Reza%2C F . An Introduction to Information Theory. New York%3A McGraw-Hill 1961. New York%3A Dover 1994. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-486-68210-2\" title%3D\"Special%3ABookSources%2F0-486-68210-2\">0-486-68210-2 <%24cheerio1 href%3D\"%2Fwiki%2FClaude_Shannon\" title%3D\"Claude Shannon\">Shannon%2C Claude %3B <%24cheerio1 href%3D\"%2Fwiki%2FWarren_Weaver\" title%3D\"Warren Weaver\">Weaver%2C Warren (1949). <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fmonoskop.org%2Fimages%2Fb%2Fbe%2FShannon_Claude_E_Weaver_Warren_The_Mathematical_Theory_of_Communication_1963.pdf\">The Mathematical Theory of Communication (PDF). <%24cheerio1 href%3D\"%2Fwiki%2FUrbana%2C_Illinois\" title%3D\"Urbana%2C Illinois\">Urbana%2C Illinois %3A <%24cheerio1 href%3D\"%2Fwiki%2FUniversity_of_Illinois_Press\" title%3D\"University of Illinois Press\">University of Illinois Press . <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-252-72548-4\" title%3D\"Special%3ABookSources%2F0-252-72548-4\">0-252-72548-4 . <%24cheerio1 href%3D\"%2Fwiki%2FLCCN_(identifier)\" class%3D\"mw-redirect\" title%3D\"LCCN (identifier)\">LCCN <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"%2F%2Flccn.loc.gov%2F49-11922\">49-11922 . Stone%2C JV. Chapter 1 of book <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fjim-stone.staff.shef.ac.uk%2FBookInfoTheory%2FInfoTheoryBookMain.html\">\"Information Theory%3A A Tutorial Introduction\" %2C University of Sheffield%2C England%2C 2014. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F978-0956372857\" title%3D\"Special%3ABookSources%2F978-0956372857\">978-0956372857 . Yeung%2C RW. <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fiest2.ie.cuhk.edu.hk%2F~whyeung%2Fbook%2F\">A First Course in Information Theory Kluwer Academic%2FPlenum Publishers%2C 2002. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-306-46791-7\" title%3D\"Special%3ABookSources%2F0-306-46791-7\">0-306-46791-7 . Yeung%2C RW. <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fiest2.ie.cuhk.edu.hk%2F~whyeung%2Fbook2%2F\">Information Theory and Network Coding Springer 2008%2C 2002. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F978-0-387-79233-0\" title%3D\"Special%3ABookSources%2F978-0-387-79233-0\">978-0-387-79233-0 Other books [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D31\" title%3D\"Edit section%3A Other books\">edit ] Leon Brillouin%2C Science and Information Theory%2C Mineola%2C N.Y.%3A Dover%2C [1956%2C 1962] 2004. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-486-43918-6\" title%3D\"Special%3ABookSources%2F0-486-43918-6\">0-486-43918-6 <%24cheerio1 href%3D\"%2Fwiki%2FJames_Gleick\" title%3D\"James Gleick\">James Gleick %2C <%24cheerio1 href%3D\"%2Fwiki%2FThe_Information%3A_A_History%2C_a_Theory%2C_a_Flood\" title%3D\"The Information%3A A History%2C a Theory%2C a Flood\">The Information%3A A History%2C a Theory%2C a Flood %2C New York%3A Pantheon%2C 2011. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F978-0-375-42372-7\" title%3D\"Special%3ABookSources%2F978-0-375-42372-7\">978-0-375-42372-7 A. I. Khinchin%2C Mathematical Foundations of Information Theory%2C New York%3A Dover%2C 1957. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-486-60434-9\" title%3D\"Special%3ABookSources%2F0-486-60434-9\">0-486-60434-9 H. S. Leff and A. F. Rex%2C Editors%2C Maxwell's Demon%3A Entropy%2C Information%2C Computing%2C Princeton University Press%2C Princeton%2C New Jersey (1990). <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-691-08727-X\" title%3D\"Special%3ABookSources%2F0-691-08727-X\">0-691-08727-X <%24cheerio1 href%3D\"%2Fwiki%2FRobert_K._Logan\" title%3D\"Robert K. Logan\">Robert K. Logan . What is Information%3F - Propagating Organization in the Biosphere%2C the Symbolosphere%2C the Technosphere and the Econosphere%2C Toronto%3A DEMO Publishing. Tom Siegfried%2C The Bit and the Pendulum%2C Wiley%2C 2000. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-471-32174-5\" title%3D\"Special%3ABookSources%2F0-471-32174-5\">0-471-32174-5 <%24cheerio1 href%3D\"%2Fwiki%2FCharles_Seife\" title%3D\"Charles Seife\">Charles Seife %2C <%24cheerio1 href%3D\"%2Fwiki%2FDecoding_the_Universe\" title%3D\"Decoding the Universe\">Decoding the Universe %2C Viking%2C 2006. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-670-03441-X\" title%3D\"Special%3ABookSources%2F0-670-03441-X\">0-670-03441-X Jeremy Campbell%2C <%24cheerio1 href%3D\"%2Fwiki%2FGrammatical_Man\" title%3D\"Grammatical Man\">Grammatical Man %2C Touchstone%2FSimon %26 Schuster%2C 1982%2C <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-671-44062-4\" title%3D\"Special%3ABookSources%2F0-671-44062-4\">0-671-44062-4 Henri Theil%2C Economics and Information Theory%2C Rand McNally %26 Company - Chicago%2C 1967. Escolano%2C Suau%2C Bonev%2C <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fwww.springer.com%2Fcomputer%2Fimage%2Bprocessing%2Fbook%2F978-1-84882-296-2\">Information Theory in Computer Vision and Pattern Recognition %2C Springer%2C 2009. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F978-1-84882-296-2\" title%3D\"Special%3ABookSources%2F978-1-84882-296-2\">978-1-84882-296-2 Vlatko Vedral%2C Decoding Reality%3A The Universe as Quantum Information%2C Oxford University Press 2010. <%24cheerio1 href%3D\"%2Fwiki%2FISBN_(identifier)\" class%3D\"mw-redirect\" title%3D\"ISBN (identifier)\">ISBN <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ABookSources%2F0-19-923769-7\" title%3D\"Special%3ABookSources%2F0-19-923769-7\">0-19-923769-7 MOOC on information theory [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D32\" title%3D\"Edit section%3A MOOC on information theory\">edit ] Raymond W. Yeung%2C \" <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fwww.inc.cuhk.edu.hk%2FInformationTheory%2Findex.html\">Information Theory \" ( <%24cheerio1 href%3D\"%2Fwiki%2FThe_Chinese_University_of_Hong_Kong\" class%3D\"mw-redirect\" title%3D\"The Chinese University of Hong Kong\">The Chinese University of Hong Kong ) External links [ <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit%26section%3D33\" title%3D\"Edit section%3A External links\">edit ] <%24cheerio1 class%3D\"mbox-image\"> <%24cheerio1 class%3D\"mbox-text plainlist\">Wikiquote has quotations related to%3A <%24cheerio1 href%3D\"https%3A%2F%2Fen.wikiquote.org%2Fwiki%2FSpecial%3ASearch%2FInformation_theory\" class%3D\"extiw\" title%3D\"q%3ASpecial%3ASearch%2FInformation theory\">Information theory <%24cheerio1 style%3D\"padding-top%3A0.4em%3Bline-height%3A1.2em\"> <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AThe_Wikipedia_Library\" title%3D\"Wikipedia%3AThe Wikipedia Library\">Library resources about Information theory <%24cheerio1 class%3D\"plainlist\" style%3D\"padding%3A0 0.1em 0.4em\"> <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fftl.toolforge.org%2Fcgi-bin%2Fftl%3Fst%3Dwp%26su%3DInformation%2Btheory\">Resources in your library <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fftl.toolforge.org%2Fcgi-bin%2Fftl%3Fst%3Dwp%26su%3DInformation%2Btheory%26library%3D0CHOOSE0\">Resources in other libraries <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fwww.encyclopediaofmath.org%2Findex.php%3Ftitle%3DInformation\">\"Information\" %2C <%24cheerio1 href%3D\"%2Fwiki%2FEncyclopedia_of_Mathematics\" title%3D\"Encyclopedia of Mathematics\">Encyclopedia of Mathematics %2C <%24cheerio1 href%3D\"%2Fwiki%2FEuropean_Mathematical_Society\" title%3D\"European Mathematical Society\">EMS Press %2C 2001 [1994] Lambert F. L. (1999)%2C \" <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fjchemed.chem.wisc.edu%2FJournal%2FIssues%2F1999%2FOct%2Fabs1385.html\">Shuffled Cards%2C Messy Desks%2C and Disorderly Dorm Rooms - Examples of Entropy Increase%3F Nonsense! \"%2C Journal of Chemical Education <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"http%3A%2F%2Fwww.itsoc.org%2F\">IEEE Information Theory Society and <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fwww.itsoc.org%2Fresources%2Fsurveys\">ITSOC Monographs%2C Surveys%2C and Reviews <%24cheerio1 class%3D\"navbox-list navbox-odd hlist\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FArtificial_intelligence\" title%3D\"Artificial intelligence\">Artificial intelligence <%24cheerio1 href%3D\"%2Fwiki%2FBiocybernetics\" title%3D\"Biocybernetics\">Biological cybernetics <%24cheerio1 href%3D\"%2Fwiki%2FBiomedical_cybernetics\" title%3D\"Biomedical cybernetics\">Biomedical cybernetics <%24cheerio1 href%3D\"%2Fwiki%2FBiorobotics\" title%3D\"Biorobotics\">Biorobotics <%24cheerio1 href%3D\"%2Fwiki%2FBiosemiotics\" title%3D\"Biosemiotics\">Biosemiotics <%24cheerio1 href%3D\"%2Fwiki%2FBrain%E2%80%93computer_interface\" title%3D\"Brain computer interface\">Neurocybernetics <%24cheerio1 href%3D\"%2Fwiki%2FCatastrophe_theory\" title%3D\"Catastrophe theory\">Catastrophe theory <%24cheerio1 href%3D\"%2Fwiki%2FComputational_neuroscience\" title%3D\"Computational neuroscience\">Computational neuroscience <%24cheerio1 href%3D\"%2Fwiki%2FConnectionism\" title%3D\"Connectionism\">Connectionism <%24cheerio1 href%3D\"%2Fwiki%2FControl_theory\" title%3D\"Control theory\">Control theory <%24cheerio1 href%3D\"%2Fwiki%2FCybernetics_in_the_Soviet_Union\" title%3D\"Cybernetics in the Soviet Union\">Cybernetics in the Soviet Union <%24cheerio1 href%3D\"%2Fwiki%2FDecision_theory\" title%3D\"Decision theory\">Decision theory <%24cheerio1 href%3D\"%2Fwiki%2FEmergence\" title%3D\"Emergence\">Emergence <%24cheerio1 href%3D\"%2Fwiki%2FEngineering_cybernetics\" title%3D\"Engineering cybernetics\">Engineering cybernetics <%24cheerio1 href%3D\"%2Fwiki%2FHomeostasis\" title%3D\"Homeostasis\">Homeostasis <%24cheerio1 class%3D\"mw-selflink selflink\">Information theory <%24cheerio1 href%3D\"%2Fwiki%2FManagement_cybernetics\" title%3D\"Management cybernetics\">Management cybernetics <%24cheerio1 href%3D\"%2Fwiki%2FMedical_cybernetics\" title%3D\"Medical cybernetics\">Medical cybernetics <%24cheerio1 href%3D\"%2Fwiki%2FSecond-order_cybernetics\" title%3D\"Second-order cybernetics\">Second-order cybernetics <%24cheerio1 href%3D\"%2Fwiki%2FSemiotics\" title%3D\"Semiotics\">Semiotics <%24cheerio1 href%3D\"%2Fwiki%2FSociocybernetics\" title%3D\"Sociocybernetics\">Sociocybernetics <%24cheerio1 href%3D\"%2Fwiki%2FSubjectivity\" title%3D\"Subjectivity\">Polycontexturality <%24cheerio1 href%3D\"%2Fwiki%2FSynergetics_(Haken)\" title%3D\"Synergetics (Haken)\">Synergetics <%24cheerio1 class%3D\"navbox-list navbox-even hlist\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FAlexander_Lerner\" title%3D\"Alexander Lerner\">Alexander Lerner <%24cheerio1 href%3D\"%2Fwiki%2FAlexey_Lyapunov\" title%3D\"Alexey Lyapunov\">Alexey Lyapunov <%24cheerio1 href%3D\"%2Fwiki%2FAlfred_Radcliffe-Brown\" title%3D\"Alfred Radcliffe-Brown\">Alfred Radcliffe-Brown <%24cheerio1 href%3D\"%2Fwiki%2FAllenna_Leonard\" title%3D\"Allenna Leonard\">Allenna Leonard <%24cheerio1 href%3D\"%2Fwiki%2FAnthony_Wilden\" title%3D\"Anthony Wilden\">Anthony Wilden <%24cheerio1 href%3D\"%2Fwiki%2FBuckminster_Fuller\" title%3D\"Buckminster Fuller\">Buckminster Fuller <%24cheerio1 href%3D\"%2Fwiki%2FCharles_Fran%C3%A7ois_(systems_scientist)\" title%3D\"Charles François (systems scientist)\">Charles François <%24cheerio1 href%3D\"%2Fwiki%2FClaude_Bernard\" title%3D\"Claude Bernard\">Claude Bernard <%24cheerio1 href%3D\"%2Fwiki%2FCliff_Joslyn\" title%3D\"Cliff Joslyn\">Cliff Joslyn <%24cheerio1 href%3D\"%2Fwiki%2FErich_von_Holst\" title%3D\"Erich von Holst\">Erich von Holst <%24cheerio1 href%3D\"%2Fwiki%2FErnst_von_Glasersfeld\" title%3D\"Ernst von Glasersfeld\">Ernst von Glasersfeld <%24cheerio1 href%3D\"%2Fwiki%2FFrancis_Heylighen\" title%3D\"Francis Heylighen\">Francis Heylighen <%24cheerio1 href%3D\"%2Fwiki%2FFrancisco_Varela\" title%3D\"Francisco Varela\">Francisco Varela <%24cheerio1 href%3D\"%2Fwiki%2FFrederic_Vester\" title%3D\"Frederic Vester\">Frederic Vester <%24cheerio1 href%3D\"%2Fwiki%2FGeoffrey_Vickers\" title%3D\"Geoffrey Vickers\">Charles Geoffrey Vickers <%24cheerio1 href%3D\"%2Fwiki%2FGordon_Pask\" title%3D\"Gordon Pask\">Gordon Pask <%24cheerio1 href%3D\"%2Fwiki%2FGordon_S._Brown\" title%3D\"Gordon S. Brown\">Gordon S. Brown <%24cheerio1 href%3D\"%2Fwiki%2FGregory_Bateson\" title%3D\"Gregory Bateson\">Gregory Bateson <%24cheerio1 href%3D\"%2Fwiki%2FHeinz_von_Foerster\" title%3D\"Heinz von Foerster\">Heinz von Foerster <%24cheerio1 href%3D\"%2Fwiki%2FHumberto_Maturana\" title%3D\"Humberto Maturana\">Humberto Maturana <%24cheerio1 href%3D\"%2Fwiki%2FI._A._Richards\" title%3D\"I. A. Richards\">I. A. Richards <%24cheerio1 href%3D\"%2Fwiki%2FIgor_Aleksander\" title%3D\"Igor Aleksander\">Igor Aleksander <%24cheerio1 href%3D\"%2Fwiki%2FJacque_Fresco\" title%3D\"Jacque Fresco\">Jacque Fresco <%24cheerio1 href%3D\"%2Fwiki%2FJakob_von_Uexk%C3%BCll\" class%3D\"mw-redirect\" title%3D\"Jakob von Uexküll\">Jakob von Uexküll <%24cheerio1 href%3D\"%2Fwiki%2FJason_Jixuan_Hu\" title%3D\"Jason Jixuan Hu\">Jason Jixuan Hu <%24cheerio1 href%3D\"%2Fwiki%2FJay_Wright_Forrester\" title%3D\"Jay Wright Forrester\">Jay Wright Forrester <%24cheerio1 href%3D\"%2Fwiki%2FJennifer_Wilby\" title%3D\"Jennifer Wilby\">Jennifer Wilby <%24cheerio1 href%3D\"%2Fwiki%2FJohn_N._Warfield\" title%3D\"John N. Warfield\">John N. Warfield <%24cheerio1 href%3D\"%2Fwiki%2FKevin_Warwick\" title%3D\"Kevin Warwick\">Kevin Warwick <%24cheerio1 href%3D\"%2Fwiki%2FLudwig_von_Bertalanffy\" title%3D\"Ludwig von Bertalanffy\">Ludwig von Bertalanffy <%24cheerio1 href%3D\"%2Fwiki%2FMaleyka_Abbaszadeh\" title%3D\"Maleyka Abbaszadeh\">Maleyka Abbaszadeh <%24cheerio1 href%3D\"%2Fwiki%2FManfred_Clynes\" title%3D\"Manfred Clynes\">Manfred Clynes <%24cheerio1 href%3D\"%2Fwiki%2FMargaret_Mead\" title%3D\"Margaret Mead\">Margaret Mead <%24cheerio1 href%3D\"%2Fwiki%2FMarian_Mazur\" title%3D\"Marian Mazur\">Marian Mazur <%24cheerio1 href%3D\"%2Fwiki%2FN._Katherine_Hayles\" title%3D\"N. Katherine Hayles\">N. Katherine Hayles <%24cheerio1 href%3D\"%2Fwiki%2FNatalia_Bekhtereva\" title%3D\"Natalia Bekhtereva\">Natalia Bekhtereva <%24cheerio1 href%3D\"%2Fwiki%2FNiklas_Luhmann\" title%3D\"Niklas Luhmann\">Niklas Luhmann <%24cheerio1 href%3D\"%2Fwiki%2FNorbert_Wiener\" title%3D\"Norbert Wiener\">Norbert Wiener <%24cheerio1 href%3D\"%2Fwiki%2FPetro_Grigorenko\" title%3D\"Petro Grigorenko\">Pyotr Grigorenko <%24cheerio1 href%3D\"%2Fwiki%2FQian_Xuesen\" title%3D\"Qian Xuesen\">Qian Xuesen <%24cheerio1 href%3D\"%2Fwiki%2FRanulph_Glanville\" title%3D\"Ranulph Glanville\">Ranulph Glanville <%24cheerio1 href%3D\"%2Fwiki%2FRobert_Trappl\" title%3D\"Robert Trappl\">Robert Trappl <%24cheerio1 href%3D\"%2Fwiki%2FSergei_P._Kurdyumov\" title%3D\"Sergei P. Kurdyumov\">Sergei P. Kurdyumov <%24cheerio1 href%3D\"%2Fwiki%2FStafford_Beer\" title%3D\"Stafford Beer\">Anthony Stafford Beer <%24cheerio1 href%3D\"%2Fwiki%2FStuart_Kauffman\" title%3D\"Stuart Kauffman\">Stuart Kauffman <%24cheerio1 href%3D\"%2Fwiki%2FStuart_Umpleby\" title%3D\"Stuart Umpleby\">Stuart Umpleby <%24cheerio1 href%3D\"%2Fwiki%2FTalcott_Parsons\" title%3D\"Talcott Parsons\">Talcott Parsons <%24cheerio1 href%3D\"%2Fwiki%2FUlla_Mitzdorf\" title%3D\"Ulla Mitzdorf\">Ulla Mitzdorf <%24cheerio1 href%3D\"%2Fwiki%2FValentin_Turchin\" title%3D\"Valentin Turchin\">Valentin Turchin <%24cheerio1 href%3D\"%2Fwiki%2FValentino_Braitenberg\" title%3D\"Valentino Braitenberg\">Valentin Braitenberg <%24cheerio1 href%3D\"%2Fwiki%2FW._Ross_Ashby\" title%3D\"W. Ross Ashby\">William Ross Ashby <%24cheerio1 href%3D\"%2Fwiki%2FWalter_Bradford_Cannon\" title%3D\"Walter Bradford Cannon\">Walter Bradford Cannon <%24cheerio1 href%3D\"%2Fwiki%2FWalter_Pitts\" title%3D\"Walter Pitts\">Walter Pitts <%24cheerio1 href%3D\"%2Fwiki%2FWarren_Sturgis_McCulloch\" title%3D\"Warren Sturgis McCulloch\">Warren McCulloch <%24cheerio1 href%3D\"%2Fwiki%2FWilliam_Grey_Walter\" title%3D\"William Grey Walter\">William Grey Walter <%24cheerio1 href%3D\"%2Fwiki%2FTemplate%3ACybernetics\" title%3D\"Template%3ACybernetics\"> <%24cheerio1bbr title%3D\"View this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">v <%24cheerio1 href%3D\"%2Fwiki%2FTemplate_talk%3ACybernetics\" title%3D\"Template talk%3ACybernetics\"> <%24cheerio1bbr title%3D\"Discuss this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">t <%24cheerio1 class%3D\"external text\" href%3D\"https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DTemplate%3ACybernetics%26action%3Dedit\"> <%24cheerio1bbr title%3D\"Edit this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">e Subfields of and cyberneticians involved in <%24cheerio1 href%3D\"%2Fwiki%2FCybernetics\" title%3D\"Cybernetics\">cybernetics Subfields <%24cheerio1 href%3D\"%2Fwiki%2FCyberneticist\" title%3D\"Cyberneticist\">Cyberneticians <%24cheerio1 class%3D\"navbox-list navbox-odd hlist\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FTemplate%3AInformatics\" title%3D\"Template%3AInformatics\"> <%24cheerio1bbr title%3D\"View this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">v <%24cheerio1 href%3D\"%2Fwiki%2FTemplate_talk%3AInformatics\" title%3D\"Template talk%3AInformatics\"> <%24cheerio1bbr title%3D\"Discuss this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">t <%24cheerio1 class%3D\"external text\" href%3D\"https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DTemplate%3AInformatics%26action%3Dedit\"> <%24cheerio1bbr title%3D\"Edit this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">e <%24cheerio1 href%3D\"%2Fwiki%2FInformation_processing\" title%3D\"Information processing\">information processing <%24cheerio1 href%3D\"%2Fwiki%2FInformation_processing\" title%3D\"Information processing\">information processes <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FPerception\" title%3D\"Perception\">perception <%24cheerio1 href%3D\"%2Fwiki%2FAttention\" title%3D\"Attention\">attention <%24cheerio1 href%3D\"%2Fwiki%2FSocial_influence\" title%3D\"Social influence\">influence <%24cheerio1 href%3D\"%2Fwiki%2FRemote_control\" title%3D\"Remote control\">operating <%24cheerio1 href%3D\"%2Fwiki%2FCommunication\" title%3D\"Communication\">communication <%24cheerio1 href%3D\"%2Fwiki%2FReason\" title%3D\"Reason\">reasoning <%24cheerio1 href%3D\"%2Fwiki%2FLearning\" title%3D\"Learning\">learning <%24cheerio1 href%3D\"%2Fwiki%2FInformation_storage\" class%3D\"mw-redirect\" title%3D\"Information storage\">storing <%24cheerio1 href%3D\"%2Fwiki%2FDecision-making\" title%3D\"Decision-making\">decision-making <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FEvent_processing\" class%3D\"mw-redirect\" title%3D\"Event processing\">event processing <%24cheerio1 href%3D\"%2Fwiki%2FSemiotics\" title%3D\"Semiotics\">sign processesing <%24cheerio1 href%3D\"%2Fwiki%2FSignal\" title%3D\"Signal\">signal processing <%24cheerio1 href%3D\"%2Fwiki%2FData_processing\" title%3D\"Data processing\">data processing <%24cheerio1 href%3D\"%2Fwiki%2FStream_processing\" title%3D\"Stream processing\">stream processing <%24cheerio1 href%3D\"%2Fwiki%2FMulti-agent_system\" title%3D\"Multi-agent system\">agent processing <%24cheerio1 href%3D\"%2Fwiki%2FState_(computer_science)\" title%3D\"State (computer science)\">state processing \\ information processes by function information processing abstractions <%24cheerio1 href%3D\"%2Fwiki%2FInformation_processor\" title%3D\"Information processor\">information processors <%24cheerio1 class%3D\"navbox-list navbox-odd hlist\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FNatural_computing%23Nature_as_information_processing\" title%3D\"Natural computing\">nature as information processing <%24cheerio1 href%3D\"%2Fwiki%2FInformation_processing_theory%23Humans_as_Information_Processing_Systems\" title%3D\"Information processing theory\">humans as information processing systems <%24cheerio1 href%3D\"%2Fwiki%2FSocial_information_processing\" title%3D\"Social information processing\">society as information processing system <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FMixed_reality\" title%3D\"Mixed reality\">mixed reality <%24cheerio1 href%3D\"%2Fwiki%2FBrain-computer_interface\" class%3D\"mw-redirect\" title%3D\"Brain-computer interface\">brain-computer interface <%24cheerio1 href%3D\"%2Fwiki%2FPhysical_computing\" title%3D\"Physical computing\">physical computing <%24cheerio1 href%3D\"%2Fwiki%2FHuman%E2%80%93computer_interaction\" title%3D\"Human computer interaction\">human computer interaction <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FProcessor_(computing)\" title%3D\"Processor (computing)\">processors and <%24cheerio1 href%3D\"%2Fwiki%2FProcess_(computing)\" title%3D\"Process (computing)\">processes <%24cheerio1 href%3D\"%2Fwiki%2FBio-inspired_computing\" title%3D\"Bio-inspired computing\">bio-inspired computing <%24cheerio1 href%3D\"%2Fwiki%2FUbiquitous_computing\" title%3D\"Ubiquitous computing\">ubiquitous computing <%24cheerio1 href%3D\"%2Fwiki%2FArtificial_brain\" title%3D\"Artificial brain\">artificial brain and <%24cheerio1 href%3D\"%2Fwiki%2FMind_uploading\" title%3D\"Mind uploading\">mind uploading <%24cheerio1 href%3D\"%2Fwiki%2FVirtual_reality\" title%3D\"Virtual reality\">virtual reality <%24cheerio1 href%3D\"%2Fwiki%2FVirtual_world\" title%3D\"Virtual world\">virtual world natural mixed artificial information processing theories and concepts <%24cheerio1 class%3D\"navbox-list navbox-odd hlist\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FComputational_theory_of_mind\" title%3D\"Computational theory of mind\">computational theory of mind <%24cheerio1 href%3D\"%2Fwiki%2FPhilosophy_of_information\" title%3D\"Philosophy of information\">philosophy of information <%24cheerio1 href%3D\"%2Fwiki%2FPhilosophy_of_artificial_intelligence\" title%3D\"Philosophy of artificial intelligence\">philosophy of artificial intelligence <%24cheerio1 href%3D\"%2Fwiki%2FDigital_philosophy\" title%3D\"Digital philosophy\">digital philosophy <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FInformation_processing_theory\" title%3D\"Information processing theory\">information processing theory <%24cheerio1 href%3D\"%2Fwiki%2FMind\" title%3D\"Mind\">mind and <%24cheerio1 href%3D\"%2Fwiki%2FIntelligence\" title%3D\"Intelligence\">intelligence <%24cheerio1 href%3D\"%2Fwiki%2FCognitive_informatics\" class%3D\"mw-redirect\" title%3D\"Cognitive informatics\">cognitive informatics and <%24cheerio1 href%3D\"%2Fwiki%2FNeuroinformatics\" title%3D\"Neuroinformatics\">neuroinformatics <%24cheerio1 href%3D\"%2Fwiki%2FBehavior_informatics\" title%3D\"Behavior informatics\">behavior informatics <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 class%3D\"mw-selflink selflink\">information theory <%24cheerio1 href%3D\"%2Fwiki%2FDecision_theory\" title%3D\"Decision theory\">decision theory <%24cheerio1 href%3D\"%2Fwiki%2FSystems_theory\" title%3D\"Systems theory\">systems theory <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FNeural_computation\" title%3D\"Neural computation\">neural computation <%24cheerio1 href%3D\"%2Fwiki%2FTheory_of_computation\" title%3D\"Theory of computation\">computation theory <%24cheerio1 href%3D\"%2Fwiki%2FAlgorithms\" class%3D\"mw-redirect\" title%3D\"Algorithms\">algorithms and <%24cheerio1 href%3D\"%2Fwiki%2FInformation_structure\" title%3D\"Information structure\">information structures <%24cheerio1 href%3D\"%2Fwiki%2FCircuit_(computer_science)\" title%3D\"Circuit (computer science)\">computational circuits <%24cheerio1 href%3D\"%2Fwiki%2FArtificial_intelligence\" title%3D\"Artificial intelligence\">artificial intelligence <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FEvolutionary_informatics\" class%3D\"mw-redirect\" title%3D\"Evolutionary informatics\">evolutionary informatics <%24cheerio1 href%3D\"%2Fwiki%2FLaw_of_conservation_of_information\" class%3D\"mw-redirect\" title%3D\"Law of conservation of information\">law of conservation of information <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FComputational_biology\" title%3D\"Computational biology\">computational and <%24cheerio1 href%3D\"%2Fwiki%2FSystems_biology\" title%3D\"Systems biology\">systems biology <%24cheerio1 href%3D\"%2Fwiki%2FGenome_informatics\" title%3D\"Genome informatics\">genetic informatics and <%24cheerio1 href%3D\"%2Fwiki%2FCellular_computing\" class%3D\"mw-redirect\" title%3D\"Cellular computing\">cellular computing <%24cheerio1 href%3D\"%2Fwiki%2FComputational_neuroscience\" title%3D\"Computational neuroscience\">computational neuroscience and <%24cheerio1 href%3D\"%2Fwiki%2FNeurocomputing\" class%3D\"mw-redirect\" title%3D\"Neurocomputing\">neurocomputing <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FAnti-information\" title%3D\"Anti-information\">anti-information <%24cheerio1 href%3D\"%2Fwiki%2FInfosphere\" title%3D\"Infosphere\">infosphere <%24cheerio1 href%3D\"%2Fwiki%2FInforg\" title%3D\"Inforg\">inforg <%24cheerio1 href%3D\"%2Fwiki%2FDecoding_the_Universe\" title%3D\"Decoding the Universe\">decoding the universe <%24cheerio1 href%3D\"%2Fwiki%2FInformation_overload\" title%3D\"Information overload\">information overload in philosophy in <%24cheerio1 href%3D\"%2Fwiki%2FCognitive_science\" title%3D\"Cognitive science\">cognitive psychology interdisciplinary in computer science in intelligent design in biology other <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FTemplate%3ACompression_methods\" title%3D\"Template%3ACompression methods\"> <%24cheerio1bbr title%3D\"View this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">v <%24cheerio1 href%3D\"%2Fwiki%2FTemplate_talk%3ACompression_methods\" title%3D\"Template talk%3ACompression methods\"> <%24cheerio1bbr title%3D\"Discuss this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">t <%24cheerio1 class%3D\"external text\" href%3D\"https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DTemplate%3ACompression_methods%26action%3Dedit\"> <%24cheerio1bbr title%3D\"Edit this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">e <%24cheerio1 href%3D\"%2Fwiki%2FData_compression\" title%3D\"Data compression\">Data compression methods <%24cheerio1 href%3D\"%2Fwiki%2FLossless_compression\" title%3D\"Lossless compression\">Lossless <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FArithmetic_coding\" title%3D\"Arithmetic coding\">Arithmetic <%24cheerio1 href%3D\"%2Fwiki%2FAsymmetric_numeral_systems\" title%3D\"Asymmetric numeral systems\">Asymmetric numeral systems <%24cheerio1 href%3D\"%2Fwiki%2FGolomb_coding\" title%3D\"Golomb coding\">Golomb <%24cheerio1 href%3D\"%2Fwiki%2FHuffman_coding\" title%3D\"Huffman coding\">Huffman <%24cheerio1 href%3D\"%2Fwiki%2FAdaptive_Huffman_coding\" title%3D\"Adaptive Huffman coding\">Adaptive <%24cheerio1 href%3D\"%2Fwiki%2FCanonical_Huffman_code\" title%3D\"Canonical Huffman code\">Canonical <%24cheerio1 href%3D\"%2Fwiki%2FModified_Huffman_coding\" title%3D\"Modified Huffman coding\">Modified <%24cheerio1 href%3D\"%2Fwiki%2FRange_encoding\" title%3D\"Range encoding\">Range <%24cheerio1 href%3D\"%2Fwiki%2FShannon_coding\" title%3D\"Shannon coding\">Shannon <%24cheerio1 href%3D\"%2Fwiki%2FShannon%E2%80%93Fano_coding\" title%3D\"Shannon Fano coding\">Shannon Fano <%24cheerio1 href%3D\"%2Fwiki%2FShannon%E2%80%93Fano%E2%80%93Elias_coding\" title%3D\"Shannon Fano Elias coding\">Shannon Fano Elias <%24cheerio1 href%3D\"%2Fwiki%2FTunstall_coding\" title%3D\"Tunstall coding\">Tunstall <%24cheerio1 href%3D\"%2Fwiki%2FUnary_coding\" title%3D\"Unary coding\">Unary <%24cheerio1 href%3D\"%2Fwiki%2FUniversal_code_(data_compression)\" title%3D\"Universal code (data compression)\">Universal <%24cheerio1 href%3D\"%2Fwiki%2FExponential-Golomb_coding\" title%3D\"Exponential-Golomb coding\">Exp-Golomb <%24cheerio1 href%3D\"%2Fwiki%2FFibonacci_coding\" title%3D\"Fibonacci coding\">Fibonacci <%24cheerio1 href%3D\"%2Fwiki%2FElias_gamma_coding\" title%3D\"Elias gamma coding\">Gamma <%24cheerio1 href%3D\"%2Fwiki%2FLevenshtein_coding\" title%3D\"Levenshtein coding\">Levenshtein <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FByte_pair_encoding\" title%3D\"Byte pair encoding\">Byte pair encoding <%24cheerio1 href%3D\"%2Fwiki%2FLZ77_and_LZ78\" title%3D\"LZ77 and LZ78\">Lempel Ziv <%24cheerio1 href%3D\"%2Fwiki%2FBrotli\" title%3D\"Brotli\">Brotli <%24cheerio1 href%3D\"%2Fwiki%2FDEFLATE\" class%3D\"mw-redirect\" title%3D\"DEFLATE\">DEFLATE <%24cheerio1 href%3D\"%2Fwiki%2FLZ4_(compression_algorithm)\" title%3D\"LZ4 (compression algorithm)\">LZ4 <%24cheerio1 href%3D\"%2Fwiki%2FLZFSE\" title%3D\"LZFSE\">LZFSE <%24cheerio1 href%3D\"%2Fwiki%2FLZJB\" title%3D\"LZJB\">LZJB <%24cheerio1 href%3D\"%2Fwiki%2FLempel%E2%80%93Ziv%E2%80%93Markov_chain_algorithm\" title%3D\"Lempel Ziv Markov chain algorithm\">LZMA <%24cheerio1 href%3D\"%2Fwiki%2FLempel%E2%80%93Ziv%E2%80%93Oberhumer\" title%3D\"Lempel Ziv Oberhumer\">LZO <%24cheerio1 href%3D\"%2Fwiki%2FLZRW\" title%3D\"LZRW\">LZRW <%24cheerio1 href%3D\"%2Fwiki%2FLempel%E2%80%93Ziv%E2%80%93Stac\" title%3D\"Lempel Ziv Stac\">LZS <%24cheerio1 href%3D\"%2Fwiki%2FLempel%E2%80%93Ziv%E2%80%93Storer%E2%80%93Szymanski\" title%3D\"Lempel Ziv Storer Szymanski\">LZSS <%24cheerio1 href%3D\"%2Fwiki%2FLempel%E2%80%93Ziv%E2%80%93Welch\" title%3D\"Lempel Ziv Welch\">LZW <%24cheerio1 href%3D\"%2Fwiki%2FLZWL\" title%3D\"LZWL\">LZWL <%24cheerio1 href%3D\"%2Fwiki%2FLZX\" title%3D\"LZX\">LZX <%24cheerio1 href%3D\"%2Fwiki%2FSnappy_(compression)\" title%3D\"Snappy (compression)\">Snappy <%24cheerio1 href%3D\"%2Fwiki%2FZstandard\" title%3D\"Zstandard\">Zstandard <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FBurrows%E2%80%93Wheeler_transform\" title%3D\"Burrows Wheeler transform\">BWT <%24cheerio1 href%3D\"%2Fwiki%2FContext_tree_weighting\" title%3D\"Context tree weighting\">CTW <%24cheerio1 href%3D\"%2Fwiki%2FDelta_encoding\" title%3D\"Delta encoding\">Delta <%24cheerio1 href%3D\"%2Fwiki%2FDynamic_Markov_compression\" title%3D\"Dynamic Markov compression\">DMC <%24cheerio1 href%3D\"%2Fwiki%2FDifferential_pulse-code_modulation\" title%3D\"Differential pulse-code modulation\">DPCM <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_cosine_transform\" title%3D\"Discrete cosine transform\">LDCT <%24cheerio1 href%3D\"%2Fwiki%2FMove-to-front_transform\" title%3D\"Move-to-front transform\">MTF <%24cheerio1 href%3D\"%2Fwiki%2FPAQ\" title%3D\"PAQ\">PAQ <%24cheerio1 href%3D\"%2Fwiki%2FPrediction_by_partial_matching\" title%3D\"Prediction by partial matching\">PPM <%24cheerio1 href%3D\"%2Fwiki%2FRun-length_encoding\" title%3D\"Run-length encoding\">RLE <%24cheerio1 href%3D\"%2Fwiki%2FEntropy_encoding\" title%3D\"Entropy encoding\">Entropy type <%24cheerio1 href%3D\"%2Fwiki%2FDictionary_coder\" title%3D\"Dictionary coder\">Dictionary type Other types <%24cheerio1 href%3D\"%2Fwiki%2FLossy_compression\" title%3D\"Lossy compression\">Lossy <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_cosine_transform\" title%3D\"Discrete cosine transform\">Discrete cosine transform <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_cosine_transform\" title%3D\"Discrete cosine transform\">DCT <%24cheerio1 href%3D\"%2Fwiki%2FModified_discrete_cosine_transform\" title%3D\"Modified discrete cosine transform\">MDCT <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_sine_transform\" title%3D\"Discrete sine transform\">DST <%24cheerio1 href%3D\"%2Fwiki%2FFast_Fourier_transform\" title%3D\"Fast Fourier transform\">FFT <%24cheerio1 href%3D\"%2Fwiki%2FWavelet_transform\" title%3D\"Wavelet transform\">Wavelet <%24cheerio1 href%3D\"%2Fwiki%2FDaubechies_wavelet\" title%3D\"Daubechies wavelet\">Daubechies <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_wavelet_transform\" title%3D\"Discrete wavelet transform\">DWT <%24cheerio1 href%3D\"%2Fwiki%2FSet_partitioning_in_hierarchical_trees\" title%3D\"Set partitioning in hierarchical trees\">SPIHT <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FDifferential_pulse-code_modulation\" title%3D\"Differential pulse-code modulation\">DPCM <%24cheerio1 href%3D\"%2Fwiki%2FAdaptive_differential_pulse-code_modulation\" title%3D\"Adaptive differential pulse-code modulation\">ADPCM <%24cheerio1 href%3D\"%2Fwiki%2FLinear_predictive_coding\" title%3D\"Linear predictive coding\">LPC <%24cheerio1 href%3D\"%2Fwiki%2FAlgebraic_code-excited_linear_prediction\" title%3D\"Algebraic code-excited linear prediction\">ACELP <%24cheerio1 href%3D\"%2Fwiki%2FCode-excited_linear_prediction\" title%3D\"Code-excited linear prediction\">CELP <%24cheerio1 href%3D\"%2Fwiki%2FLog_area_ratio\" title%3D\"Log area ratio\">LAR <%24cheerio1 href%3D\"%2Fwiki%2FLine_spectral_pairs\" title%3D\"Line spectral pairs\">LSP <%24cheerio1 href%3D\"%2Fwiki%2FWarped_linear_predictive_coding\" title%3D\"Warped linear predictive coding\">WLPC Motion <%24cheerio1 href%3D\"%2Fwiki%2FMotion_compensation\" title%3D\"Motion compensation\">Compensation <%24cheerio1 href%3D\"%2Fwiki%2FMotion_estimation\" title%3D\"Motion estimation\">Estimation <%24cheerio1 href%3D\"%2Fwiki%2FMotion_vector\" title%3D\"Motion vector\">Vector <%24cheerio1 href%3D\"%2Fwiki%2FPsychoacoustics\" title%3D\"Psychoacoustics\">Psychoacoustic <%24cheerio1 href%3D\"%2Fwiki%2FTransform_coding\" title%3D\"Transform coding\">Transform type Predictive type <%24cheerio1 href%3D\"%2Fwiki%2FData_compression%23Audio\" title%3D\"Data compression\">Audio <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FBit_rate\" title%3D\"Bit rate\">Bit rate <%24cheerio1 href%3D\"%2Fwiki%2FAverage_bitrate\" title%3D\"Average bitrate\">ABR <%24cheerio1 href%3D\"%2Fwiki%2FConstant_bitrate\" title%3D\"Constant bitrate\">CBR <%24cheerio1 href%3D\"%2Fwiki%2FVariable_bitrate\" title%3D\"Variable bitrate\">VBR <%24cheerio1 href%3D\"%2Fwiki%2FCompanding\" title%3D\"Companding\">Companding <%24cheerio1 href%3D\"%2Fwiki%2FConvolution\" title%3D\"Convolution\">Convolution <%24cheerio1 href%3D\"%2Fwiki%2FDynamic_range\" title%3D\"Dynamic range\">Dynamic range <%24cheerio1 href%3D\"%2Fwiki%2FLatency_(audio)\" title%3D\"Latency (audio)\">Latency <%24cheerio1 href%3D\"%2Fwiki%2FNyquist%E2%80%93Shannon_sampling_theorem\" title%3D\"Nyquist Shannon sampling theorem\">Nyquist Shannon theorem <%24cheerio1 href%3D\"%2Fwiki%2FSampling_(signal_processing)\" title%3D\"Sampling (signal processing)\">Sampling <%24cheerio1 href%3D\"%2Fwiki%2FSound_quality\" title%3D\"Sound quality\">Sound quality <%24cheerio1 href%3D\"%2Fwiki%2FSpeech_coding\" title%3D\"Speech coding\">Speech coding <%24cheerio1 href%3D\"%2Fwiki%2FSub-band_coding\" title%3D\"Sub-band coding\">Sub-band coding <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FA-law_algorithm\" title%3D\"A-law algorithm\">A-law <%24cheerio1 href%3D\"%2Fwiki%2F%CE%9C-law_algorithm\" title%3D\"Μ-law algorithm\">μ-law <%24cheerio1 href%3D\"%2Fwiki%2FDifferential_pulse-code_modulation\" title%3D\"Differential pulse-code modulation\">DPCM <%24cheerio1 href%3D\"%2Fwiki%2FAdaptive_differential_pulse-code_modulation\" title%3D\"Adaptive differential pulse-code modulation\">ADPCM <%24cheerio1 href%3D\"%2Fwiki%2FDelta_modulation\" title%3D\"Delta modulation\">DM <%24cheerio1 href%3D\"%2Fwiki%2FFourier_transform\" title%3D\"Fourier transform\">FT <%24cheerio1 href%3D\"%2Fwiki%2FFast_Fourier_transform\" title%3D\"Fast Fourier transform\">FFT <%24cheerio1 href%3D\"%2Fwiki%2FLinear_predictive_coding\" title%3D\"Linear predictive coding\">LPC <%24cheerio1 href%3D\"%2Fwiki%2FAlgebraic_code-excited_linear_prediction\" title%3D\"Algebraic code-excited linear prediction\">ACELP <%24cheerio1 href%3D\"%2Fwiki%2FCode-excited_linear_prediction\" title%3D\"Code-excited linear prediction\">CELP <%24cheerio1 href%3D\"%2Fwiki%2FLog_area_ratio\" title%3D\"Log area ratio\">LAR <%24cheerio1 href%3D\"%2Fwiki%2FLine_spectral_pairs\" title%3D\"Line spectral pairs\">LSP <%24cheerio1 href%3D\"%2Fwiki%2FWarped_linear_predictive_coding\" title%3D\"Warped linear predictive coding\">WLPC <%24cheerio1 href%3D\"%2Fwiki%2FModified_discrete_cosine_transform\" title%3D\"Modified discrete cosine transform\">MDCT <%24cheerio1 href%3D\"%2Fwiki%2FPsychoacoustics\" title%3D\"Psychoacoustics\">Psychoacoustic model Concepts <%24cheerio1 href%3D\"%2Fwiki%2FAudio_codec\" title%3D\"Audio codec\">Codec parts <%24cheerio1 href%3D\"%2Fwiki%2FImage_compression\" title%3D\"Image compression\">Image <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FChroma_subsampling\" title%3D\"Chroma subsampling\">Chroma subsampling <%24cheerio1 href%3D\"%2Fwiki%2FCoding_tree_unit\" title%3D\"Coding tree unit\">Coding tree unit <%24cheerio1 href%3D\"%2Fwiki%2FColor_space\" title%3D\"Color space\">Color space <%24cheerio1 href%3D\"%2Fwiki%2FCompression_artifact\" title%3D\"Compression artifact\">Compression artifact <%24cheerio1 href%3D\"%2Fwiki%2FImage_resolution\" title%3D\"Image resolution\">Image resolution <%24cheerio1 href%3D\"%2Fwiki%2FMacroblock\" title%3D\"Macroblock\">Macroblock <%24cheerio1 href%3D\"%2Fwiki%2FPixel\" title%3D\"Pixel\">Pixel <%24cheerio1 href%3D\"%2Fwiki%2FPeak_signal-to-noise_ratio\" title%3D\"Peak signal-to-noise ratio\">PSNR <%24cheerio1 href%3D\"%2Fwiki%2FQuantization_(image_processing)\" title%3D\"Quantization (image processing)\">Quantization <%24cheerio1 href%3D\"%2Fwiki%2FStandard_test_image\" title%3D\"Standard test image\">Standard test image <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FChain_code\" title%3D\"Chain code\">Chain code <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_cosine_transform\" title%3D\"Discrete cosine transform\">DCT <%24cheerio1 href%3D\"%2Fwiki%2FDEFLATE\" class%3D\"mw-redirect\" title%3D\"DEFLATE\">DEFLATE <%24cheerio1 href%3D\"%2Fwiki%2FFractal_compression\" title%3D\"Fractal compression\">Fractal <%24cheerio1 href%3D\"%2Fwiki%2FKarhunen%E2%80%93Lo%C3%A8ve_theorem\" title%3D\"Karhunen Loève theorem\">KLT <%24cheerio1 href%3D\"%2Fwiki%2FPyramid_(image_processing)\" title%3D\"Pyramid (image processing)\">LP <%24cheerio1 href%3D\"%2Fwiki%2FRun-length_encoding\" title%3D\"Run-length encoding\">RLE <%24cheerio1 href%3D\"%2Fwiki%2FWavelet_transform\" title%3D\"Wavelet transform\">Wavelet <%24cheerio1 href%3D\"%2Fwiki%2FDaubechies_wavelet\" title%3D\"Daubechies wavelet\">Daubechies <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_wavelet_transform\" title%3D\"Discrete wavelet transform\">DWT <%24cheerio1 href%3D\"%2Fwiki%2FEmbedded_Zerotrees_of_Wavelet_transforms\" title%3D\"Embedded Zerotrees of Wavelet transforms\">EZW <%24cheerio1 href%3D\"%2Fwiki%2FSet_partitioning_in_hierarchical_trees\" title%3D\"Set partitioning in hierarchical trees\">SPIHT Concepts Methods <%24cheerio1 href%3D\"%2Fwiki%2FData_compression%23Video\" title%3D\"Data compression\">Video <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FBit_rate\" title%3D\"Bit rate\">Bit rate <%24cheerio1 href%3D\"%2Fwiki%2FAverage_bitrate\" title%3D\"Average bitrate\">ABR <%24cheerio1 href%3D\"%2Fwiki%2FConstant_bitrate\" title%3D\"Constant bitrate\">CBR <%24cheerio1 href%3D\"%2Fwiki%2FVariable_bitrate\" title%3D\"Variable bitrate\">VBR <%24cheerio1 href%3D\"%2Fwiki%2FDisplay_resolution\" title%3D\"Display resolution\">Display resolution <%24cheerio1 href%3D\"%2Fwiki%2FFilm_frame\" title%3D\"Film frame\">Frame <%24cheerio1 href%3D\"%2Fwiki%2FFrame_rate\" title%3D\"Frame rate\">Frame rate <%24cheerio1 href%3D\"%2Fwiki%2FVideo_compression_picture_types\" title%3D\"Video compression picture types\">Frame types <%24cheerio1 href%3D\"%2Fwiki%2FInterlaced_video\" title%3D\"Interlaced video\">Interlace <%24cheerio1 href%3D\"%2Fwiki%2FVideo%23Characteristics_of_video_streams\" title%3D\"Video\">Video characteristics <%24cheerio1 href%3D\"%2Fwiki%2FVideo_quality\" title%3D\"Video quality\">Video quality <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_cosine_transform\" title%3D\"Discrete cosine transform\">DCT <%24cheerio1 href%3D\"%2Fwiki%2FDifferential_pulse-code_modulation\" title%3D\"Differential pulse-code modulation\">DPCM <%24cheerio1 href%3D\"%2Fwiki%2FDeblocking_filter\" title%3D\"Deblocking filter\">Deblocking filter <%24cheerio1 href%3D\"%2Fwiki%2FLapped_transform\" title%3D\"Lapped transform\">Lapped transform Motion <%24cheerio1 href%3D\"%2Fwiki%2FMotion_compensation\" title%3D\"Motion compensation\">Compensation <%24cheerio1 href%3D\"%2Fwiki%2FMotion_estimation\" title%3D\"Motion estimation\">Estimation <%24cheerio1 href%3D\"%2Fwiki%2FMotion_vector\" title%3D\"Motion vector\">Vector <%24cheerio1 href%3D\"%2Fwiki%2FWavelet_transform\" title%3D\"Wavelet transform\">Wavelet <%24cheerio1 href%3D\"%2Fwiki%2FDaubechies_wavelet\" title%3D\"Daubechies wavelet\">Daubechies <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_wavelet_transform\" title%3D\"Discrete wavelet transform\">DWT Concepts <%24cheerio1 href%3D\"%2Fwiki%2FVideo_codec\" title%3D\"Video codec\">Codec parts <%24cheerio1 class%3D\"mw-selflink selflink\">Theory <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FEntropy_(information_theory)\" title%3D\"Entropy (information theory)\">Entropy <%24cheerio1 class%3D\"mw-selflink selflink\">Information theory <%24cheerio1 href%3D\"%2Fwiki%2FTimeline_of_information_theory\" title%3D\"Timeline of information theory\">Timeline <%24cheerio1 href%3D\"%2Fwiki%2FKolmogorov_complexity\" title%3D\"Kolmogorov complexity\">Kolmogorov complexity <%24cheerio1 href%3D\"%2Fwiki%2FQuantization_(signal_processing)\" title%3D\"Quantization (signal processing)\">Quantization <%24cheerio1 href%3D\"%2Fwiki%2FRate%E2%80%93distortion_theory\" title%3D\"Rate distortion theory\">Rate distortion <%24cheerio1 href%3D\"%2Fwiki%2FRedundancy_(information_theory)\" title%3D\"Redundancy (information theory)\">Redundancy <%24cheerio1 class%3D\"navbox-abovebelow\" colspan%3D\"2\"> <%24cheerio1 href%3D\"%2Fwiki%2FTemplate%3ACompression_formats\" title%3D\"Template%3ACompression formats\">Compression formats <%24cheerio1 href%3D\"%2Fwiki%2FTemplate%3ACompression_software\" title%3D\"Template%3ACompression software\">Compression software (codecs) <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FCategory_theory\" title%3D\"Category theory\">Category theory <%24cheerio1 class%3D\"mw-selflink selflink\">Information theory <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_logic\" title%3D\"Mathematical logic\">Mathematical logic <%24cheerio1 href%3D\"%2Fwiki%2FPhilosophy_of_mathematics\" title%3D\"Philosophy of mathematics\">Philosophy of mathematics <%24cheerio1 href%3D\"%2Fwiki%2FSet_theory\" title%3D\"Set theory\">Set theory <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FAbstract_algebra\" title%3D\"Abstract algebra\">Abstract <%24cheerio1 href%3D\"%2Fwiki%2FCommutative_algebra\" title%3D\"Commutative algebra\">Commutative <%24cheerio1 href%3D\"%2Fwiki%2FElementary_algebra\" title%3D\"Elementary algebra\">Elementary <%24cheerio1 href%3D\"%2Fwiki%2FGroup_theory\" title%3D\"Group theory\">Group theory <%24cheerio1 href%3D\"%2Fwiki%2FLinear_algebra\" title%3D\"Linear algebra\">Linear <%24cheerio1 href%3D\"%2Fwiki%2FMultilinear_algebra\" title%3D\"Multilinear algebra\">Multilinear <%24cheerio1 href%3D\"%2Fwiki%2FUniversal_algebra\" title%3D\"Universal algebra\">Universal <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FCalculus\" title%3D\"Calculus\">Calculus <%24cheerio1 href%3D\"%2Fwiki%2FReal_analysis\" title%3D\"Real analysis\">Real analysis <%24cheerio1 href%3D\"%2Fwiki%2FComplex_analysis\" title%3D\"Complex analysis\">Complex analysis <%24cheerio1 href%3D\"%2Fwiki%2FDifferential_equation\" title%3D\"Differential equation\">Differential equations <%24cheerio1 href%3D\"%2Fwiki%2FFunctional_analysis\" title%3D\"Functional analysis\">Functional analysis <%24cheerio1 href%3D\"%2Fwiki%2FHarmonic_analysis\" title%3D\"Harmonic analysis\">Harmonic analysis <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FCombinatorics\" title%3D\"Combinatorics\">Combinatorics <%24cheerio1 href%3D\"%2Fwiki%2FGraph_theory\" title%3D\"Graph theory\">Graph theory <%24cheerio1 href%3D\"%2Fwiki%2FOrder_theory\" title%3D\"Order theory\">Order theory <%24cheerio1 href%3D\"%2Fwiki%2FGame_theory\" title%3D\"Game theory\">Game theory <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FAlgebraic_geometry\" title%3D\"Algebraic geometry\">Algebraic <%24cheerio1 href%3D\"%2Fwiki%2FAnalytic_geometry\" title%3D\"Analytic geometry\">Analytic <%24cheerio1 href%3D\"%2Fwiki%2FDifferential_geometry\" title%3D\"Differential geometry\">Differential <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_geometry\" title%3D\"Discrete geometry\">Discrete <%24cheerio1 href%3D\"%2Fwiki%2FEuclidean_geometry\" title%3D\"Euclidean geometry\">Euclidean <%24cheerio1 href%3D\"%2Fwiki%2FFinite_geometry\" title%3D\"Finite geometry\">Finite <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FArithmetic\" title%3D\"Arithmetic\">Arithmetic <%24cheerio1 href%3D\"%2Fwiki%2FAlgebraic_number_theory\" title%3D\"Algebraic number theory\">Algebraic number theory <%24cheerio1 href%3D\"%2Fwiki%2FAnalytic_number_theory\" title%3D\"Analytic number theory\">Analytic number theory <%24cheerio1 href%3D\"%2Fwiki%2FDiophantine_geometry\" title%3D\"Diophantine geometry\">Diophantine geometry <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FAlgebraic_topology\" title%3D\"Algebraic topology\">Algebraic <%24cheerio1 href%3D\"%2Fwiki%2FDifferential_topology\" title%3D\"Differential topology\">Differential <%24cheerio1 href%3D\"%2Fwiki%2FGeometric_topology\" title%3D\"Geometric topology\">Geometric <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FControl_theory\" title%3D\"Control theory\">Control theory <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_and_theoretical_biology\" title%3D\"Mathematical and theoretical biology\">Mathematical biology <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_chemistry\" title%3D\"Mathematical chemistry\">Mathematical chemistry <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_economics\" title%3D\"Mathematical economics\">Mathematical economics <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_finance\" title%3D\"Mathematical finance\">Mathematical finance <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_physics\" title%3D\"Mathematical physics\">Mathematical physics <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_psychology\" title%3D\"Mathematical psychology\">Mathematical psychology <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_sociology\" title%3D\"Mathematical sociology\">Mathematical sociology <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_statistics\" title%3D\"Mathematical statistics\">Mathematical statistics <%24cheerio1 href%3D\"%2Fwiki%2FOperations_research\" title%3D\"Operations research\">Operations research <%24cheerio1 href%3D\"%2Fwiki%2FProbability_theory\" title%3D\"Probability theory\">Probability <%24cheerio1 href%3D\"%2Fwiki%2FStatistics\" title%3D\"Statistics\">Statistics <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FComputer_science\" title%3D\"Computer science\">Computer science <%24cheerio1 href%3D\"%2Fwiki%2FTheory_of_computation\" title%3D\"Theory of computation\">Theory of computation <%24cheerio1 href%3D\"%2Fwiki%2FNumerical_analysis\" title%3D\"Numerical analysis\">Numerical analysis <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_optimization\" title%3D\"Mathematical optimization\">Optimization <%24cheerio1 href%3D\"%2Fwiki%2FComputer_algebra\" title%3D\"Computer algebra\">Computer algebra <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FHistory_of_mathematics\" title%3D\"History of mathematics\">History of mathematics <%24cheerio1 href%3D\"%2Fwiki%2FRecreational_mathematics\" title%3D\"Recreational mathematics\">Recreational mathematics <%24cheerio1 href%3D\"%2Fwiki%2FMathematics_and_art\" title%3D\"Mathematics and art\">Mathematics and art <%24cheerio1 href%3D\"%2Fwiki%2FMathematics_education\" title%3D\"Mathematics education\">Mathematics education <%24cheerio1 class%3D\"navbox-abovebelow\" colspan%3D\"2\"> <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AFields_of_mathematics\" title%3D\"Category%3AFields of mathematics\">Category <%24cheerio1 href%3D\"%2Fwiki%2FPortal%3AMathematics\" title%3D\"Portal%3AMathematics\">Portal <%24cheerio1 href%3D\"https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FCategory%3AMathematics\" class%3D\"extiw\" title%3D\"commons%3ACategory%3AMathematics\">Commons <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AWikiProject_Mathematics\" title%3D\"Wikipedia%3AWikiProject Mathematics\">WikiProject <%24cheerio1 href%3D\"%2Fwiki%2FTemplate%3AAreas_of_mathematics\" title%3D\"Template%3AAreas of mathematics\"> <%24cheerio1bbr title%3D\"View this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">v <%24cheerio1 href%3D\"%2Fwiki%2FTemplate_talk%3AAreas_of_mathematics\" title%3D\"Template talk%3AAreas of mathematics\"> <%24cheerio1bbr title%3D\"Discuss this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">t <%24cheerio1 class%3D\"external text\" href%3D\"https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DTemplate%3AAreas_of_mathematics%26action%3Dedit\"> <%24cheerio1bbr title%3D\"Edit this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">e <%24cheerio1 href%3D\"%2Fwiki%2FMathematics\" title%3D\"Mathematics\">Mathematics ( <%24cheerio1 href%3D\"%2Fwiki%2FAreas_of_mathematics\" title%3D\"Areas of mathematics\">areas of mathematics ) <%24cheerio1 href%3D\"%2Fwiki%2FFoundations_of_mathematics\" title%3D\"Foundations of mathematics\">Foundations <%24cheerio1 href%3D\"%2Fwiki%2FAlgebra\" title%3D\"Algebra\">Algebra <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_analysis\" title%3D\"Mathematical analysis\">Analysis <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_mathematics\" title%3D\"Discrete mathematics\">Discrete <%24cheerio1 href%3D\"%2Fwiki%2FGeometry\" title%3D\"Geometry\">Geometry <%24cheerio1 href%3D\"%2Fwiki%2FNumber_theory\" title%3D\"Number theory\">Number theory <%24cheerio1 href%3D\"%2Fwiki%2FTopology\" title%3D\"Topology\">Topology <%24cheerio1 href%3D\"%2Fwiki%2FApplied_mathematics\" title%3D\"Applied mathematics\">Applied <%24cheerio1 href%3D\"%2Fwiki%2FComputational_mathematics\" title%3D\"Computational mathematics\">Computational <%24cheerio1 href%3D\"%2Fwiki%2FLists_of_mathematics_topics\" title%3D\"Lists of mathematics topics\">Related topics <%24cheerio1 class%3D\"navbox-abovebelow\" colspan%3D\"3\"> Note%3A This template roughly follows the 2012 <%24cheerio1 href%3D\"%2Fwiki%2FACM_Computing_Classification_System\" title%3D\"ACM Computing Classification System\">ACM Computing Classification System . <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FPrinted_circuit_board\" title%3D\"Printed circuit board\">Printed circuit board <%24cheerio1 href%3D\"%2Fwiki%2FPeripheral\" title%3D\"Peripheral\">Peripheral <%24cheerio1 href%3D\"%2Fwiki%2FIntegrated_circuit\" title%3D\"Integrated circuit\">Integrated circuit <%24cheerio1 href%3D\"%2Fwiki%2FVery_Large_Scale_Integration\" title%3D\"Very Large Scale Integration\">Very Large Scale Integration <%24cheerio1 href%3D\"%2Fwiki%2FSystem_on_a_chip\" title%3D\"System on a chip\">Systems on Chip (SoCs) <%24cheerio1 href%3D\"%2Fwiki%2FGreen_computing\" title%3D\"Green computing\">Energy consumption (Green computing) <%24cheerio1 href%3D\"%2Fwiki%2FElectronic_design_automation\" title%3D\"Electronic design automation\">Electronic design automation <%24cheerio1 href%3D\"%2Fwiki%2FHardware_acceleration\" title%3D\"Hardware acceleration\">Hardware acceleration <%24cheerio1 class%3D\"noviewer navbox-image\" rowspan%3D\"17\" style%3D\"width%3A1px%3Bpadding%3A0px 0px 0px 2px\"> <%24cheerio1 href%3D\"%2Fwiki%2FFile%3AComputer_Retro.svg\" class%3D\"image\"> <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FComputer_architecture\" title%3D\"Computer architecture\">Computer architecture <%24cheerio1 href%3D\"%2Fwiki%2FEmbedded_system\" title%3D\"Embedded system\">Embedded system <%24cheerio1 href%3D\"%2Fwiki%2FReal-time_computing\" title%3D\"Real-time computing\">Real-time computing <%24cheerio1 href%3D\"%2Fwiki%2FDependability\" title%3D\"Dependability\">Dependability <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FNetwork_architecture\" title%3D\"Network architecture\">Network architecture <%24cheerio1 href%3D\"%2Fwiki%2FNetwork_protocol\" class%3D\"mw-redirect\" title%3D\"Network protocol\">Network protocol <%24cheerio1 href%3D\"%2Fwiki%2FNetworking_hardware\" title%3D\"Networking hardware\">Network components <%24cheerio1 href%3D\"%2Fwiki%2FNetwork_scheduler\" title%3D\"Network scheduler\">Network scheduler <%24cheerio1 href%3D\"%2Fwiki%2FNetwork_performance\" title%3D\"Network performance\">Network performance evaluation <%24cheerio1 href%3D\"%2Fwiki%2FNetwork_service\" title%3D\"Network service\">Network service <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FInterpreter_(computing)\" title%3D\"Interpreter (computing)\">Interpreter <%24cheerio1 href%3D\"%2Fwiki%2FMiddleware\" title%3D\"Middleware\">Middleware <%24cheerio1 href%3D\"%2Fwiki%2FVirtual_machine\" title%3D\"Virtual machine\">Virtual machine <%24cheerio1 href%3D\"%2Fwiki%2FOperating_system\" title%3D\"Operating system\">Operating system <%24cheerio1 href%3D\"%2Fwiki%2FSoftware_quality\" title%3D\"Software quality\">Software quality <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FProgramming_paradigm\" title%3D\"Programming paradigm\">Programming paradigm <%24cheerio1 href%3D\"%2Fwiki%2FProgramming_language\" title%3D\"Programming language\">Programming language <%24cheerio1 href%3D\"%2Fwiki%2FCompiler_construction\" class%3D\"mw-redirect\" title%3D\"Compiler construction\">Compiler <%24cheerio1 href%3D\"%2Fwiki%2FDomain-specific_language\" title%3D\"Domain-specific language\">Domain-specific language <%24cheerio1 href%3D\"%2Fwiki%2FModeling_language\" title%3D\"Modeling language\">Modeling language <%24cheerio1 href%3D\"%2Fwiki%2FSoftware_framework\" title%3D\"Software framework\">Software framework <%24cheerio1 href%3D\"%2Fwiki%2FIntegrated_development_environment\" title%3D\"Integrated development environment\">Integrated development environment <%24cheerio1 href%3D\"%2Fwiki%2FSoftware_configuration_management\" title%3D\"Software configuration management\">Software configuration management <%24cheerio1 href%3D\"%2Fwiki%2FLibrary_(computing)\" title%3D\"Library (computing)\">Software library <%24cheerio1 href%3D\"%2Fwiki%2FSoftware_repository\" title%3D\"Software repository\">Software repository <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FControl_variable_(programming)\" title%3D\"Control variable (programming)\">Control variable <%24cheerio1 href%3D\"%2Fwiki%2FSoftware_development_process\" title%3D\"Software development process\">Software development process <%24cheerio1 href%3D\"%2Fwiki%2FRequirements_analysis\" title%3D\"Requirements analysis\">Requirements analysis <%24cheerio1 href%3D\"%2Fwiki%2FSoftware_design\" title%3D\"Software design\">Software design <%24cheerio1 href%3D\"%2Fwiki%2FSoftware_construction\" title%3D\"Software construction\">Software construction <%24cheerio1 href%3D\"%2Fwiki%2FSoftware_deployment\" title%3D\"Software deployment\">Software deployment <%24cheerio1 href%3D\"%2Fwiki%2FSoftware_maintenance\" title%3D\"Software maintenance\">Software maintenance <%24cheerio1 href%3D\"%2Fwiki%2FProgramming_team\" title%3D\"Programming team\">Programming team <%24cheerio1 href%3D\"%2Fwiki%2FOpen-source_software\" title%3D\"Open-source software\">Open-source model <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FModel_of_computation\" title%3D\"Model of computation\">Model of computation <%24cheerio1 href%3D\"%2Fwiki%2FFormal_language\" title%3D\"Formal language\">Formal language <%24cheerio1 href%3D\"%2Fwiki%2FAutomata_theory\" title%3D\"Automata theory\">Automata theory <%24cheerio1 href%3D\"%2Fwiki%2FComputability_theory\" title%3D\"Computability theory\">Computability theory <%24cheerio1 href%3D\"%2Fwiki%2FComputational_complexity_theory\" title%3D\"Computational complexity theory\">Computational complexity theory <%24cheerio1 href%3D\"%2Fwiki%2FLogic_in_computer_science\" title%3D\"Logic in computer science\">Logic <%24cheerio1 href%3D\"%2Fwiki%2FSemantics_(computer_science)\" title%3D\"Semantics (computer science)\">Semantics <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FAlgorithm_design\" class%3D\"mw-redirect\" title%3D\"Algorithm design\">Algorithm design <%24cheerio1 href%3D\"%2Fwiki%2FAnalysis_of_algorithms\" title%3D\"Analysis of algorithms\">Analysis of algorithms <%24cheerio1 href%3D\"%2Fwiki%2FAlgorithmic_efficiency\" title%3D\"Algorithmic efficiency\">Algorithmic efficiency <%24cheerio1 href%3D\"%2Fwiki%2FRandomized_algorithm\" title%3D\"Randomized algorithm\">Randomized algorithm <%24cheerio1 href%3D\"%2Fwiki%2FComputational_geometry\" title%3D\"Computational geometry\">Computational geometry <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FDiscrete_mathematics\" title%3D\"Discrete mathematics\">Discrete mathematics <%24cheerio1 href%3D\"%2Fwiki%2FProbability\" title%3D\"Probability\">Probability <%24cheerio1 href%3D\"%2Fwiki%2FStatistics\" title%3D\"Statistics\">Statistics <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_software\" title%3D\"Mathematical software\">Mathematical software <%24cheerio1 class%3D\"mw-selflink selflink\">Information theory <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_analysis\" title%3D\"Mathematical analysis\">Mathematical analysis <%24cheerio1 href%3D\"%2Fwiki%2FNumerical_analysis\" title%3D\"Numerical analysis\">Numerical analysis <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FDatabase\" title%3D\"Database\">Database management system <%24cheerio1 href%3D\"%2Fwiki%2FComputer_data_storage\" title%3D\"Computer data storage\">Information storage systems <%24cheerio1 href%3D\"%2Fwiki%2FEnterprise_information_system\" title%3D\"Enterprise information system\">Enterprise information system <%24cheerio1 href%3D\"%2Fwiki%2FSocial_software\" title%3D\"Social software\">Social information systems <%24cheerio1 href%3D\"%2Fwiki%2FGeographic_information_system\" title%3D\"Geographic information system\">Geographic information system <%24cheerio1 href%3D\"%2Fwiki%2FDecision_support_system\" title%3D\"Decision support system\">Decision support system <%24cheerio1 href%3D\"%2Fwiki%2FProcess_control\" title%3D\"Process control\">Process control system <%24cheerio1 href%3D\"%2Fwiki%2FMultimedia_database\" title%3D\"Multimedia database\">Multimedia information system <%24cheerio1 href%3D\"%2Fwiki%2FData_mining\" title%3D\"Data mining\">Data mining <%24cheerio1 href%3D\"%2Fwiki%2FDigital_library\" title%3D\"Digital library\">Digital library <%24cheerio1 href%3D\"%2Fwiki%2FComputing_platform\" title%3D\"Computing platform\">Computing platform <%24cheerio1 href%3D\"%2Fwiki%2FDigital_marketing\" title%3D\"Digital marketing\">Digital marketing <%24cheerio1 href%3D\"%2Fwiki%2FWorld_Wide_Web\" title%3D\"World Wide Web\">World Wide Web <%24cheerio1 href%3D\"%2Fwiki%2FInformation_retrieval\" title%3D\"Information retrieval\">Information retrieval <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FCryptography\" title%3D\"Cryptography\">Cryptography <%24cheerio1 href%3D\"%2Fwiki%2FFormal_methods\" title%3D\"Formal methods\">Formal methods <%24cheerio1 href%3D\"%2Fwiki%2FSecurity_service_(telecommunication)\" title%3D\"Security service (telecommunication)\">Security services <%24cheerio1 href%3D\"%2Fwiki%2FIntrusion_detection_system\" title%3D\"Intrusion detection system\">Intrusion detection system <%24cheerio1 href%3D\"%2Fwiki%2FComputer_security_compromised_by_hardware_failure\" title%3D\"Computer security compromised by hardware failure\">Hardware security <%24cheerio1 href%3D\"%2Fwiki%2FNetwork_security\" title%3D\"Network security\">Network security <%24cheerio1 href%3D\"%2Fwiki%2FInformation_security\" title%3D\"Information security\">Information security <%24cheerio1 href%3D\"%2Fwiki%2FApplication_security\" title%3D\"Application security\">Application security <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FInteraction_design\" title%3D\"Interaction design\">Interaction design <%24cheerio1 href%3D\"%2Fwiki%2FSocial_computing\" title%3D\"Social computing\">Social computing <%24cheerio1 href%3D\"%2Fwiki%2FUbiquitous_computing\" title%3D\"Ubiquitous computing\">Ubiquitous computing <%24cheerio1 href%3D\"%2Fwiki%2FVisualization_(graphics)\" title%3D\"Visualization (graphics)\">Visualization <%24cheerio1 href%3D\"%2Fwiki%2FComputer_accessibility\" title%3D\"Computer accessibility\">Accessibility <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FConcurrent_computing\" title%3D\"Concurrent computing\">Concurrent computing <%24cheerio1 href%3D\"%2Fwiki%2FParallel_computing\" title%3D\"Parallel computing\">Parallel computing <%24cheerio1 href%3D\"%2Fwiki%2FDistributed_computing\" title%3D\"Distributed computing\">Distributed computing <%24cheerio1 href%3D\"%2Fwiki%2FMultithreading_(computer_architecture)\" title%3D\"Multithreading (computer architecture)\">Multithreading <%24cheerio1 href%3D\"%2Fwiki%2FMultiprocessing\" title%3D\"Multiprocessing\">Multiprocessing <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FNatural_language_processing\" title%3D\"Natural language processing\">Natural language processing <%24cheerio1 href%3D\"%2Fwiki%2FKnowledge_representation_and_reasoning\" title%3D\"Knowledge representation and reasoning\">Knowledge representation and reasoning <%24cheerio1 href%3D\"%2Fwiki%2FComputer_vision\" title%3D\"Computer vision\">Computer vision <%24cheerio1 href%3D\"%2Fwiki%2FAutomated_planning_and_scheduling\" title%3D\"Automated planning and scheduling\">Automated planning and scheduling <%24cheerio1 href%3D\"%2Fwiki%2FMathematical_optimization\" title%3D\"Mathematical optimization\">Search methodology <%24cheerio1 href%3D\"%2Fwiki%2FControl_theory\" title%3D\"Control theory\">Control method <%24cheerio1 href%3D\"%2Fwiki%2FPhilosophy_of_artificial_intelligence\" title%3D\"Philosophy of artificial intelligence\">Philosophy of artificial intelligence <%24cheerio1 href%3D\"%2Fwiki%2FDistributed_artificial_intelligence\" title%3D\"Distributed artificial intelligence\">Distributed artificial intelligence <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FSupervised_learning\" title%3D\"Supervised learning\">Supervised learning <%24cheerio1 href%3D\"%2Fwiki%2FUnsupervised_learning\" title%3D\"Unsupervised learning\">Unsupervised learning <%24cheerio1 href%3D\"%2Fwiki%2FReinforcement_learning\" title%3D\"Reinforcement learning\">Reinforcement learning <%24cheerio1 href%3D\"%2Fwiki%2FMulti-task_learning\" title%3D\"Multi-task learning\">Multi-task learning <%24cheerio1 href%3D\"%2Fwiki%2FCross-validation_(statistics)\" title%3D\"Cross-validation (statistics)\">Cross-validation <%24cheerio1 class%3D\"navbox-list navbox-even\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FComputer_animation\" title%3D\"Computer animation\">Animation <%24cheerio1 href%3D\"%2Fwiki%2FRendering_(computer_graphics)\" title%3D\"Rendering (computer graphics)\">Rendering <%24cheerio1 href%3D\"%2Fwiki%2FPhoto_manipulation\" title%3D\"Photo manipulation\">Image manipulation <%24cheerio1 href%3D\"%2Fwiki%2FGraphics_processing_unit\" title%3D\"Graphics processing unit\">Graphics processing unit <%24cheerio1 href%3D\"%2Fwiki%2FMixed_reality\" title%3D\"Mixed reality\">Mixed reality <%24cheerio1 href%3D\"%2Fwiki%2FVirtual_reality\" title%3D\"Virtual reality\">Virtual reality <%24cheerio1 href%3D\"%2Fwiki%2FImage_compression\" title%3D\"Image compression\">Image compression <%24cheerio1 href%3D\"%2Fwiki%2FSolid_modeling\" title%3D\"Solid modeling\">Solid modeling <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FE-commerce\" title%3D\"E-commerce\">E-commerce <%24cheerio1 href%3D\"%2Fwiki%2FEnterprise_software\" title%3D\"Enterprise software\">Enterprise software <%24cheerio1 href%3D\"%2Fwiki%2FComputational_mathematics\" title%3D\"Computational mathematics\">Computational mathematics <%24cheerio1 href%3D\"%2Fwiki%2FComputational_physics\" title%3D\"Computational physics\">Computational physics <%24cheerio1 href%3D\"%2Fwiki%2FComputational_chemistry\" title%3D\"Computational chemistry\">Computational chemistry <%24cheerio1 href%3D\"%2Fwiki%2FComputational_biology\" title%3D\"Computational biology\">Computational biology <%24cheerio1 href%3D\"%2Fwiki%2FComputational_social_science\" title%3D\"Computational social science\">Computational social science <%24cheerio1 href%3D\"%2Fwiki%2FComputational_engineering\" title%3D\"Computational engineering\">Computational engineering <%24cheerio1 href%3D\"%2Fwiki%2FHealth_informatics\" title%3D\"Health informatics\">Computational healthcare <%24cheerio1 href%3D\"%2Fwiki%2FDigital_art\" title%3D\"Digital art\">Digital art <%24cheerio1 href%3D\"%2Fwiki%2FElectronic_publishing\" title%3D\"Electronic publishing\">Electronic publishing <%24cheerio1 href%3D\"%2Fwiki%2FCyberwarfare\" title%3D\"Cyberwarfare\">Cyberwarfare <%24cheerio1 href%3D\"%2Fwiki%2FElectronic_voting\" title%3D\"Electronic voting\">Electronic voting <%24cheerio1 href%3D\"%2Fwiki%2FVideo_game\" title%3D\"Video game\">Video games <%24cheerio1 href%3D\"%2Fwiki%2FWord_processor\" title%3D\"Word processor\">Word processing <%24cheerio1 href%3D\"%2Fwiki%2FOperations_research\" title%3D\"Operations research\">Operations research <%24cheerio1 href%3D\"%2Fwiki%2FEducational_technology\" title%3D\"Educational technology\">Educational technology <%24cheerio1 href%3D\"%2Fwiki%2FDocument_management_system\" title%3D\"Document management system\">Document management <%24cheerio1 class%3D\"navbox-abovebelow\" colspan%3D\"3\"> <%24cheerio1 href%3D\"%2Fwiki%2FBook%3AComputer_science\" class%3D\"mw-redirect\" title%3D\"Book%3AComputer science\">Book <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AComputer_science\" title%3D\"Category%3AComputer science\">Category <%24cheerio1 href%3D\"%2Fwiki%2FOutline_of_computer_science\" title%3D\"Outline of computer science\">Outline <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AWikiProject_Computer_science\" title%3D\"Wikipedia%3AWikiProject Computer science\">WikiProject <%24cheerio1 href%3D\"https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FCategory%3AComputer_science\" class%3D\"extiw\" title%3D\"commons%3ACategory%3AComputer science\">Commons <%24cheerio1 href%3D\"%2Fwiki%2FTemplate%3AComputer_science\" title%3D\"Template%3AComputer science\"> <%24cheerio1bbr title%3D\"View this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">v <%24cheerio1 href%3D\"%2Fwiki%2FTemplate_talk%3AComputer_science\" title%3D\"Template talk%3AComputer science\"> <%24cheerio1bbr title%3D\"Discuss this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">t <%24cheerio1 class%3D\"external text\" href%3D\"https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DTemplate%3AComputer_science%26action%3Dedit\"> <%24cheerio1bbr title%3D\"Edit this template\" style%3D\"%3B%3Bbackground%3Anone transparent%3Bborder%3Anone%3Bbox-shadow%3Anone%3Bpadding%3A0%3B\">e <%24cheerio1 href%3D\"%2Fwiki%2FComputer_science\" title%3D\"Computer science\">Computer science <%24cheerio1 href%3D\"%2Fwiki%2FComputer_hardware\" title%3D\"Computer hardware\">Hardware Computer systems organization <%24cheerio1 href%3D\"%2Fwiki%2FComputer_network\" title%3D\"Computer network\">Networks Software organization <%24cheerio1 href%3D\"%2Fwiki%2FProgramming_language_theory\" title%3D\"Programming language theory\">Software notations and <%24cheerio1 href%3D\"%2Fwiki%2FProgramming_tool\" title%3D\"Programming tool\">tools <%24cheerio1 href%3D\"%2Fwiki%2FSoftware_development\" title%3D\"Software development\">Software development <%24cheerio1 href%3D\"%2Fwiki%2FTheory_of_computation\" title%3D\"Theory of computation\">Theory of computation <%24cheerio1 href%3D\"%2Fwiki%2FAlgorithm\" title%3D\"Algorithm\">Algorithms Mathematics of computing <%24cheerio1 href%3D\"%2Fwiki%2FInformation_system\" title%3D\"Information system\">Information systems <%24cheerio1 href%3D\"%2Fwiki%2FComputer_security\" title%3D\"Computer security\">Security <%24cheerio1 href%3D\"%2Fwiki%2FHuman%E2%80%93computer_interaction\" title%3D\"Human computer interaction\">Human computer interaction <%24cheerio1 href%3D\"%2Fwiki%2FConcurrency_(computer_science)\" title%3D\"Concurrency (computer science)\">Concurrency <%24cheerio1 href%3D\"%2Fwiki%2FArtificial_intelligence\" title%3D\"Artificial intelligence\">Artificial intelligence <%24cheerio1 href%3D\"%2Fwiki%2FMachine_learning\" title%3D\"Machine learning\">Machine learning <%24cheerio1 href%3D\"%2Fwiki%2FComputer_graphics\" title%3D\"Computer graphics\">Graphics Applied computing <%24cheerio1 class%3D\"navbox-list navbox-odd\" style%3D\"text-align%3Aleft%3Bborder-left-width%3A2px%3Bborder-left-style%3Asolid%3Bwidth%3A100%%3Bpadding%3A0px\"> <%24cheerio1 href%3D\"%2Fwiki%2FGND_(identifier)\" class%3D\"mw-redirect\" title%3D\"GND (identifier)\">GND %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fd-nb.info%2Fgnd%2F4026927-9\">4026927-9 <%24cheerio1 href%3D\"%2Fwiki%2FNDL_(identifier)\" class%3D\"mw-redirect\" title%3D\"NDL (identifier)\">NDL %3A <%24cheerio1 rel%3D\"nofollow\" class%3D\"external text\" href%3D\"https%3A%2F%2Fid.ndl.go.jp%2Fauth%2Fndlna%2F00575012\">00575012 <%24cheerio1 href%3D\"%2Fwiki%2FHelp%3AAuthority_control\" title%3D\"Help%3AAuthority control\">Authority control <%24cheerio1 href%3D\"https%3A%2F%2Fwww.wikidata.org%2Fwiki%2FQ131222%23identifiers\" title%3D\"Edit this at Wikidata\"> Retrieved from \" <%24cheerio1 dir%3D\"ltr\" href%3D\"https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26oldid%3D1001439814\">https%3A%2F%2Fen.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26oldid%3D1001439814 \" <%24cheerio1 href%3D\"%2Fwiki%2FHelp%3ACategory\" title%3D\"Help%3ACategory\">Categories %3A <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AInformation_theory\" title%3D\"Category%3AInformation theory\">Information theory <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AComputer-related_introductions_in_1948\" title%3D\"Category%3AComputer-related introductions in 1948\">Computer-related introductions in 1948 <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AComputer_science\" title%3D\"Category%3AComputer science\">Computer science <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3ACybernetics\" title%3D\"Category%3ACybernetics\">Cybernetics <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AFormal_sciences\" title%3D\"Category%3AFormal sciences\">Formal sciences <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AInformation_Age\" title%3D\"Category%3AInformation Age\">Information Age <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AClaude_Shannon\" title%3D\"Category%3AClaude Shannon\">Claude Shannon Hidden categories%3A <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3ACS1_errors%3A_missing_periodical\" title%3D\"Category%3ACS1 errors%3A missing periodical\">CS1 errors%3A missing periodical <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AArticles_with_short_description\" title%3D\"Category%3AArticles with short description\">Articles with short description <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AShort_description_is_different_from_Wikidata\" title%3D\"Category%3AShort description is different from Wikidata\">Short description is different from Wikidata <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AArticles_with_too_many_examples_from_May_2020\" title%3D\"Category%3AArticles with too many examples from May 2020\">Articles with too many examples from May 2020 <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AAll_articles_with_too_many_examples\" title%3D\"Category%3AAll articles with too many examples\">All articles with too many examples <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AWikipedia_articles_with_style_issues_from_May_2020\" title%3D\"Category%3AWikipedia articles with style issues from May 2020\">Wikipedia articles with style issues from May 2020 <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AWikipedia_articles_with_GND_identifiers\" title%3D\"Category%3AWikipedia articles with GND identifiers\">Wikipedia articles with GND identifiers <%24cheerio1 href%3D\"%2Fwiki%2FCategory%3AWikipedia_articles_with_NDL_identifiers\" title%3D\"Category%3AWikipedia articles with NDL identifiers\">Wikipedia articles with NDL identifiers Navigation menu Personal tools Not logged in <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3AMyTalk\" title%3D\"Discussion about edits from this IP address [n]\" accesskey%3D\"n\">Talk <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3AMyContributions\" title%3D\"A list of edits made from this IP address [y]\" accesskey%3D\"y\">Contributions <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DSpecial%3ACreateAccount%26returnto%3DInformation%2Btheory\" title%3D\"You are encouraged to create an account and log in%3B however%2C it is not mandatory\">Create account <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DSpecial%3AUserLogin%26returnto%3DInformation%2Btheory\" title%3D\"You're encouraged to log in%3B however%2C it's not mandatory. [o]\" accesskey%3D\"o\">Log in Namespaces <%24cheerio1 href%3D\"%2Fwiki%2FInformation_theory\" title%3D\"View the content page [c]\" accesskey%3D\"c\">Article <%24cheerio1 href%3D\"%2Fwiki%2FTalk%3AInformation_theory\" rel%3D\"discussion\" title%3D\"Discuss improvements to the content page [t]\" accesskey%3D\"t\">Talk Variants Views <%24cheerio1 href%3D\"%2Fwiki%2FInformation_theory\">Read <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dedit\" title%3D\"Edit this page [e]\" accesskey%3D\"e\">Edit <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dhistory\" title%3D\"Past revisions of this page [h]\" accesskey%3D\"h\">View history More Search <%24cheerio1 class%3D\"mw-wiki-logo\" href%3D\"%2Fwiki%2FMain_Page\" title%3D\"Visit the main page\"> Navigation <%24cheerio1 href%3D\"%2Fwiki%2FMain_Page\" title%3D\"Visit the main page [z]\" accesskey%3D\"z\">Main page <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AContents\" title%3D\"Guides to browsing Wikipedia\">Contents <%24cheerio1 href%3D\"%2Fwiki%2FPortal%3ACurrent_events\" title%3D\"Articles related to current events\">Current events <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ARandom\" title%3D\"Visit a randomly selected article [x]\" accesskey%3D\"x\">Random article <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AAbout\" title%3D\"Learn about Wikipedia and how it works\">About Wikipedia <%24cheerio1 href%3D\"%2F%2Fen.wikipedia.org%2Fwiki%2FWikipedia%3AContact_us\" title%3D\"How to contact Wikipedia\">Contact us <%24cheerio1 href%3D\"https%3A%2F%2Fdonate.wikimedia.org%2Fwiki%2FSpecial%3AFundraiserRedirector%3Futm_source%3Ddonate%26utm_medium%3Dsidebar%26utm_campaign%3DC13_en.wikipedia.org%26uselang%3Den\" title%3D\"Support us by donating to the Wikimedia Foundation\">Donate Contribute <%24cheerio1 href%3D\"%2Fwiki%2FHelp%3AContents\" title%3D\"Guidance on how to use and edit Wikipedia\">Help <%24cheerio1 href%3D\"%2Fwiki%2FHelp%3AIntroduction\" title%3D\"Learn how to edit Wikipedia\">Learn to edit <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3ACommunity_portal\" title%3D\"The hub for editors\">Community portal <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ARecentChanges\" title%3D\"A list of recent changes to Wikipedia [r]\" accesskey%3D\"r\">Recent changes <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AFile_Upload_Wizard\" title%3D\"Add images or other media for use on Wikipedia\">Upload file Tools <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3AWhatLinksHere%2FInformation_theory\" title%3D\"List of all English Wikipedia pages containing links to this page [j]\" accesskey%3D\"j\">What links here <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ARecentChangesLinked%2FInformation_theory\" rel%3D\"nofollow\" title%3D\"Recent changes in pages linked from this page [k]\" accesskey%3D\"k\">Related changes <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AFile_Upload_Wizard\" title%3D\"Upload files [u]\" accesskey%3D\"u\">Upload file <%24cheerio1 href%3D\"%2Fwiki%2FSpecial%3ASpecialPages\" title%3D\"A list of all special pages [q]\" accesskey%3D\"q\">Special pages <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26oldid%3D1001439814\" title%3D\"Permanent link to this revision of this page\">Permanent link <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26action%3Dinfo\" title%3D\"More information about this page\">Page information <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DSpecial%3ACiteThisPage%26page%3DInformation_theory%26id%3D1001439814%26wpFormIdentifier%3Dtitleform\" title%3D\"Information on how to cite this page\">Cite this page <%24cheerio1 href%3D\"https%3A%2F%2Fwww.wikidata.org%2Fwiki%2FSpecial%3AEntityPage%2FQ131222\" title%3D\"Structured data on this page hosted by Wikidata [g]\" accesskey%3D\"g\">Wikidata item Print%2Fexport <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DSpecial%3ADownloadAsPdf%26page%3DInformation_theory%26action%3Dshow-download-screen\" title%3D\"Download this page as a PDF file\">Download as PDF <%24cheerio1 href%3D\"%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26printable%3Dyes\" title%3D\"Printable version of this page [p]\" accesskey%3D\"p\">Printable version In other projects <%24cheerio1 href%3D\"https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FCategory%3AInformation_theory\" hreflang%3D\"en\">Wikimedia Commons <%24cheerio1 href%3D\"https%3A%2F%2Fen.wikiquote.org%2Fwiki%2FInformation_theory\" hreflang%3D\"en\">Wikiquote Languages <%24cheerio1 href%3D\"https%3A%2F%2Faf.wikipedia.org%2Fwiki%2FInligtingsteorie\" title%3D\"Inligtingsteorie Afrikaans\" hreflang%3D\"af\" class%3D\"interlanguage-link-target\" lang%3D\"af\">Afrikaans <%24cheerio1 href%3D\"https%3A%2F%2Far.wikipedia.org%2Fwiki%2F%D9%86%D8%B8%D8%B1%D9%8A%D8%A9_%D8%A7%D9%84%D9%85%D8%B9%D9%84%D9%88%D9%85%D8%A7%D8%AA\" title%3D\"نظرية المعلومات Arabic\" hreflang%3D\"ar\" class%3D\"interlanguage-link-target\" lang%3D\"ar\">العربية <%24cheerio1 href%3D\"https%3A%2F%2Fast.wikipedia.org%2Fwiki%2FTeor%C3%ADa_de_la_informaci%C3%B3n\" title%3D\"Teoría de la información Asturian\" hreflang%3D\"ast\" class%3D\"interlanguage-link-target\" lang%3D\"ast\">Asturianu <%24cheerio1 href%3D\"https%3A%2F%2Faz.wikipedia.org%2Fwiki%2F%C4%B0nformasiya_n%C9%99z%C9%99riyy%C9%99si\" title%3D\"İnformasiya nəzəriyyəsi Azerbaijani\" hreflang%3D\"az\" class%3D\"interlanguage-link-target\" lang%3D\"az\">Azərbaycanca <%24cheerio1 href%3D\"https%3A%2F%2Fbn.wikipedia.org%2Fwiki%2F%E0%A6%A4%E0%A6%A5%E0%A7%8D%E0%A6%AF_%E0%A6%A4%E0%A6%A4%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%AC\" title%3D\"তথ্য তত্ত্ব Bangla\" hreflang%3D\"bn\" class%3D\"interlanguage-link-target\" lang%3D\"bn\">বাংলা <%24cheerio1 href%3D\"https%3A%2F%2Fba.wikipedia.org%2Fwiki%2F%D0%9C%D3%99%D2%93%D0%BB%D2%AF%D0%BC%D3%99%D1%82_%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%8F%D2%BB%D1%8B\" title%3D\"Мәғлүмәт теорияһы Bashkir\" hreflang%3D\"ba\" class%3D\"interlanguage-link-target\" lang%3D\"ba\">Башҡортса <%24cheerio1 href%3D\"https%3A%2F%2Fbe.wikipedia.org%2Fwiki%2F%D0%A2%D1%8D%D0%BE%D1%80%D1%8B%D1%8F_%D1%96%D0%BD%D1%84%D0%B0%D1%80%D0%BC%D0%B0%D1%86%D1%8B%D1%96\" title%3D\"Тэорыя інфармацыі Belarusian\" hreflang%3D\"be\" class%3D\"interlanguage-link-target\" lang%3D\"be\">Беларуская <%24cheerio1 href%3D\"https%3A%2F%2Fbg.wikipedia.org%2Fwiki%2F%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%BD%D0%B0_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D1%8F%D1%82%D0%B0\" title%3D\"Теория на информацията Bulgarian\" hreflang%3D\"bg\" class%3D\"interlanguage-link-target\" lang%3D\"bg\">Български <%24cheerio1 href%3D\"https%3A%2F%2Fbar.wikipedia.org%2Fwiki%2FInformationstheorie\" title%3D\"Informationstheorie Bavarian\" hreflang%3D\"bar\" class%3D\"interlanguage-link-target\" lang%3D\"bar\">Boarisch <%24cheerio1 href%3D\"https%3A%2F%2Fca.wikipedia.org%2Fwiki%2FTeoria_de_la_informaci%C3%B3\" title%3D\"Teoria de la informació Catalan\" hreflang%3D\"ca\" class%3D\"interlanguage-link-target\" lang%3D\"ca\">Català <%24cheerio1 href%3D\"https%3A%2F%2Fcs.wikipedia.org%2Fwiki%2FTeorie_informace\" title%3D\"Teorie informace Czech\" hreflang%3D\"cs\" class%3D\"interlanguage-link-target\" lang%3D\"cs\">Čeština <%24cheerio1 href%3D\"https%3A%2F%2Fda.wikipedia.org%2Fwiki%2FInformationsteori\" title%3D\"Informationsteori Danish\" hreflang%3D\"da\" class%3D\"interlanguage-link-target\" lang%3D\"da\">Dansk <%24cheerio1 href%3D\"https%3A%2F%2Fde.wikipedia.org%2Fwiki%2FInformationstheorie\" title%3D\"Informationstheorie German\" hreflang%3D\"de\" class%3D\"interlanguage-link-target\" lang%3D\"de\">Deutsch <%24cheerio1 href%3D\"https%3A%2F%2Fet.wikipedia.org%2Fwiki%2FInformatsiooniteooria\" title%3D\"Informatsiooniteooria Estonian\" hreflang%3D\"et\" class%3D\"interlanguage-link-target\" lang%3D\"et\">Eesti <%24cheerio1 href%3D\"https%3A%2F%2Fel.wikipedia.org%2Fwiki%2F%CE%98%CE%B5%CF%89%CF%81%CE%AF%CE%B1_%CF%80%CE%BB%CE%B7%CF%81%CE%BF%CF%86%CE%BF%CF%81%CE%AF%CE%B1%CF%82\" title%3D\"Θεωρία πληροφορίας Greek\" hreflang%3D\"el\" class%3D\"interlanguage-link-target\" lang%3D\"el\">Ελληνικά <%24cheerio1 href%3D\"https%3A%2F%2Fes.wikipedia.org%2Fwiki%2FTeor%C3%ADa_de_la_informaci%C3%B3n\" title%3D\"Teoría de la información Spanish\" hreflang%3D\"es\" class%3D\"interlanguage-link-target\" lang%3D\"es\">Español <%24cheerio1 href%3D\"https%3A%2F%2Feo.wikipedia.org%2Fwiki%2FInformteorio\" title%3D\"Informteorio Esperanto\" hreflang%3D\"eo\" class%3D\"interlanguage-link-target\" lang%3D\"eo\">Esperanto <%24cheerio1 href%3D\"https%3A%2F%2Ffa.wikipedia.org%2Fwiki%2F%D9%86%D8%B8%D8%B1%DB%8C%D9%87_%D8%A7%D8%B7%D9%84%D8%A7%D8%B9%D8%A7%D8%AA\" title%3D\"نظریه اطلاعات Persian\" hreflang%3D\"fa\" class%3D\"interlanguage-link-target\" lang%3D\"fa\">فارسی <%24cheerio1 href%3D\"https%3A%2F%2Ffr.wikipedia.org%2Fwiki%2FTh%C3%A9orie_de_l%27information\" title%3D\"Théorie de l'information French\" hreflang%3D\"fr\" class%3D\"interlanguage-link-target\" lang%3D\"fr\">Français <%24cheerio1 href%3D\"https%3A%2F%2Fga.wikipedia.org%2Fwiki%2FTeoiric_na_faisn%C3%A9ise\" title%3D\"Teoiric na faisnéise Irish\" hreflang%3D\"ga\" class%3D\"interlanguage-link-target\" lang%3D\"ga\">Gaeilge <%24cheerio1 href%3D\"https%3A%2F%2Fgl.wikipedia.org%2Fwiki%2FTeor%C3%ADa_da_informaci%C3%B3n\" title%3D\"Teoría da información Galician\" hreflang%3D\"gl\" class%3D\"interlanguage-link-target\" lang%3D\"gl\">Galego <%24cheerio1 href%3D\"https%3A%2F%2Fko.wikipedia.org%2Fwiki%2F%EC%A0%95%EB%B3%B4_%EC%9D%B4%EB%A1%A0\" title%3D\"정보 이론 Korean\" hreflang%3D\"ko\" class%3D\"interlanguage-link-target\" lang%3D\"ko\">한국어 <%24cheerio1 href%3D\"https%3A%2F%2Fhy.wikipedia.org%2Fwiki%2F%D4%BB%D5%B6%D6%86%D5%B8%D6%80%D5%B4%D5%A1%D6%81%D5%AB%D5%A1%D5%B5%D5%AB_%D5%BF%D5%A5%D5%BD%D5%B8%D6%82%D5%A9%D5%B5%D5%B8%D6%82%D5%B6\" title%3D\"Ինֆորմացիայի տեսություն Armenian\" hreflang%3D\"hy\" class%3D\"interlanguage-link-target\" lang%3D\"hy\">Հայերեն <%24cheerio1 href%3D\"https%3A%2F%2Fhr.wikipedia.org%2Fwiki%2FTeorija_informacije\" title%3D\"Teorija informacije Croatian\" hreflang%3D\"hr\" class%3D\"interlanguage-link-target\" lang%3D\"hr\">Hrvatski <%24cheerio1 href%3D\"https%3A%2F%2Fio.wikipedia.org%2Fwiki%2FInformo-teorio\" title%3D\"Informo-teorio Ido\" hreflang%3D\"io\" class%3D\"interlanguage-link-target\" lang%3D\"io\">Ido <%24cheerio1 href%3D\"https%3A%2F%2Fid.wikipedia.org%2Fwiki%2FTeori_informasi\" title%3D\"Teori informasi Indonesian\" hreflang%3D\"id\" class%3D\"interlanguage-link-target\" lang%3D\"id\">Bahasa Indonesia <%24cheerio1 href%3D\"https%3A%2F%2Fia.wikipedia.org%2Fwiki%2FTheoria_del_information\" title%3D\"Theoria del information Interlingua\" hreflang%3D\"ia\" class%3D\"interlanguage-link-target\" lang%3D\"ia\">Interlingua <%24cheerio1 href%3D\"https%3A%2F%2Fit.wikipedia.org%2Fwiki%2FTeoria_dell%27informazione\" title%3D\"Teoria dell'informazione Italian\" hreflang%3D\"it\" class%3D\"interlanguage-link-target\" lang%3D\"it\">Italiano <%24cheerio1 href%3D\"https%3A%2F%2Fhe.wikipedia.org%2Fwiki%2F%D7%AA%D7%95%D7%A8%D7%AA_%D7%94%D7%90%D7%99%D7%A0%D7%A4%D7%95%D7%A8%D7%9E%D7%A6%D7%99%D7%94\" title%3D\"תורת האינפורמציה Hebrew\" hreflang%3D\"he\" class%3D\"interlanguage-link-target\" lang%3D\"he\">עברית <%24cheerio1 href%3D\"https%3A%2F%2Fka.wikipedia.org%2Fwiki%2F%E1%83%98%E1%83%9C%E1%83%A4%E1%83%9D%E1%83%A0%E1%83%9B%E1%83%90%E1%83%AA%E1%83%98%E1%83%98%E1%83%A1_%E1%83%97%E1%83%94%E1%83%9D%E1%83%A0%E1%83%98%E1%83%90\" title%3D\"ინფორმაციის თეორია Georgian\" hreflang%3D\"ka\" class%3D\"interlanguage-link-target\" lang%3D\"ka\">ქართული <%24cheerio1 href%3D\"https%3A%2F%2Fkk.wikipedia.org%2Fwiki%2F%D0%90%D2%9B%D0%BF%D0%B0%D1%80%D0%B0%D1%82_%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%8F%D1%81%D1%8B\" title%3D\"Ақпарат теориясы Kazakh\" hreflang%3D\"kk\" class%3D\"interlanguage-link-target\" lang%3D\"kk\">Қазақша <%24cheerio1 href%3D\"https%3A%2F%2Flv.wikipedia.org%2Fwiki%2FInform%C4%81cijas_teorija\" title%3D\"Informācijas teorija Latvian\" hreflang%3D\"lv\" class%3D\"interlanguage-link-target\" lang%3D\"lv\">Latviešu <%24cheerio1 href%3D\"https%3A%2F%2Flt.wikipedia.org%2Fwiki%2FInformacijos_teorija\" title%3D\"Informacijos teorija Lithuanian\" hreflang%3D\"lt\" class%3D\"interlanguage-link-target\" lang%3D\"lt\">Lietuvių <%24cheerio1 href%3D\"https%3A%2F%2Fhu.wikipedia.org%2Fwiki%2FInform%C3%A1ci%C3%B3elm%C3%A9let\" title%3D\"Információelmélet Hungarian\" hreflang%3D\"hu\" class%3D\"interlanguage-link-target\" lang%3D\"hu\">Magyar <%24cheerio1 href%3D\"https%3A%2F%2Fmk.wikipedia.org%2Fwiki%2F%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%98%D0%B0_%D0%BD%D0%B0_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%B8\" title%3D\"Теорија на информации Macedonian\" hreflang%3D\"mk\" class%3D\"interlanguage-link-target\" lang%3D\"mk\">Македонски <%24cheerio1 href%3D\"https%3A%2F%2Fml.wikipedia.org%2Fwiki%2F%E0%B4%B5%E0%B4%BF%E0%B4%B5%E0%B4%B0_%E0%B4%B8%E0%B4%BF%E0%B4%A6%E0%B5%8D%E0%B4%A7%E0%B4%BE%E0%B4%A8%E0%B5%8D%E0%B4%A4%E0%B4%82\" title%3D\"വിവര സിദ്ധാന്തം Malayalam\" hreflang%3D\"ml\" class%3D\"interlanguage-link-target\" lang%3D\"ml\">മലയാളം <%24cheerio1 href%3D\"https%3A%2F%2Fms.wikipedia.org%2Fwiki%2FTeori_maklumat\" title%3D\"Teori maklumat Malay\" hreflang%3D\"ms\" class%3D\"interlanguage-link-target\" lang%3D\"ms\">Bahasa Melayu <%24cheerio1 href%3D\"https%3A%2F%2Fmwl.wikipedia.org%2Fwiki%2FTeorie_de_l%27anforma%C3%A7on\" title%3D\"Teorie de l'anformaçon Mirandese\" hreflang%3D\"mwl\" class%3D\"interlanguage-link-target\" lang%3D\"mwl\">Mirandés <%24cheerio1 href%3D\"https%3A%2F%2Fmn.wikipedia.org%2Fwiki%2F%D0%9C%D1%8D%D0%B4%D1%8D%D1%8D%D0%BB%D0%BB%D0%B8%D0%B9%D0%BD_%D0%BE%D0%BD%D0%BE%D0%BB\" title%3D\"Мэдээллийн онол Mongolian\" hreflang%3D\"mn\" class%3D\"interlanguage-link-target\" lang%3D\"mn\">Монгол <%24cheerio1 href%3D\"https%3A%2F%2Fmy.wikipedia.org%2Fwiki%2F%E1%80%9E%E1%80%90%E1%80%84%E1%80%BA%E1%80%B8%E1%80%A1%E1%80%81%E1%80%BB%E1%80%80%E1%80%BA%E1%80%A1%E1%80%9C%E1%80%80%E1%80%BA_%E1%80%9E%E1%80%AE%E1%80%A1%E1%80%AD%E1%80%AF%E1%80%9B%E1%80%AE\" title%3D\"သတင်းအချက်အလက် သီအိုရီ Burmese\" hreflang%3D\"my\" class%3D\"interlanguage-link-target\" lang%3D\"my\">မြန်မာဘာသာ <%24cheerio1 href%3D\"https%3A%2F%2Fnl.wikipedia.org%2Fwiki%2FInformatietheorie\" title%3D\"Informatietheorie Dutch\" hreflang%3D\"nl\" class%3D\"interlanguage-link-target\" lang%3D\"nl\">Nederlands <%24cheerio1 href%3D\"https%3A%2F%2Fja.wikipedia.org%2Fwiki%2F%E6%83%85%E5%A0%B1%E7%90%86%E8%AB%96\" title%3D\"情報理論 Japanese\" hreflang%3D\"ja\" class%3D\"interlanguage-link-target\" lang%3D\"ja\">日本語 <%24cheerio1 href%3D\"https%3A%2F%2Fno.wikipedia.org%2Fwiki%2FInformasjonsteori\" title%3D\"Informasjonsteori Norwegian Bokmål\" hreflang%3D\"nb\" class%3D\"interlanguage-link-target\" lang%3D\"nb\">Norsk bokmål <%24cheerio1 href%3D\"https%3A%2F%2Fnn.wikipedia.org%2Fwiki%2FInformasjonsteori\" title%3D\"Informasjonsteori Norwegian Nynorsk\" hreflang%3D\"nn\" class%3D\"interlanguage-link-target\" lang%3D\"nn\">Norsk nynorsk <%24cheerio1 href%3D\"https%3A%2F%2Foc.wikipedia.org%2Fwiki%2FTeoria_de_l%27informacion\" title%3D\"Teoria de l'informacion Occitan\" hreflang%3D\"oc\" class%3D\"interlanguage-link-target\" lang%3D\"oc\">Occitan <%24cheerio1 href%3D\"https%3A%2F%2Fuz.wikipedia.org%2Fwiki%2FInformatsiya_nazariyasi\" title%3D\"Informatsiya nazariyasi Uzbek\" hreflang%3D\"uz\" class%3D\"interlanguage-link-target\" lang%3D\"uz\">Oʻzbekcha%2Fўзбекча <%24cheerio1 href%3D\"https%3A%2F%2Fpnb.wikipedia.org%2Fwiki%2F%D9%86%D8%B8%D8%B1%DB%8C%DB%82_%D8%A7%D8%B7%D9%84%D8%A7%D8%B9%D8%A7%D8%AA\" title%3D\"نظریۂ اطلاعات Western Punjabi\" hreflang%3D\"pnb\" class%3D\"interlanguage-link-target\" lang%3D\"pnb\">پنجابی <%24cheerio1 href%3D\"https%3A%2F%2Fpl.wikipedia.org%2Fwiki%2FTeoria_informacji\" title%3D\"Teoria informacji Polish\" hreflang%3D\"pl\" class%3D\"interlanguage-link-target\" lang%3D\"pl\">Polski <%24cheerio1 href%3D\"https%3A%2F%2Fpt.wikipedia.org%2Fwiki%2FTeoria_da_informa%C3%A7%C3%A3o\" title%3D\"Teoria da informação Portuguese\" hreflang%3D\"pt\" class%3D\"interlanguage-link-target\" lang%3D\"pt\">Português <%24cheerio1 href%3D\"https%3A%2F%2Fro.wikipedia.org%2Fwiki%2FTeoria_informa%C8%9Biei\" title%3D\"Teoria informației Romanian\" hreflang%3D\"ro\" class%3D\"interlanguage-link-target\" lang%3D\"ro\">Română <%24cheerio1 href%3D\"https%3A%2F%2Fru.wikipedia.org%2Fwiki%2F%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%B8\" title%3D\"Теория информации Russian\" hreflang%3D\"ru\" class%3D\"interlanguage-link-target\" lang%3D\"ru\">Русский <%24cheerio1 href%3D\"https%3A%2F%2Fsimple.wikipedia.org%2Fwiki%2FInformation_theory\" title%3D\"Information theory Simple English\" hreflang%3D\"en-simple\" class%3D\"interlanguage-link-target\" lang%3D\"en-simple\">Simple English <%24cheerio1 href%3D\"https%3A%2F%2Fsk.wikipedia.org%2Fwiki%2FTe%C3%B3ria_inform%C3%A1cie\" title%3D\"Teória informácie Slovak\" hreflang%3D\"sk\" class%3D\"interlanguage-link-target\" lang%3D\"sk\">Slovenčina <%24cheerio1 href%3D\"https%3A%2F%2Fsl.wikipedia.org%2Fwiki%2FTeorija_informacij\" title%3D\"Teorija informacij Slovenian\" hreflang%3D\"sl\" class%3D\"interlanguage-link-target\" lang%3D\"sl\">Slovenščina <%24cheerio1 href%3D\"https%3A%2F%2Fckb.wikipedia.org%2Fwiki%2F%D8%AA%DB%8C%DB%86%D8%B1%DB%8C%DB%8C_%D8%B2%D8%A7%D9%86%DB%8C%D8%A7%D8%B1%DB%8C\" title%3D\"تیۆریی زانیاری Central Kurdish\" hreflang%3D\"ckb\" class%3D\"interlanguage-link-target\" lang%3D\"ckb\">کوردی <%24cheerio1 href%3D\"https%3A%2F%2Fsr.wikipedia.org%2Fwiki%2F%D0%A2%D0%B5%D0%BE%D1%80%D0%B8%D1%98%D0%B0_%D0%B8%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D1%98%D0%B5\" title%3D\"Теорија информације Serbian\" hreflang%3D\"sr\" class%3D\"interlanguage-link-target\" lang%3D\"sr\">Српски %2F srpski <%24cheerio1 href%3D\"https%3A%2F%2Fsh.wikipedia.org%2Fwiki%2FTeorija_informacije\" title%3D\"Teorija informacije Serbo-Croatian\" hreflang%3D\"sh\" class%3D\"interlanguage-link-target\" lang%3D\"sh\">Srpskohrvatski %2F српскохрватски <%24cheerio1 href%3D\"https%3A%2F%2Ffi.wikipedia.org%2Fwiki%2FInformaatioteoria\" title%3D\"Informaatioteoria Finnish\" hreflang%3D\"fi\" class%3D\"interlanguage-link-target\" lang%3D\"fi\">Suomi <%24cheerio1 href%3D\"https%3A%2F%2Fsv.wikipedia.org%2Fwiki%2FInformationsteori\" title%3D\"Informationsteori Swedish\" hreflang%3D\"sv\" class%3D\"interlanguage-link-target\" lang%3D\"sv\">Svenska <%24cheerio1 href%3D\"https%3A%2F%2Ftl.wikipedia.org%2Fwiki%2FTeorya_ng_impormasyon\" title%3D\"Teorya ng impormasyon Tagalog\" hreflang%3D\"tl\" class%3D\"interlanguage-link-target\" lang%3D\"tl\">Tagalog <%24cheerio1 href%3D\"https%3A%2F%2Fta.wikipedia.org%2Fwiki%2F%E0%AE%A4%E0%AE%95%E0%AE%B5%E0%AE%B2%E0%AF%8D_%E0%AE%95%E0%AF%8B%E0%AE%9F%E0%AF%8D%E0%AE%AA%E0%AE%BE%E0%AE%9F%E0%AF%81\" title%3D\"தகவல் கோட்பாடு Tamil\" hreflang%3D\"ta\" class%3D\"interlanguage-link-target\" lang%3D\"ta\">தமிழ் <%24cheerio1 href%3D\"https%3A%2F%2Fth.wikipedia.org%2Fwiki%2F%E0%B8%97%E0%B8%A4%E0%B8%A9%E0%B8%8E%E0%B8%B5%E0%B8%AA%E0%B8%B2%E0%B8%A3%E0%B8%AA%E0%B8%99%E0%B9%80%E0%B8%97%E0%B8%A8\" title%3D\"ทฤษฎีสารสนเทศ Thai\" hreflang%3D\"th\" class%3D\"interlanguage-link-target\" lang%3D\"th\">ไทย <%24cheerio1 href%3D\"https%3A%2F%2Ftr.wikipedia.org%2Fwiki%2FBilgi_teorisi\" title%3D\"Bilgi teorisi Turkish\" hreflang%3D\"tr\" class%3D\"interlanguage-link-target\" lang%3D\"tr\">Türkçe <%24cheerio1 href%3D\"https%3A%2F%2Fuk.wikipedia.org%2Fwiki%2F%D0%A2%D0%B5%D0%BE%D1%80%D1%96%D1%8F_%D1%96%D0%BD%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D1%96%D1%97\" title%3D\"Теорія інформації Ukrainian\" hreflang%3D\"uk\" class%3D\"interlanguage-link-target\" lang%3D\"uk\">Українська <%24cheerio1 href%3D\"https%3A%2F%2Fur.wikipedia.org%2Fwiki%2F%D9%86%D8%B8%D8%B1%DB%8C%DB%82_%D8%A7%D8%B7%D9%84%D8%A7%D8%B9%D8%A7%D8%AA\" title%3D\"نظریۂ اطلاعات Urdu\" hreflang%3D\"ur\" class%3D\"interlanguage-link-target\" lang%3D\"ur\">اردو <%24cheerio1 href%3D\"https%3A%2F%2Fvi.wikipedia.org%2Fwiki%2FL%C3%BD_thuy%E1%BA%BFt_th%C3%B4ng_tin\" title%3D\"Lý thuyết thông tin Vietnamese\" hreflang%3D\"vi\" class%3D\"interlanguage-link-target\" lang%3D\"vi\">Tiếng Việt <%24cheerio1 href%3D\"https%3A%2F%2Fwuu.wikipedia.org%2Fwiki%2F%E4%BF%A1%E6%81%AF%E8%AE%BA\" title%3D\"信息论 Wu Chinese\" hreflang%3D\"wuu\" class%3D\"interlanguage-link-target\" lang%3D\"wuu\">吴语 <%24cheerio1 href%3D\"https%3A%2F%2Fzh-yue.wikipedia.org%2Fwiki%2F%E8%B3%87%E8%A8%8A%E7%90%86%E8%AB%96\" title%3D\"資訊理論 Cantonese\" hreflang%3D\"yue\" class%3D\"interlanguage-link-target\" lang%3D\"yue\">粵語 <%24cheerio1 href%3D\"https%3A%2F%2Fzh.wikipedia.org%2Fwiki%2F%E4%BF%A1%E6%81%AF%E8%AE%BA\" title%3D\"信息论 Chinese\" hreflang%3D\"zh\" class%3D\"interlanguage-link-target\" lang%3D\"zh\">中文 <%24cheerio1 href%3D\"https%3A%2F%2Fwww.wikidata.org%2Fwiki%2FSpecial%3AEntityPage%2FQ131222%23sitelinks-wikipedia\" title%3D\"Edit interlanguage links\" class%3D\"wbc-editpage\">Edit links This page was last edited on 19 January 2021%2C at 17%3A59 (UTC). Text is available under the <%24cheerio1 rel%3D\"license\" href%3D\"%2F%2Fen.wikipedia.org%2Fwiki%2FWikipedia%3AText_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\">Creative Commons Attribution-ShareAlike License <%24cheerio1 rel%3D\"license\" href%3D\"%2F%2Fcreativecommons.org%2Flicenses%2Fby-sa%2F3.0%2F\" style%3D\"display%3Anone%3B\"> %3B additional terms may apply. By using this site%2C you agree to the <%24cheerio1 href%3D\"%2F%2Ffoundation.wikimedia.org%2Fwiki%2FTerms_of_Use\">Terms of Use and <%24cheerio1 href%3D\"%2F%2Ffoundation.wikimedia.org%2Fwiki%2FPrivacy_policy\">Privacy Policy . Wikipedia® is a registered trademark of the <%24cheerio1 href%3D\"%2F%2Fwww.wikimediafoundation.org%2F\">Wikimedia Foundation%2C Inc. %2C a non-profit organization. <%24cheerio1 href%3D\"https%3A%2F%2Ffoundation.wikimedia.org%2Fwiki%2FPrivacy_policy\" class%3D\"extiw\" title%3D\"wmf%3APrivacy policy\">Privacy policy <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AAbout\" title%3D\"Wikipedia%3AAbout\">About Wikipedia <%24cheerio1 href%3D\"%2Fwiki%2FWikipedia%3AGeneral_disclaimer\" title%3D\"Wikipedia%3AGeneral disclaimer\">Disclaimers <%24cheerio1 href%3D\"%2F%2Fen.wikipedia.org%2Fwiki%2FWikipedia%3AContact_us\">Contact Wikipedia <%24cheerio1 href%3D\"%2F%2Fen.m.wikipedia.org%2Fw%2Findex.php%3Ftitle%3DInformation_theory%26mobileaction%3Dtoggle_view_mobile\" class%3D\"noprint stopMobileRedirectToggle\">Mobile view <%24cheerio1 href%3D\"https%3A%2F%2Fwww.mediawiki.org%2Fwiki%2FSpecial%3AMyLanguage%2FHow_to_contribute\">Developers <%24cheerio1 href%3D\"https%3A%2F%2Fstats.wikimedia.org%2F%23%2Fen.wikipedia.org\">Statistics <%24cheerio1 href%3D\"https%3A%2F%2Ffoundation.wikimedia.org%2Fwiki%2FCookie_statement\">Cookie statement <%24cheerio1 href%3D\"https%3A%2F%2Fwikimediafoundation.org%2F\"> <%24cheerio1 href%3D\"https%3A%2F%2Fwww.mediawiki.org%2F\"> "}}
background_scripts.js:1:325986
